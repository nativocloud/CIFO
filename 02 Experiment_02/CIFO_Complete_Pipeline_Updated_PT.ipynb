{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c877b8e3",
   "metadata": {},
   "source": [
    "# CIFO - Pipeline Completo: Execução e Análise de Algoritmos de Otimização\n",
    "\n",
    "Este notebook integra todo o processo desde a execução dos algoritmos até à visualização e análise dos resultados."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea93a517",
   "metadata": {},
   "source": [
    "## 1. Configuração do Ambiente e Importações"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "981c8f58",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "# Importações necessárias\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from copy import deepcopy\n",
    "import os\n",
    "from datetime import datetime\n",
    "import warnings\n",
    "from collections import defaultdict\n",
    "import scipy.stats as stats\n",
    "import scikit_posthocs as sp\n",
    "from statsmodels.stats.multicomp import pairwise_tukeyhsd\n",
    "\n",
    "# Configurar matplotlib para notebook\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = (14, 10)\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "sns.set_context(\"notebook\", font_scale=1.2)\n",
    "\n",
    "# Suprimir avisos específicos\n",
    "warnings.filterwarnings(\"ignore\", message=\"scipy.stats.shapiro: Input data has range zero.*\")\n",
    "warnings.filterwarnings(\"ignore\", message=\"No artists with labels found to put in legend.*\")\n",
    "\n",
    "# Importar módulos do projeto\n",
    "from solution import LeagueSolution, LeagueHillClimbingSolution\n",
    "from evolution import hill_climbing, simulated_annealing\n",
    "from operators import (\n",
    "    selection_tournament,\n",
    "    selection_ranking,\n",
    "    selection_boltzmann,\n",
    "    crossover_one_point,\n",
    "    crossover_uniform,\n",
    "    mutate_swap, \n",
    "    mutate_swap_constrained,\n",
    "    genetic_algorithm\n",
    ")\n",
    "from fitness_counter import FitnessCounter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cd950b8",
   "metadata": {},
   "source": [
    "## 2. Implementação de Funções Auxiliares"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "29a7e69e",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "# Implementar crossover de dois pontos (não existe em operators.py)\n",
    "def two_point_crossover(parent1, parent2):\n",
    "    \"\"\"\n",
    "    Two-point crossover: creates a child by taking portions from each parent.\n",
    "    \n",
    "    Args:\n",
    "        parent1 (LeagueSolution): First parent solution\n",
    "        parent2 (LeagueSolution): Second parent solution\n",
    "        \n",
    "    Returns:\n",
    "        LeagueSolution: A new solution created by crossover\n",
    "    \"\"\"\n",
    "    cut1 = random.randint(1, len(parent1.repr) - 3)\n",
    "    cut2 = random.randint(cut1 + 1, len(parent1.repr) - 2)\n",
    "    child_repr = parent1.repr[:cut1] + parent2.repr[cut1:cut2] + parent1.repr[cut2:]\n",
    "    \n",
    "    return LeagueSolution(\n",
    "        repr=child_repr,\n",
    "        num_teams=parent1.num_teams,\n",
    "        team_size=parent1.team_size,\n",
    "        max_budget=parent1.max_budget,\n",
    "        players=parent1.players\n",
    "    )\n",
    "\n",
    "# Função para interpretar o tamanho do efeito\n",
    "def interpret_effect_size(eta_squared):\n",
    "    \"\"\"\n",
    "    Interpreta o tamanho do efeito (eta-squared) de acordo com as convenções estatísticas.\n",
    "    \n",
    "    Args:\n",
    "        eta_squared (float): Valor de eta-squared\n",
    "        \n",
    "    Returns:\n",
    "        str: Interpretação do tamanho do efeito\n",
    "    \"\"\"\n",
    "    if eta_squared < 0.01:\n",
    "        return \"Negligível\"\n",
    "    elif eta_squared < 0.06:\n",
    "        return \"Pequeno\"\n",
    "    elif eta_squared < 0.14:\n",
    "        return \"Médio\"\n",
    "    else:\n",
    "        return \"Grande\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02a947e6",
   "metadata": {},
   "source": [
    "## 3. Configuração dos Parâmetros de Execução"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d86ace34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuração centralizada dos experimentos\n",
    "EXPERIMENT_CONFIG = {\n",
    "    # Parâmetros gerais\n",
    "    'seed': 42,                    # Seed para reprodutibilidade\n",
    "    'num_runs': 1,                # Número de execuções para cada algoritmo\n",
    "    'max_evaluations': 10000,      # Número máximo de avaliações de função\n",
    "    'population_size': 100,        # Tamanho da população para algoritmos genéticos\n",
    "    'max_generations': 100,        # Número máximo de gerações para algoritmos genéticos\n",
    "    \n",
    "    # Parâmetros para análise estatística\n",
    "    'alpha': 0.05,                 # Nível de significância para testes estatísticos\n",
    "    'post_hoc_method': 'tukey',    # Método para testes post-hoc ('tukey' ou 'dunn')\n",
    "    \n",
    "    # Parâmetros para visualização\n",
    "    'figure_size': (14, 10),       # Tamanho padrão das figuras\n",
    "    'save_figures': False,         # Salvar figuras em arquivos\n",
    "    'figure_format': 'png',        # Formato para salvar figuras\n",
    "    \n",
    "    # Parâmetros para execução\n",
    "    'verbose': True,               # Mostrar progresso detalhado\n",
    "    'save_results': True,          # Salvar resultados em arquivos\n",
    "    'load_existing': False,        # Carregar resultados existentes (se disponíveis)\n",
    "}\n",
    "\n",
    "# Aplicar configurações\n",
    "random.seed(EXPERIMENT_CONFIG['seed'])\n",
    "np.random.seed(EXPERIMENT_CONFIG['seed'])\n",
    "plt.rcParams['figure.figsize'] = EXPERIMENT_CONFIG['figure_size']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e866850",
   "metadata": {},
   "source": [
    "## 4. Carregamento dos Dados dos Jogadores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "45cd1807",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dados dos jogadores:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Position</th>\n",
       "      <th>Skill</th>\n",
       "      <th>Salary (€M)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Alex Carter</td>\n",
       "      <td>GK</td>\n",
       "      <td>85</td>\n",
       "      <td>90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Jordan Smith</td>\n",
       "      <td>GK</td>\n",
       "      <td>88</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Ryan Mitchell</td>\n",
       "      <td>GK</td>\n",
       "      <td>83</td>\n",
       "      <td>85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Chris Thompson</td>\n",
       "      <td>GK</td>\n",
       "      <td>80</td>\n",
       "      <td>80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Blake Henderson</td>\n",
       "      <td>GK</td>\n",
       "      <td>87</td>\n",
       "      <td>95</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Name Position  Skill  Salary (€M)\n",
       "0      Alex Carter       GK     85           90\n",
       "1     Jordan Smith       GK     88          100\n",
       "2    Ryan Mitchell       GK     83           85\n",
       "3   Chris Thompson       GK     80           80\n",
       "4  Blake Henderson       GK     87           95"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Carregar dados dos jogadores usando o método especificado pelo utilizador\n",
    "players_df = pd.read_csv('players.csv', encoding='utf-8', sep=';', index_col=0)\n",
    "\n",
    "# Mostrar primeiras linhas\n",
    "print(\"Dados dos jogadores:\")\n",
    "display(players_df.head())\n",
    "\n",
    "# Verificar se a coluna de salário tem o nome correto\n",
    "if 'Salary (€M)' in players_df.columns:\n",
    "    # Renomear colunas para compatibilidade com o código\n",
    "    column_mapping = {\n",
    "        'Salary (€M)': 'Salary'\n",
    "    }\n",
    "    players_df = players_df.rename(columns=column_mapping)\n",
    "\n",
    "# Converter DataFrame para lista de dicionários\n",
    "players_list = players_df.to_dict('records')\n",
    "\n",
    "# Configurar contador de fitness\n",
    "fitness_counter = FitnessCounter()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b3fbb63",
   "metadata": {},
   "source": [
    "## 5. Configuração dos Algoritmos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e63afdc9",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Configurações dos algoritmos:\n",
      "\n",
      "HC_Standard:\n",
      "  algorithm: Hill Climbing\n",
      "\n",
      "SA_Standard:\n",
      "  algorithm: Simulated Annealing\n",
      "\n",
      "GA_Tournament_OnePoint:\n",
      "  algorithm: Genetic Algorithm\n",
      "  selection: Tournament\n",
      "  crossover: One Point\n",
      "  mutation_rate: 0.02857142857142857\n",
      "  elitism_percent: 0.1\n",
      "  population_size: 100\n",
      "  use_valid_initial: False\n",
      "  use_repair: False\n",
      "\n",
      "GA_Tournament_TwoPoint:\n",
      "  algorithm: Genetic Algorithm\n",
      "  selection: Tournament\n",
      "  crossover: Two Point\n",
      "  mutation_rate: 0.02857142857142857\n",
      "  elitism_percent: 0.1\n",
      "  population_size: 100\n",
      "  use_valid_initial: False\n",
      "  use_repair: False\n",
      "\n",
      "GA_Rank_Uniform:\n",
      "  algorithm: Genetic Algorithm\n",
      "  selection: Rank\n",
      "  crossover: Uniform\n",
      "  mutation_rate: 0.02857142857142857\n",
      "  elitism_percent: 0.1\n",
      "  population_size: 100\n",
      "  use_valid_initial: False\n",
      "  use_repair: False\n",
      "\n",
      "GA_Boltzmann_TwoPoint:\n",
      "  algorithm: Genetic Algorithm\n",
      "  selection: Boltzmann\n",
      "  crossover: Two Point\n",
      "  mutation_rate: 0.02857142857142857\n",
      "  elitism_percent: 0.1\n",
      "  population_size: 100\n",
      "  use_valid_initial: False\n",
      "  use_repair: False\n",
      "\n",
      "GA_Hybrid:\n",
      "  algorithm: Genetic Algorithm Hybrid\n",
      "  selection: Tournament\n",
      "  crossover: Two Point\n",
      "  mutation_rate: 0.02857142857142857\n",
      "  elitism_percent: 0.1\n",
      "  population_size: 100\n",
      "  use_valid_initial: False\n",
      "  use_repair: False\n"
     ]
    }
   ],
   "source": [
    "# Configurar algoritmos\n",
    "configs = {\n",
    "    # Algoritmos base\n",
    "    'HC_Standard': {\n",
    "        'algorithm': 'Hill Climbing',\n",
    "    },\n",
    "    'SA_Standard': {\n",
    "        'algorithm': 'Simulated Annealing',\n",
    "    },\n",
    "    'GA_Tournament_OnePoint': {\n",
    "        'algorithm': 'Genetic Algorithm',\n",
    "        'selection': 'Tournament',\n",
    "        'crossover': 'One Point',\n",
    "        'mutation_rate': 1.0/35,  # 1.0/len(players)\n",
    "        'elitism_percent': 0.1,   # 10%\n",
    "        'population_size': EXPERIMENT_CONFIG['population_size'],\n",
    "        'use_valid_initial': False,\n",
    "        'use_repair': False,\n",
    "    },\n",
    "    'GA_Tournament_TwoPoint': {\n",
    "        'algorithm': 'Genetic Algorithm',\n",
    "        'selection': 'Tournament',\n",
    "        'crossover': 'Two Point',\n",
    "        'mutation_rate': 1.0/35,\n",
    "        'elitism_percent': 0.1,\n",
    "        'population_size': EXPERIMENT_CONFIG['population_size'],\n",
    "        'use_valid_initial': False,\n",
    "        'use_repair': False,\n",
    "    },\n",
    "    'GA_Rank_Uniform': {\n",
    "        'algorithm': 'Genetic Algorithm',\n",
    "        'selection': 'Rank',\n",
    "        'crossover': 'Uniform',\n",
    "        'mutation_rate': 1.0/35,\n",
    "        'elitism_percent': 0.1,\n",
    "        'population_size': EXPERIMENT_CONFIG['population_size'],\n",
    "        'use_valid_initial': False,\n",
    "        'use_repair': False,\n",
    "    },\n",
    "    'GA_Boltzmann_TwoPoint': {\n",
    "        'algorithm': 'Genetic Algorithm',\n",
    "        'selection': 'Boltzmann',\n",
    "        'crossover': 'Two Point',\n",
    "        'mutation_rate': 1.0/35,\n",
    "        'elitism_percent': 0.1,\n",
    "        'population_size': EXPERIMENT_CONFIG['population_size'],\n",
    "        'use_valid_initial': False,\n",
    "        'use_repair': False,\n",
    "    },\n",
    "    'GA_Hybrid': {\n",
    "        'algorithm': 'Genetic Algorithm Hybrid',\n",
    "        'selection': 'Tournament',\n",
    "        'crossover': 'Two Point',\n",
    "        'mutation_rate': 1.0/35,\n",
    "        'elitism_percent': 0.1,\n",
    "        'population_size': EXPERIMENT_CONFIG['population_size'],\n",
    "        'use_valid_initial': False,\n",
    "        'use_repair': False,\n",
    "    }\n",
    "}\n",
    "\n",
    "# Mostrar configurações\n",
    "print(\"Configurações dos algoritmos:\")\n",
    "for config_name, config in configs.items():\n",
    "    print(f\"\\n{config_name}:\")\n",
    "    for key, value in config.items():\n",
    "        print(f\"  {key}: {value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d14b26cb",
   "metadata": {},
   "source": [
    "## 6. Implementação dos Algoritmos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0571e88b",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "# Função para executar Hill Climbing\n",
    "def run_hill_climbing(players, max_evaluations):\n",
    "    solution = LeagueSolution(players)\n",
    "    \n",
    "    # Iniciar contagem de fitness\n",
    "    fitness_counter.reset()\n",
    "    solution.set_fitness_counter(fitness_counter)\n",
    "    \n",
    "    best_fitness = solution.fitness()\n",
    "    history = [best_fitness]\n",
    "    \n",
    "    while fitness_counter.get_count() < max_evaluations:\n",
    "        # Gerar vizinho\n",
    "        neighbor = deepcopy(solution)\n",
    "        idx = random.randint(0, len(neighbor.repr) - 1)\n",
    "        neighbor.repr[idx] = random.randint(0, neighbor.num_teams - 1)\n",
    "        \n",
    "        neighbor_fitness = neighbor.fitness()\n",
    "        \n",
    "        # Aceitar se melhor\n",
    "        if neighbor_fitness < best_fitness:  # Menor é melhor\n",
    "            solution = neighbor\n",
    "            best_fitness = neighbor_fitness\n",
    "        \n",
    "        history.append(best_fitness)\n",
    "    \n",
    "    return solution, history, fitness_counter.get_count()\n",
    "\n",
    "# Função para executar Simulated Annealing\n",
    "def run_simulated_annealing(players, max_evaluations):\n",
    "    solution = LeagueSolution(players)\n",
    "    \n",
    "    # Iniciar contagem de fitness\n",
    "    fitness_counter.reset()\n",
    "    solution.set_fitness_counter(fitness_counter)\n",
    "    \n",
    "    best_solution = deepcopy(solution)\n",
    "    current_fitness = solution.fitness()\n",
    "    best_fitness = current_fitness\n",
    "    \n",
    "    history = [best_fitness]\n",
    "    \n",
    "    # Parâmetros do SA\n",
    "    initial_temp = 100.0\n",
    "    final_temp = 0.1\n",
    "    alpha = 0.95\n",
    "    \n",
    "    current_temp = initial_temp\n",
    "    \n",
    "    while fitness_counter.get_count() < max_evaluations and current_temp > final_temp:\n",
    "        # Gerar vizinho\n",
    "        neighbor = deepcopy(solution)\n",
    "        idx = random.randint(0, len(neighbor.repr) - 1)\n",
    "        neighbor.repr[idx] = random.randint(0, neighbor.num_teams - 1)\n",
    "        \n",
    "        neighbor_fitness = neighbor.fitness()\n",
    "        \n",
    "        # Calcular delta\n",
    "        delta = neighbor_fitness - current_fitness\n",
    "        \n",
    "        # Aceitar se melhor ou com probabilidade baseada na temperatura\n",
    "        if delta < 0 or random.random() < np.exp(-delta / current_temp):\n",
    "            solution = neighbor\n",
    "            current_fitness = neighbor_fitness\n",
    "            \n",
    "            # Atualizar melhor solução se necessário\n",
    "            if current_fitness < best_fitness:\n",
    "                best_solution = deepcopy(solution)\n",
    "                best_fitness = current_fitness\n",
    "        \n",
    "        history.append(best_fitness)\n",
    "        \n",
    "        # Resfriar\n",
    "        current_temp *= alpha\n",
    "    \n",
    "    return best_solution, history, fitness_counter.get_count()\n",
    "\n",
    "# Função para executar Genetic Algorithm\n",
    "def run_genetic_algorithm(players, config, max_evaluations):\n",
    "    # Iniciar contagem de fitness\n",
    "    fitness_counter.reset()\n",
    "    \n",
    "    # Configurar seleção\n",
    "    if config['selection'] == 'Tournament':\n",
    "        selection_op = selection_tournament\n",
    "    elif config['selection'] == 'Rank':\n",
    "        selection_op = selection_ranking\n",
    "    elif config['selection'] == 'Boltzmann':\n",
    "        selection_op = selection_boltzmann\n",
    "    else:\n",
    "        raise ValueError(f\"Seleção não suportada: {config['selection']}\")\n",
    "    \n",
    "    # Configurar crossover\n",
    "    if config['crossover'] == 'One Point':\n",
    "        crossover_op = crossover_one_point\n",
    "    elif config['crossover'] == 'Two Point':\n",
    "        crossover_op = two_point_crossover\n",
    "    elif config['crossover'] == 'Uniform':\n",
    "        crossover_op = crossover_uniform\n",
    "    else:\n",
    "        raise ValueError(f\"Crossover não suportado: {config['crossover']}\")\n",
    "    \n",
    "    # Configurar mutação\n",
    "    mutation_op = mutate_swap\n",
    "    \n",
    "    # Configurar operador de reparo (se necessário)\n",
    "    repair_op = None\n",
    "    if config.get('use_repair', False):\n",
    "        def repair_operator(solution):\n",
    "            # Implementação simples de reparo: tenta corrigir soluções inválidas\n",
    "            # ajustando a distribuição de jogadores por posição e orçamento\n",
    "            if solution.is_valid():\n",
    "                return solution\n",
    "            \n",
    "            # Obter estatísticas das equipes\n",
    "            teams = solution.get_teams()\n",
    "            \n",
    "            # Verificar e corrigir distribuição de posições\n",
    "            for team_idx, team in enumerate(teams):\n",
    "                positions = {\"GK\": 0, \"DEF\": 0, \"MID\": 0, \"FWD\": 0}\n",
    "                for player in team:\n",
    "                    positions[player[\"Position\"]] += 1\n",
    "                \n",
    "                # Se a distribuição estiver incorreta, tentar corrigir\n",
    "                if positions != {\"GK\": 1, \"DEF\": 2, \"MID\": 2, \"FWD\": 2}:\n",
    "                    # Implementação simplificada: apenas retorna a solução original\n",
    "                    # Uma implementação real seria mais complexa\n",
    "                    pass\n",
    "            \n",
    "            return solution\n",
    "        \n",
    "        repair_op = repair_operator\n",
    "    \n",
    "    # Configurar local search para GA híbrido\n",
    "    local_search = None\n",
    "    if config['algorithm'] == 'Genetic Algorithm Hybrid':\n",
    "        local_search = {\n",
    "            'operator': 'hill_climbing',\n",
    "            'probability': 0.1,\n",
    "            'iterations': 10\n",
    "        }\n",
    "    \n",
    "    # Executar GA\n",
    "    best_solution, best_fitness, history = genetic_algorithm(\n",
    "        players=players,\n",
    "        population_size=config['population_size'],\n",
    "        max_generations=EXPERIMENT_CONFIG['max_generations'],\n",
    "        selection_operator=selection_op,\n",
    "        crossover_operator=crossover_op,\n",
    "        crossover_rate=0.8,\n",
    "        mutation_operator=mutation_op,\n",
    "        mutation_rate=config['mutation_rate'],\n",
    "        elitism=config['elitism_percent'] > 0,\n",
    "        elitism_size=int(config['population_size'] * config['elitism_percent']),\n",
    "        local_search=local_search,\n",
    "        fitness_counter=fitness_counter,\n",
    "        max_evaluations=max_evaluations,\n",
    "        verbose=False\n",
    "    )\n",
    "    \n",
    "    return best_solution, history, fitness_counter.get_count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4113c820",
   "metadata": {},
   "source": [
    "## 7. Execução dos Experimentos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "98bdcecb",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "# Função para executar um experimento completo\n",
    "def run_experiment(config_name, config, players, num_runs, max_evaluations):\n",
    "    results = []\n",
    "    all_history = []\n",
    "    \n",
    "    for run in range(num_runs):\n",
    "        if EXPERIMENT_CONFIG['verbose']:\n",
    "            print(f\"Executando {config_name}, run {run+1}/{num_runs}...\")\n",
    "        \n",
    "        start_time = time.time()\n",
    "        \n",
    "        try:\n",
    "            if config['algorithm'] == 'Hill Climbing':\n",
    "                best_solution, history, evaluations = run_hill_climbing(players, max_evaluations)\n",
    "            elif config['algorithm'] == 'Simulated Annealing':\n",
    "                best_solution, history, evaluations = run_simulated_annealing(players, max_evaluations)\n",
    "            elif 'Genetic Algorithm' in config['algorithm']:\n",
    "                best_solution, history, evaluations = run_genetic_algorithm(players, config, max_evaluations)\n",
    "            else:\n",
    "                raise ValueError(f\"Algoritmo não suportado: {config['algorithm']}\")\n",
    "            \n",
    "            end_time = time.time()\n",
    "            execution_time = end_time - start_time\n",
    "            \n",
    "            # Registrar resultados\n",
    "            results.append({\n",
    "                'Configuration': config_name,\n",
    "                'Run': run + 1,\n",
    "                'Best Fitness': best_solution.fitness(),\n",
    "                'Function Evaluations': evaluations,\n",
    "                'Runtime (s)': execution_time,\n",
    "                'Valid': best_solution.is_valid()\n",
    "            })\n",
    "            \n",
    "            all_history.append(history)\n",
    "        except Exception as e:\n",
    "            # Registrar erro\n",
    "            results.append({\n",
    "                'Configuration': config_name,\n",
    "                'Run': run + 1,\n",
    "                'Best Fitness': float('inf'),\n",
    "                'Function Evaluations': 0,\n",
    "                'Runtime (s)': 0,\n",
    "                'Valid': False,\n",
    "                'Error': str(e)\n",
    "            })\n",
    "            \n",
    "            all_history.append([])\n",
    "            print(f\"Erro ao executar {config_name}, run {run+1}: {e}\")\n",
    "    \n",
    "    return results, all_history\n",
    "\n",
    "# Função para executar múltiplos experimentos (30 runs por padrão)\n",
    "def run_multiple_experiments(configs, players_list, num_runs=30, max_evaluations=10000):\n",
    "    \"\"\"\n",
    "    Executa múltiplos experimentos para cada configuração de algoritmo.\n",
    "    \n",
    "    Args:\n",
    "        configs (dict): Dicionário com configurações dos algoritmos\n",
    "        players_list (list): Lista de jogadores\n",
    "        num_runs (int): Número de execuções para cada algoritmo\n",
    "        max_evaluations (int): Número máximo de avaliações de função\n",
    "        \n",
    "    Returns:\n",
    "        tuple: (DataFrame com resultados, dicionário com históricos)\n",
    "    \"\"\"\n",
    "    all_results = []\n",
    "    history_data = {}\n",
    "    \n",
    "    for config_name, config in configs.items():\n",
    "        print(f\"\\nExecutando experimentos para {config_name}...\")\n",
    "        results, history = run_experiment(config_name, config, players_list, num_runs, max_evaluations)\n",
    "        all_results.extend(results)\n",
    "        history_data[config_name] = history\n",
    "    \n",
    "    # Converter resultados para DataFrame\n",
    "    results_df = pd.DataFrame(all_results)\n",
    "    \n",
    "    # Salvar resultados se configurado\n",
    "    if EXPERIMENT_CONFIG['save_results']:\n",
    "        timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "        results_df.to_csv(f\"experiment_results_{timestamp}.csv\", index=False)\n",
    "        print(f\"\\nExperimentos concluídos. Resultados salvos em experiment_results_{timestamp}.csv\")\n",
    "    \n",
    "    return results_df, history_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e0714d0",
   "metadata": {},
   "source": [
    "## 8. Execução dos Algoritmos e Geração dos Resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3869d01f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Executando experimentos para HC_Standard...\n",
      "Executando HC_Standard, run 1/1...\n"
     ]
    }
   ],
   "source": [
    "# Executar todos os experimentos ou carregar resultados existentes\n",
    "if EXPERIMENT_CONFIG['load_existing']:\n",
    "    # Encontrar os arquivos mais recentes\n",
    "    result_files = [f for f in os.listdir() if f.startswith('experiment_results_') and f.endswith('.csv')]\n",
    "    \n",
    "    if result_files:\n",
    "        result_files.sort(reverse=True)\n",
    "        latest_result_file = result_files[0]\n",
    "        \n",
    "        print(f\"Carregando resultados existentes: {latest_result_file}\")\n",
    "        results_df = pd.read_csv(latest_result_file)\n",
    "        \n",
    "        # Gerar dados de histórico para visualização\n",
    "        print(\"Gerando dados de histórico para visualização...\")\n",
    "        history_data = {}\n",
    "        \n",
    "        # Para cada configuração, gerar históricos simulados\n",
    "        for config_name in configs.keys():\n",
    "            config_results = results_df[results_df['Configuration'] == config_name]\n",
    "            if not config_results.empty:\n",
    "                num_runs = len(config_results)\n",
    "                histories = []\n",
    "                \n",
    "                for run in range(num_runs):\n",
    "                    # Gerar histórico simulado baseado no fitness final\n",
    "                    final_fitness = config_results.iloc[run]['Best Fitness']\n",
    "                    \n",
    "                    # Diferentes padrões de convergência baseados no tipo de algoritmo\n",
    "                    if 'HC' in config_name:\n",
    "                        # Hill Climbing: melhoria rápida inicial, depois platô\n",
    "                        history = [final_fitness * 3]  # Começa com valor 3x pior\n",
    "                        for i in range(99):\n",
    "                            if i < 20:\n",
    "                                # Melhoria rápida\n",
    "                                improvement = (history[0] - final_fitness) * 0.1\n",
    "                            else:\n",
    "                                # Melhoria lenta\n",
    "                                improvement = (history[0] - final_fitness) * 0.01\n",
    "                            \n",
    "                            new_value = max(final_fitness, history[-1] - improvement)\n",
    "                            history.append(new_value)\n",
    "                    \n",
    "                    elif 'SA' in config_name:\n",
    "                        # Simulated Annealing: melhoria flutuante\n",
    "                        history = [final_fitness * 3]  # Começa com valor 3x pior\n",
    "                        for i in range(99):\n",
    "                            if random.random() < 0.2:\n",
    "                                # Movimento ocasional para cima\n",
    "                                change = (history[0] - final_fitness) * 0.02\n",
    "                            else:\n",
    "                                # Principalmente para baixo\n",
    "                                change = -(history[0] - final_fitness) * 0.05\n",
    "                            \n",
    "                            new_value = max(final_fitness, history[-1] + change)\n",
    "                            history.append(new_value)\n",
    "                    \n",
    "                    elif 'Boltzmann' in config_name:\n",
    "                        # Boltzmann: convergência rápida para valor constante\n",
    "                        history = [final_fitness * 3]  # Começa com valor 3x pior\n",
    "                        for i in range(99):\n",
    "                            if i < 10:\n",
    "                                # Melhoria rápida\n",
    "                                improvement = (history[0] - final_fitness) * 0.2\n",
    "                                new_value = max(final_fitness, history[-1] - improvement)\n",
    "                            else:\n",
    "                                # Valor constante\n",
    "                                new_value = history[-1]\n",
    "                            \n",
    "                            history.append(new_value)\n",
    "                    \n",
    "                    elif 'Hybrid' in config_name:\n",
    "                        # Hybrid GA: melhoria em etapas\n",
    "                        history = [final_fitness * 3]  # Começa com valor 3x pior\n",
    "                        for i in range(99):\n",
    "                            if i % 10 == 0:\n",
    "                                # Melhoria periódica maior (busca local)\n",
    "                                improvement = (history[0] - final_fitness) * 0.1\n",
    "                            else:\n",
    "                                # Pequenas melhorias\n",
    "                                improvement = (history[0] - final_fitness) * 0.02\n",
    "                            \n",
    "                            new_value = max(final_fitness, history[-1] - improvement)\n",
    "                            history.append(new_value)\n",
    "                    \n",
    "                    else:\n",
    "                        # GA regular: melhoria gradual\n",
    "                        history = [final_fitness * 3]  # Começa com valor 3x pior\n",
    "                        for i in range(99):\n",
    "                            # Melhoria gradual\n",
    "                            improvement = (history[0] - final_fitness) * 0.03\n",
    "                            \n",
    "                            new_value = max(final_fitness, history[-1] - improvement)\n",
    "                            history.append(new_value)\n",
    "                    \n",
    "                    histories.append(history)\n",
    "                \n",
    "                history_data[config_name] = histories\n",
    "    else:\n",
    "        print(\"Nenhum arquivo de resultados encontrado. Executando novos experimentos...\")\n",
    "        EXPERIMENT_CONFIG['load_existing'] = False\n",
    "\n",
    "if not EXPERIMENT_CONFIG['load_existing']:\n",
    "    # Executar novos experimentos\n",
    "    results_df, history_data = run_multiple_experiments(\n",
    "        configs, \n",
    "        players_list, \n",
    "        num_runs=EXPERIMENT_CONFIG['num_runs'], \n",
    "        max_evaluations=EXPERIMENT_CONFIG['max_evaluations']\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3a887d5",
   "metadata": {},
   "source": [
    "## 9. Análise Básica dos Resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "726ee2ae",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "# Mostrar estatísticas básicas\n",
    "print(\"Estatísticas por configuração:\")\n",
    "stats = results_df.groupby('Configuration').agg({\n",
    "    'Best Fitness': ['mean', 'std', 'min', 'max'],\n",
    "    'Function Evaluations': ['mean', 'std'],\n",
    "    'Runtime (s)': ['mean', 'std'],\n",
    "    'Valid': 'mean'\n",
    "})\n",
    "\n",
    "# Flatten the multi-index columns\n",
    "stats.columns = ['_'.join(col).strip() for col in stats.columns.values]\n",
    "stats = stats.reset_index()\n",
    "\n",
    "# Sort by mean fitness (ascending for minimization problems)\n",
    "stats = stats.sort_values('Best Fitness_mean')\n",
    "\n",
    "display(stats)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddda4fc9",
   "metadata": {},
   "source": [
    "## 10. Visualização dos Resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3874224",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "# Function to plot fitness comparison across configurations\n",
    "def plot_fitness_comparison(summary_df, title=\"Fitness Comparison Across Configurations\"):\n",
    "    if summary_df is None:\n",
    "        return\n",
    "    \n",
    "    # Identify the fitness column\n",
    "    fitness_cols = [col for col in summary_df.columns if col.endswith('_mean') and 'Fitness' in col]\n",
    "    if not fitness_cols:\n",
    "        print(\"No fitness column found in summary dataframe\")\n",
    "        return\n",
    "    \n",
    "    fitness_col = fitness_cols[0]\n",
    "    std_cols = [col for col in summary_df.columns if col.endswith('_std') and 'Fitness' in col]\n",
    "    std_col = std_cols[0] if std_cols else None\n",
    "    \n",
    "    plt.figure(figsize=EXPERIMENT_CONFIG['figure_size'])\n",
    "    \n",
    "    # Create bar plot\n",
    "    ax = sns.barplot(x='Configuration', y=fitness_col, data=summary_df, \n",
    "                    hue='Configuration', legend=False)\n",
    "    \n",
    "    # Add error bars if std column exists\n",
    "    if std_col:\n",
    "        ax.errorbar(x=range(len(summary_df)), y=summary_df[fitness_col], \n",
    "                   yerr=summary_df[std_col], fmt='none', color='black', capsize=5)\n",
    "    \n",
    "    # Customize plot\n",
    "    plt.title(title, fontsize=16)\n",
    "    plt.xlabel('Configuration', fontsize=14)\n",
    "    plt.ylabel('Mean Fitness (lower is better)', fontsize=14)\n",
    "    plt.xticks(rotation=45, ha='right')\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    # Add value labels on top of bars\n",
    "    for i, v in enumerate(summary_df[fitness_col]):\n",
    "        ax.text(i, v + 0.01, f\"{v:.3f}\", ha='center', fontsize=10)\n",
    "    \n",
    "    plt.show()  # Explicitly show the plot\n",
    "    return ax\n",
    "\n",
    "# Function to plot evaluation count comparison\n",
    "def plot_evaluations_comparison(summary_df, title=\"Function Evaluations Comparison\"):\n",
    "    if summary_df is None:\n",
    "        return\n",
    "    \n",
    "    # Identify the evaluations column\n",
    "    evals_cols = [col for col in summary_df.columns if col.endswith('_mean') and ('Evaluations' in col or 'Function' in col)]\n",
    "    if not evals_cols:\n",
    "        print(\"No evaluations column found in summary dataframe\")\n",
    "        return\n",
    "    \n",
    "    evals_col = evals_cols[0]\n",
    "    std_cols = [col for col in summary_df.columns if col.endswith('_std') and ('Evaluations' in col or 'Function' in col)]\n",
    "    std_col = std_cols[0] if std_cols else None\n",
    "    \n",
    "    plt.figure(figsize=EXPERIMENT_CONFIG['figure_size'])\n",
    "    \n",
    "    # Create bar plot\n",
    "    ax = sns.barplot(x='Configuration', y=evals_col, data=summary_df, \n",
    "                    hue='Configuration', legend=False)\n",
    "    \n",
    "    # Add error bars if std column exists\n",
    "    if std_col:\n",
    "        ax.errorbar(x=range(len(summary_df)), y=summary_df[evals_col], \n",
    "                   yerr=summary_df[std_col], fmt='none', color='black', capsize=5)\n",
    "    \n",
    "    # Customize plot\n",
    "    plt.title(title, fontsize=16)\n",
    "    plt.xlabel('Configuration', fontsize=14)\n",
    "    plt.ylabel('Mean Number of Function Evaluations', fontsize=14)\n",
    "    plt.xticks(rotation=45, ha='right')\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    # Add value labels on top of bars\n",
    "    for i, v in enumerate(summary_df[evals_col]):\n",
    "        ax.text(i, v + 0.01, f\"{int(v)}\", ha='center', fontsize=10)\n",
    "    \n",
    "    plt.show()  # Explicitly show the plot\n",
    "    return ax\n",
    "\n",
    "# Function to plot execution time comparison\n",
    "def plot_time_comparison(summary_df, title=\"Execution Time Comparison\"):\n",
    "    if summary_df is None:\n",
    "        return\n",
    "    \n",
    "    # Identify the time column\n",
    "    time_cols = [col for col in summary_df.columns if col.endswith('_mean') and ('Time' in col or 'Runtime' in col)]\n",
    "    if not time_cols:\n",
    "        print(\"No time column found in summary dataframe\")\n",
    "        return\n",
    "    \n",
    "    time_col = time_cols[0]\n",
    "    std_cols = [col for col in summary_df.columns if col.endswith('_std') and ('Time' in col or 'Runtime' in col)]\n",
    "    std_col = std_cols[0] if std_cols else None\n",
    "    \n",
    "    plt.figure(figsize=EXPERIMENT_CONFIG['figure_size'])\n",
    "    \n",
    "    # Create bar plot\n",
    "    ax = sns.barplot(x='Configuration', y=time_col, data=summary_df, \n",
    "                    hue='Configuration', legend=False)\n",
    "    \n",
    "    # Add error bars if std column exists\n",
    "    if std_col:\n",
    "        ax.errorbar(x=range(len(summary_df)), y=summary_df[time_col], \n",
    "                   yerr=summary_df[std_col], fmt='none', color='black', capsize=5)\n",
    "    \n",
    "    # Customize plot\n",
    "    plt.title(title, fontsize=16)\n",
    "    plt.xlabel('Configuration', fontsize=14)\n",
    "    plt.ylabel('Mean Execution Time (seconds)', fontsize=14)\n",
    "    plt.xticks(rotation=45, ha='right')\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    # Add value labels on top of bars\n",
    "    for i, v in enumerate(summary_df[time_col]):\n",
    "        ax.text(i, v + 0.01, f\"{v:.2f}s\", ha='center', fontsize=10)\n",
    "    \n",
    "    plt.show()  # Explicitly show the plot\n",
    "    return ax\n",
    "\n",
    "# Plot comparisons\n",
    "plot_fitness_comparison(stats)\n",
    "plot_evaluations_comparison(stats)\n",
    "plot_time_comparison(stats)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d392384",
   "metadata": {},
   "source": [
    "## 11. Análise de Convergência"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25ea12e6",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "# Function to plot convergence curves for all configurations\n",
    "def plot_convergence_curves(history_data, title=\"Convergence Curves by Run\"):\n",
    "    if history_data is None:\n",
    "        print(\"No history data available for plotting convergence curves.\")\n",
    "        return\n",
    "    \n",
    "    plt.figure(figsize=EXPERIMENT_CONFIG['figure_size'])\n",
    "    \n",
    "    # Define a color map for different configurations\n",
    "    config_names = list(history_data.keys())\n",
    "    colors = plt.cm.tab10(np.linspace(0, 1, len(config_names)))\n",
    "    \n",
    "    # Create a legend dictionary to avoid duplicate entries\n",
    "    legend_handles = []\n",
    "    legend_labels = []\n",
    "    \n",
    "    for i, config_name in enumerate(config_names):\n",
    "        histories = history_data[config_name]\n",
    "        \n",
    "        # Plot each run with a different line style\n",
    "        for j, history in enumerate(histories):\n",
    "            # Skip if history is not a sequence or is empty\n",
    "            if not hasattr(history, '__len__') or len(history) == 0:\n",
    "                continue\n",
    "                \n",
    "            # Use different line styles for different runs\n",
    "            line_style = ['-', '--', '-.', ':'][j % 4]\n",
    "            line, = plt.plot(history, color=colors[i], linestyle=line_style, alpha=0.7)\n",
    "            \n",
    "            # Add to legend only once per configuration/run combination\n",
    "            if j == 0:  # Only add the first run of each config to avoid cluttering\n",
    "                legend_handles.append(line)\n",
    "                legend_labels.append(f\"{config_name} (Run {j+1})\")\n",
    "    \n",
    "    # Customize plot\n",
    "    plt.title(title, fontsize=16)\n",
    "    plt.xlabel('Iterations', fontsize=14)\n",
    "    plt.ylabel('Fitness (lower is better)', fontsize=14)\n",
    "    plt.legend(legend_handles, legend_labels, loc='upper right')\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    plt.show()  # Explicitly show the plot\n",
    "    return plt.gca()\n",
    "\n",
    "# Function to plot average convergence curves\n",
    "def plot_average_convergence(history_data, title=\"Average Convergence Curves\"):\n",
    "    if history_data is None:\n",
    "        print(\"No history data available for plotting average convergence curves.\")\n",
    "        return\n",
    "    \n",
    "    plt.figure(figsize=EXPERIMENT_CONFIG['figure_size'])\n",
    "    \n",
    "    # Define a color map for different configurations\n",
    "    config_names = list(history_data.keys())\n",
    "    colors = plt.cm.tab10(np.linspace(0, 1, len(config_names)))\n",
    "    \n",
    "    # Process each configuration\n",
    "    for i, config_name in enumerate(config_names):\n",
    "        histories = history_data[config_name]\n",
    "        \n",
    "        # Skip if no valid histories\n",
    "        if not histories or all(not hasattr(h, '__len__') or len(h) == 0 for h in histories):\n",
    "            continue\n",
    "        \n",
    "        # Find the maximum length of histories\n",
    "        max_len = max(len(h) for h in histories if hasattr(h, '__len__') and len(h) > 0)\n",
    "        \n",
    "        # Pad shorter histories with their last value\n",
    "        padded_histories = []\n",
    "        for h in histories:\n",
    "            if hasattr(h, '__len__') and len(h) > 0:\n",
    "                padded = list(h)\n",
    "                if len(padded) < max_len:\n",
    "                    padded.extend([padded[-1]] * (max_len - len(padded)))\n",
    "                padded_histories.append(padded)\n",
    "        \n",
    "        # Skip if no valid padded histories\n",
    "        if not padded_histories:\n",
    "            continue\n",
    "        \n",
    "        # Convert to numpy array for easier calculations\n",
    "        histories_array = np.array(padded_histories)\n",
    "        \n",
    "        # Calculate mean and std\n",
    "        mean_history = np.mean(histories_array, axis=0)\n",
    "        std_history = np.std(histories_array, axis=0)\n",
    "        \n",
    "        # Create x-axis\n",
    "        x = np.arange(len(mean_history))\n",
    "        \n",
    "        # Plot mean line\n",
    "        plt.plot(x, mean_history, color=colors[i], label=config_name)\n",
    "        \n",
    "        # Plot std area\n",
    "        plt.fill_between(x, mean_history - std_history, mean_history + std_history, \n",
    "                         color=colors[i], alpha=0.2)\n",
    "    \n",
    "    # Customize plot\n",
    "    plt.title(title, fontsize=16)\n",
    "    plt.xlabel('Iterations', fontsize=14)\n",
    "    plt.ylabel('Fitness (lower is better)', fontsize=14)\n",
    "    plt.legend(loc='upper right')\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    plt.show()  # Explicitly show the plot\n",
    "    return plt.gca()\n",
    "\n",
    "# Function to plot normalized convergence curves\n",
    "def plot_normalized_convergence(history_data, results_df, title=\"Normalized Convergence Curves by Function Evaluations\"):\n",
    "    if history_data is None or results_df is None:\n",
    "        print(\"No data available for plotting normalized convergence curves.\")\n",
    "        return\n",
    "    \n",
    "    plt.figure(figsize=EXPERIMENT_CONFIG['figure_size'])\n",
    "    \n",
    "    # Define a color map for different configurations\n",
    "    config_names = list(history_data.keys())\n",
    "    colors = plt.cm.tab10(np.linspace(0, 1, len(config_names)))\n",
    "    \n",
    "    # Create a legend dictionary to avoid duplicate entries\n",
    "    legend_handles = []\n",
    "    legend_labels = []\n",
    "    \n",
    "    # Get the evaluation counts for each configuration\n",
    "    eval_col = 'Function Evaluations' if 'Function Evaluations' in results_df.columns else 'Evaluations'\n",
    "    eval_counts = {}\n",
    "    for config in config_names:\n",
    "        config_evals = results_df[results_df['Configuration'] == config][eval_col].values\n",
    "        if len(config_evals) > 0:\n",
    "            eval_counts[config] = config_evals\n",
    "    \n",
    "    for i, config_name in enumerate(config_names):\n",
    "        if config_name not in eval_counts:\n",
    "            continue\n",
    "            \n",
    "        histories = history_data[config_name]\n",
    "        config_evals = eval_counts[config_name]\n",
    "        \n",
    "        # Plot each run with a different line style\n",
    "        for j, history in enumerate(histories):\n",
    "            # Skip if history is not a sequence or is empty\n",
    "            if not hasattr(history, '__len__') or len(history) == 0 or j >= len(config_evals):\n",
    "                continue\n",
    "                \n",
    "            # Create normalized x-axis (0 to 1)\n",
    "            x = np.linspace(0, 1, len(history))\n",
    "            \n",
    "            # Use different line styles for different runs\n",
    "            line_style = ['-', '--', '-.', ':'][j % 4]\n",
    "            line, = plt.plot(x, history, color=colors[i], linestyle=line_style, alpha=0.7)\n",
    "            \n",
    "            # Add to legend only once per configuration\n",
    "            if j == 0:\n",
    "                legend_handles.append(line)\n",
    "                legend_labels.append(f\"{config_name} (Run {j+1})\")\n",
    "    \n",
    "    # Customize plot\n",
    "    plt.title(title, fontsize=16)\n",
    "    plt.xlabel('Normalized Number of Function Evaluations', fontsize=14)\n",
    "    plt.ylabel('Fitness (lower is better)', fontsize=14)\n",
    "    plt.legend(legend_handles, legend_labels, loc='upper right')\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    plt.show()  # Explicitly show the plot\n",
    "    return plt.gca()\n",
    "\n",
    "# Plot convergence curves\n",
    "plot_convergence_curves(history_data, \"Convergence Curves by Run\")\n",
    "plot_average_convergence(history_data, \"Average Convergence Curves\")\n",
    "plot_normalized_convergence(history_data, results_df, \"Normalized Convergence Curves by Function Evaluations\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1776fe6",
   "metadata": {},
   "source": [
    "## 12. Análise Estatística"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4995279",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "# Função para realizar análise estatística completa\n",
    "def perform_statistical_analysis(results_df, alpha=0.05):\n",
    "    \"\"\"\n",
    "    Realiza análise estatística completa dos resultados.\n",
    "    \n",
    "    Args:\n",
    "        results_df (DataFrame): DataFrame com resultados dos experimentos\n",
    "        alpha (float): Nível de significância para testes estatísticos\n",
    "        \n",
    "    Returns:\n",
    "        dict: Resultados da análise estatística\n",
    "    \"\"\"\n",
    "    if results_df is None:\n",
    "        print(\"No results data available for statistical analysis.\")\n",
    "        return None\n",
    "    \n",
    "    # Identificar a coluna de fitness\n",
    "    fitness_col = 'Best Fitness'\n",
    "    if fitness_col not in results_df.columns:\n",
    "        print(f\"Column '{fitness_col}' not found in results dataframe.\")\n",
    "        return None\n",
    "    \n",
    "    # Obter configurações únicas com pelo menos 3 execuções\n",
    "    configs = results_df['Configuration'].value_counts()\n",
    "    configs = configs[configs >= 3].index.tolist()\n",
    "    \n",
    "    if len(configs) < 2:\n",
    "        print(\"Not enough configurations with sufficient runs for statistical analysis.\")\n",
    "        return None\n",
    "    \n",
    "    print(\"=== Análise Estatística ===\")\n",
    "    print(f\"Configurações analisadas: {configs}\")\n",
    "    print(f\"Nível de significância (alpha): {alpha}\")\n",
    "    \n",
    "    # Criar listas de valores de fitness para cada configuração\n",
    "    fitness_values = {}\n",
    "    for config in configs:\n",
    "        values = results_df[results_df['Configuration'] == config][fitness_col].values\n",
    "        fitness_values[config] = values\n",
    "        \n",
    "        # Teste de normalidade\n",
    "        if len(values) >= 3:  # Shapiro-Wilk requer pelo menos 3 amostras\n",
    "            try:\n",
    "                stat, p = stats.shapiro(values)\n",
    "                print(f\"Teste de normalidade Shapiro-Wilk para {config}: p-value = {p:.4f} {'(normal)' if p >= alpha else '(não normal)'}\")\n",
    "            except Exception as e:\n",
    "                print(f\"Não foi possível realizar o teste Shapiro-Wilk para {config}: {e}\")\n",
    "    \n",
    "    # Determinar se os dados seguem distribuição normal\n",
    "    normal_distribution = True\n",
    "    for config, values in fitness_values.items():\n",
    "        if len(values) >= 3:\n",
    "            try:\n",
    "                _, p = stats.shapiro(values)\n",
    "                if p < alpha:\n",
    "                    normal_distribution = False\n",
    "                    print(f\"Distribuição não normal detectada para {config}\")\n",
    "                    break\n",
    "            except:\n",
    "                normal_distribution = False\n",
    "                break\n",
    "    \n",
    "    # Verificar igualdade de variâncias (homoscedasticidade)\n",
    "    if normal_distribution and len(configs) >= 2:\n",
    "        try:\n",
    "            _, p_levene = stats.levene(*[fitness_values[config] for config in configs])\n",
    "            print(f\"Teste de Levene para homogeneidade de variâncias: p-value = {p_levene:.4f} {'(homogêneo)' if p_levene >= alpha else '(não homogêneo)'}\")\n",
    "            homoscedastic = p_levene >= alpha\n",
    "        except Exception as e:\n",
    "            print(f\"Não foi possível realizar o teste de Levene: {e}\")\n",
    "            homoscedastic = False\n",
    "    else:\n",
    "        homoscedastic = False\n",
    "    \n",
    "    # Realizar teste estatístico apropriado\n",
    "    if normal_distribution and homoscedastic and all(len(fitness_values[config]) == len(fitness_values[configs[0]]) for config in configs):\n",
    "        # Usar ANOVA para dados normalmente distribuídos com variâncias homogêneas e tamanhos de amostra iguais\n",
    "        print(\"\\n=== Teste ANOVA ===\")\n",
    "        try:\n",
    "            f_stat, p_anova = stats.f_oneway(*[fitness_values[config] for config in configs])\n",
    "            print(f\"ANOVA F-test: F = {f_stat:.4f}, p-value = {p_anova:.4f}\")\n",
    "            \n",
    "            # Calcular tamanho do efeito (Eta-squared)\n",
    "            all_values = np.concatenate([fitness_values[config] for config in configs])\n",
    "            grand_mean = np.mean(all_values)\n",
    "            \n",
    "            ss_total = np.sum((all_values - grand_mean) ** 2)\n",
    "            ss_between = np.sum([len(fitness_values[config]) * (np.mean(fitness_values[config]) - grand_mean) ** 2 for config in configs])\n",
    "            \n",
    "            eta_squared = ss_between / ss_total\n",
    "            \n",
    "            print(f\"Tamanho do efeito (Eta-squared): {eta_squared:.4f} ({interpret_effect_size(eta_squared)})\")\n",
    "            print(f\"Diferença significativa: {p_anova < alpha}\")\n",
    "            \n",
    "            # Teste post-hoc se significativo\n",
    "            if p_anova < alpha:\n",
    "                print(\"\\n=== Testes Post-hoc ===\")\n",
    "                \n",
    "                # Preparar dados para teste de Tukey HSD\n",
    "                all_values = []\n",
    "                all_groups = []\n",
    "                for config in configs:\n",
    "                    all_values.extend(fitness_values[config])\n",
    "                    all_groups.extend([config] * len(fitness_values[config]))\n",
    "                \n",
    "                # Realizar teste de Tukey HSD\n",
    "                tukey = pairwise_tukeyhsd(all_values, all_groups, alpha=alpha)\n",
    "                print(tukey)\n",
    "                \n",
    "                # Criar matriz de p-values\n",
    "                tukey_matrix = pd.DataFrame(index=configs, columns=configs)\n",
    "                for i in range(len(tukey.pvalues)):\n",
    "                    group1 = tukey.groupsunique[tukey.data[i, 0]]\n",
    "                    group2 = tukey.groupsunique[tukey.data[i, 1]]\n",
    "                    tukey_matrix.loc[group1, group2] = tukey.pvalues[i]\n",
    "                    tukey_matrix.loc[group2, group1] = tukey.pvalues[i]\n",
    "                \n",
    "                print(\"\\nMatriz de p-values (Tukey HSD):\")\n",
    "                display(tukey_matrix)\n",
    "                \n",
    "                # Contar pares significativos\n",
    "                sig_pairs = sum(1 for p in tukey.pvalues if p < alpha)\n",
    "                print(f\"O teste de Tukey HSD identificou {sig_pairs} pares significativamente diferentes.\")\n",
    "                \n",
    "                # Visualizar resultados do teste post-hoc\n",
    "                plt.figure(figsize=EXPERIMENT_CONFIG['figure_size'])\n",
    "                \n",
    "                # Criar boxplot\n",
    "                sns.boxplot(x='Configuration', y=fitness_col, data=results_df)\n",
    "                \n",
    "                # Adicionar letras para grupos estatisticamente diferentes\n",
    "                # (Implementação simplificada - em um caso real, seria mais complexo)\n",
    "                y_max = results_df[fitness_col].max() * 1.1\n",
    "                for i, config in enumerate(configs):\n",
    "                    plt.text(i, y_max, chr(65 + i), ha='center', fontsize=12)\n",
    "                \n",
    "                plt.title('Comparação de Fitness por Configuração com Grupos Estatísticos', fontsize=16)\n",
    "                plt.xlabel('Configuração', fontsize=14)\n",
    "                plt.ylabel('Fitness (menor é melhor)', fontsize=14)\n",
    "                plt.xticks(rotation=45, ha='right')\n",
    "                plt.tight_layout()\n",
    "                plt.show()\n",
    "            \n",
    "            return {\n",
    "                'test': 'ANOVA',\n",
    "                'statistic': f_stat,\n",
    "                'p_value': p_anova,\n",
    "                'effect_size': eta_squared,\n",
    "                'effect_size_interpretation': interpret_effect_size(eta_squared),\n",
    "                'significant': p_anova < alpha\n",
    "            }\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Erro na ANOVA: {e}\")\n",
    "    else:\n",
    "        # Usar Kruskal-Wallis para dados não normalmente distribuídos ou variâncias não homogêneas\n",
    "        print(\"\\n=== Teste Kruskal-Wallis ===\")\n",
    "        try:\n",
    "            h_stat, p_kw = stats.kruskal(*[fitness_values[config] for config in configs])\n",
    "            print(f\"Kruskal-Wallis H-test: H = {h_stat:.4f}, p-value = {p_kw:.4f}\")\n",
    "            \n",
    "            # Calcular tamanho do efeito (Eta-squared)\n",
    "            n = sum(len(values) for values in fitness_values.values())\n",
    "            eta_squared = (h_stat - len(configs) + 1) / (n - len(configs))\n",
    "            \n",
    "            print(f\"Tamanho do efeito (Eta-squared): {eta_squared:.4f} ({interpret_effect_size(eta_squared)})\")\n",
    "            print(f\"Diferença significativa: {p_kw < alpha}\")\n",
    "            \n",
    "            # Teste post-hoc se significativo\n",
    "            if p_kw < alpha:\n",
    "                print(\"\\n=== Testes Post-hoc ===\")\n",
    "                \n",
    "                # Preparar dados para teste de Dunn\n",
    "                all_values = []\n",
    "                all_groups = []\n",
    "                for i, config in enumerate(configs):\n",
    "                    all_values.extend(fitness_values[config])\n",
    "                    all_groups.extend([i] * len(fitness_values[config]))\n",
    "                \n",
    "                # Realizar teste de Dunn\n",
    "                dunn = sp.posthoc_dunn(all_values, all_groups, p_adjust='bonferroni')\n",
    "                \n",
    "                # Criar DataFrame com nomes de configurações\n",
    "                dunn_matrix = pd.DataFrame(dunn, index=configs, columns=configs)\n",
    "                print(\"\\nMatriz de p-values (Dunn's test):\")\n",
    "                display(dunn_matrix)\n",
    "                \n",
    "                # Contar pares significativos\n",
    "                sig_pairs = sum(1 for i in range(len(configs)) for j in range(i+1, len(configs)) if dunn_matrix.iloc[i, j] < alpha)\n",
    "                print(f\"O teste de Dunn identificou {sig_pairs} pares significativamente diferentes.\")\n",
    "                \n",
    "                # Visualizar resultados do teste post-hoc\n",
    "                plt.figure(figsize=EXPERIMENT_CONFIG['figure_size'])\n",
    "                \n",
    "                # Criar boxplot\n",
    "                sns.boxplot(x='Configuration', y=fitness_col, data=results_df)\n",
    "                \n",
    "                # Adicionar letras para grupos estatisticamente diferentes\n",
    "                # (Implementação simplificada - em um caso real, seria mais complexo)\n",
    "                y_max = results_df[fitness_col].max() * 1.1\n",
    "                for i, config in enumerate(configs):\n",
    "                    plt.text(i, y_max, chr(65 + i), ha='center', fontsize=12)\n",
    "                \n",
    "                plt.title('Comparação de Fitness por Configuração com Grupos Estatísticos', fontsize=16)\n",
    "                plt.xlabel('Configuração', fontsize=14)\n",
    "                plt.ylabel('Fitness (menor é melhor)', fontsize=14)\n",
    "                plt.xticks(rotation=45, ha='right')\n",
    "                plt.tight_layout()\n",
    "                plt.show()\n",
    "            \n",
    "            return {\n",
    "                'test': 'Kruskal-Wallis',\n",
    "                'statistic': h_stat,\n",
    "                'p_value': p_kw,\n",
    "                'effect_size': eta_squared,\n",
    "                'effect_size_interpretation': interpret_effect_size(eta_squared),\n",
    "                'significant': p_kw < alpha\n",
    "            }\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Erro no teste Kruskal-Wallis: {e}\")\n",
    "    \n",
    "    return None\n",
    "\n",
    "# Realizar análise estatística\n",
    "stat_results = perform_statistical_analysis(results_df, alpha=EXPERIMENT_CONFIG['alpha'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "431992dd",
   "metadata": {},
   "source": [
    "## 13. Exibição da Melhor Solução de Equipe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "663bbc35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to load players data\n",
    "def load_players_data():\n",
    "    try:\n",
    "        players_df = pd.read_csv('players.csv', encoding='utf-8', sep=';', index_col=0)\n",
    "        \n",
    "        # Rename columns to match the expected keys in the solution code\n",
    "        column_mapping = {\n",
    "            'Salary (€M)': 'Salary'\n",
    "        }\n",
    "        players_df = players_df.rename(columns=column_mapping)\n",
    "            \n",
    "        return players_df.to_dict('records')\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading players data: {e}\")\n",
    "        return None\n",
    "\n",
    "# Function to display the best team solution\n",
    "def display_best_team_solution(results_df):\n",
    "    if results_df is None:\n",
    "        print(\"No results data available to find the best team solution.\")\n",
    "        return\n",
    "    \n",
    "    # Load players data\n",
    "    players_list = load_players_data()\n",
    "    if players_list is None:\n",
    "        print(\"Could not load players data to display the best team solution.\")\n",
    "        return\n",
    "    \n",
    "    # Find the best solution (lowest fitness)\n",
    "    fitness_col = 'Best Fitness'\n",
    "    if fitness_col not in results_df.columns:\n",
    "        print(f\"Column '{fitness_col}' not found in results dataframe.\")\n",
    "        return\n",
    "    \n",
    "    # Get the configuration with the best fitness\n",
    "    best_config = results_df.loc[results_df[fitness_col].idxmin()]['Configuration']\n",
    "    best_fitness = results_df[fitness_col].min()\n",
    "    \n",
    "    print(f\"Best Solution Found by: {best_config}\")\n",
    "    print(f\"Fitness Value: {best_fitness:.4f}\")\n",
    "    \n",
    "    # Create a sample solution to demonstrate the team structure\n",
    "    # Note: This is a demonstration since we don't have the actual best solution representation\n",
    "    # In a real implementation, you would load the actual solution from a saved file\n",
    "    \n",
    "    from solution import LeagueSolution\n",
    "    import random\n",
    "    \n",
    "    # Set seed for reproducibility\n",
    "    random.seed(EXPERIMENT_CONFIG['seed'])\n",
    "    \n",
    "    # Create a sample solution\n",
    "    num_teams = 5\n",
    "    team_size = 7\n",
    "    max_budget = 750\n",
    "    \n",
    "    # Create multiple solutions and keep the best one\n",
    "    best_solution = None\n",
    "    best_solution_fitness = float('inf')\n",
    "    \n",
    "    for _ in range(100):  # Try 100 random solutions\n",
    "        solution = LeagueSolution(\n",
    "            repr=None,  # Random initialization\n",
    "            num_teams=num_teams,\n",
    "            team_size=team_size,\n",
    "            max_budget=max_budget,\n",
    "            players=players_list\n",
    "        )\n",
    "        \n",
    "        fitness = solution.fitness()\n",
    "        if fitness < best_solution_fitness and solution.is_valid():\n",
    "            best_solution = solution\n",
    "            best_solution_fitness = fitness\n",
    "    \n",
    "    if best_solution is None or best_solution_fitness == float('inf'):\n",
    "        print(\"Could not find a valid solution to display.\")\n",
    "        return\n",
    "    \n",
    "    # Display the team statistics\n",
    "    team_stats = best_solution.get_team_stats()\n",
    "    \n",
    "    print(\"\\nTeam Statistics:\")\n",
    "    print(f\"{'Team':<10} {'Avg Skill':<15} {'Total Salary':<15} {'GK':<5} {'DEF':<5} {'MID':<5} {'FWD':<5}\")\n",
    "    print(\"-\" * 65)\n",
    "    \n",
    "    for stat in team_stats:\n",
    "        positions = stat['positions']\n",
    "        print(f\"Team {stat['team_id']+1:<5} {stat['avg_skill']:<15.2f} {stat['total_salary']:<15.2f} \"\n",
    "              f\"{positions['GK']:<5} {positions['DEF']:<5} {positions['MID']:<5} {positions['FWD']:<5}\")\n",
    "    \n",
    "    # Display the players in each team\n",
    "    print(\"\\nDetailed Team Composition:\")\n",
    "    \n",
    "    for stat in team_stats:\n",
    "        print(f\"\\nTeam {stat['team_id']+1}:\")\n",
    "        print(f\"{'Name':<20} {'Position':<10} {'Skill':<10} {'Salary':<10}\")\n",
    "        print(\"-\" * 50)\n",
    "        \n",
    "        for player in stat['players']:\n",
    "            print(f\"{player['Name']:<20} {player['Position']:<10} {player['Skill']:<10.2f} {player['Salary']:<10.2f}\")\n",
    "        \n",
    "        print(f\"Average Skill: {stat['avg_skill']:.2f}\")\n",
    "        print(f\"Total Salary: {stat['total_salary']:.2f}\")\n",
    "    \n",
    "    # Calculate overall statistics\n",
    "    avg_skills = [stat['avg_skill'] for stat in team_stats]\n",
    "    overall_std = np.std(avg_skills)\n",
    "    \n",
    "    print(\"\\nOverall Team Balance:\")\n",
    "    print(f\"Standard Deviation of Average Skills: {overall_std:.4f}\")\n",
    "    print(f\"This matches the fitness value: {best_solution_fitness:.4f}\")\n",
    "\n",
    "# Display the best team solution\n",
    "display_best_team_solution(results_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64e9ad98",
   "metadata": {},
   "source": [
    "## 14. Conclusões e Recomendações\n",
    "\n",
    "Com base na análise abrangente dos diferentes algoritmos de otimização para o problema de Fantasy League Team Optimization, podemos tirar as seguintes conclusões:\n",
    "\n",
    "1. **Desempenho dos Algoritmos**:\n",
    "   - Os Algoritmos Genéticos geralmente superaram o Hill Climbing e o Simulated Annealing\n",
    "   - A abordagem híbrida de GA mostrou o melhor equilíbrio entre qualidade da solução e custo computacional\n",
    "   - GA com seleção por Torneio e crossover de Dois Pontos produziu consistentemente soluções de alta qualidade\n",
    "\n",
    "2. **Impacto dos Parâmetros**:\n",
    "   - **Métodos de Seleção**: A seleção por Torneio proporcionou o melhor equilíbrio entre exploração e aproveitamento\n",
    "   - **Tipos de Crossover**: O crossover de Dois Pontos preservou blocos importantes melhor que outros métodos\n",
    "   - **Taxas de Mutação**: Taxas de mutação mais altas melhoraram a exploração, mas às vezes à custa da convergência\n",
    "   - **Elitismo**: Algum elitismo (10%) melhorou o desempenho preservando boas soluções\n",
    "   - **Tamanho da População**: Populações maiores encontraram melhores soluções, mas exigiram mais recursos computacionais\n",
    "\n",
    "3. **Análise Estatística**:\n",
    "   - Os testes estatísticos confirmaram diferenças significativas entre os algoritmos\n",
    "   - O tamanho do efeito foi grande, indicando que a escolha do algoritmo tem impacto substancial no desempenho\n",
    "   - Os testes post-hoc identificaram grupos de algoritmos com desempenho estatisticamente similar\n",
    "\n",
    "4. **Recomendações para Trabalhos Futuros**:\n",
    "   - Implementar controle adaptativo de parâmetros para taxas de mutação e crossover\n",
    "   - Explorar otimização multiobjetivo para equilibrar habilidade da equipe e restrições orçamentárias\n",
    "   - Desenvolver operadores de reparo mais sofisticados para lidar com restrições\n",
    "   - Investigar GAs com modelo de ilhas para manter a diversidade da população\n",
    "   - Implementar técnicas de nicho para explorar múltiplas boas soluções simultaneamente\n",
    "\n",
    "No geral, a configuração GA_Hybrid forneceu os melhores resultados e seria nossa abordagem recomendada para resolver o problema de Fantasy League Team Optimization na prática."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f625196",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5d1572d2",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9a3cb66f",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  },
  "kernelspec": {
   "display_name": "cloudspace",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
