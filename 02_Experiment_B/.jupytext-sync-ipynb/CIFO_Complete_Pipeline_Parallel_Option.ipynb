{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c86088b1",
   "metadata": {},
   "source": [
    "# CIFO - Complete Pipeline with Configurable Parallel Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bed8afba",
   "metadata": {},
   "source": [
    "## 1. Setup and Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "88979e8a",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import time\n",
    "import random\n",
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import multiprocessing\n",
    "from copy import deepcopy\n",
    "from enum import Enum\n",
    "import json\n",
    "from datetime import datetime\n",
    "import scipy.stats as stats\n",
    "import scikit_posthocs as sp\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "random.seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "# Configure matplotlib for better visualization\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = (14, 10)\n",
    "plt.style.use('ggplot')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31c38072",
   "metadata": {},
   "source": [
    "### 1.1 Execution Mode Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0c5d4cc9",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "# Define execution mode enum\n",
    "class ExecutionMode(Enum):\n",
    "    SINGLE_PROCESSOR = 1  # Sequential execution\n",
    "    MULTI_PROCESSOR = 2   # Parallel execution"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "396d8cd4",
   "metadata": {},
   "source": [
    "### 1.2 Experiment Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e6205ede",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Centralized experiment configuration\n",
    "EXPERIMENT_CONFIG = {\n",
    "    # General parameters\n",
    "    'seed': 42,                    # Seed for reproducibility\n",
    "    'num_runs': 30,                # Number of runs for each algorithm\n",
    "    'max_evaluations': 10000,      # Maximum number of function evaluations\n",
    "    'population_size': 100,        # Population size for genetic algorithms\n",
    "    'max_generations': 100,        # Maximum number of generations for genetic algorithms\n",
    "    \n",
    "    # Execution parameters\n",
    "    'execution_mode': ExecutionMode.SINGLE_PROCESSOR,  # Sequential execution by default\n",
    "    'use_parallel': False,         # Simple flag to enable/disable parallel processing\n",
    "    'num_processes': max(1, multiprocessing.cpu_count() - 1),  # Use all but one CPU core\n",
    "    \n",
    "    # Statistical analysis parameters\n",
    "    'alpha': 0.05,                 # Significance level for statistical tests\n",
    "    'post_hoc_method': 'tukey',    # Post-hoc test method ('tukey' or 'dunn')\n",
    "    \n",
    "    # Visualization parameters\n",
    "    'figure_size': (14, 10),       # Default figure size\n",
    "    'save_figures': False,         # Save figures to files\n",
    "    'figure_format': 'png',        # Format for saving figures\n",
    "    \n",
    "    # Data storage parameters\n",
    "    'save_results': True,          # Save results to files\n",
    "    'save_history': True,          # Save convergence history\n",
    "    'save_statistics': True,       # Save statistical test results\n",
    "    'results_dir': 'experiment_results',  # Directory for storing results\n",
    "    \n",
    "    # Execution parameters\n",
    "    'verbose': True,               # Show detailed progress\n",
    "    'load_existing': False,        # Load existing results (if available)\n",
    "    \n",
    "    # Data handling parameters\n",
    "    'use_simulated_data': False,   # Never use simulated data, only real data\n",
    "}\n",
    "\n",
    "# Update execution mode based on use_parallel flag\n",
    "if EXPERIMENT_CONFIG['use_parallel']:\n",
    "    EXPERIMENT_CONFIG['execution_mode'] = ExecutionMode.MULTI_PROCESSOR\n",
    "else:\n",
    "    EXPERIMENT_CONFIG['execution_mode'] = ExecutionMode.SINGLE_PROCESSOR"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf2424e5",
   "metadata": {},
   "source": [
    "## 2. Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "476d7136",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error loading players.csv: [Errno 2] No such file or directory: 'players.csv'\n"
     ]
    }
   ],
   "source": [
    "# Load player data\n",
    "try:\n",
    "    players_df = pd.read_csv('players.csv', encoding='utf-8', sep=';', index_col=0)\n",
    "    print(f\"Loaded {len(players_df)} players from CSV file.\")\n",
    "except Exception as e:\n",
    "    print(f\"Error loading players.csv: {e}\")\n",
    "    players_df = None\n",
    "\n",
    "# Display first few rows\n",
    "if players_df is not None:\n",
    "    display(players_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a414b617",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert DataFrame to list of dictionaries\n",
    "if players_df is not None:\n",
    "    players_list = players_df.to_dict('records')\n",
    "    \n",
    "    # Rename 'Salary (€M)' to 'Salary' if needed\n",
    "    for player in players_list:\n",
    "        if 'Salary (€M)' in player and 'Salary' not in player:\n",
    "            player['Salary'] = player.pop('Salary (€M)')\n",
    "else:\n",
    "    players_list = []"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55ccd398",
   "metadata": {},
   "source": [
    "## 3. Solution Representation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6c38d35f",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'solution'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Import solution class from solution.py\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msolution\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m LeagueSolution\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'solution'"
     ]
    }
   ],
   "source": [
    "# Import solution class from solution.py\n",
    "from solution import LeagueSolution"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ec9573a",
   "metadata": {},
   "source": [
    "## 4. Fitness Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bbea03a",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "# Import fitness counter from fitness_counter.py\n",
    "from fitness_counter import FitnessCounter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "627e5aa6",
   "metadata": {},
   "source": [
    "## 5. Algorithm Implementations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe5a3671",
   "metadata": {},
   "source": [
    "### 5.1 Hill Climbing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da5726f2",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def run_hill_climbing(solution, max_iterations=1000):\n",
    "    \"\"\"\n",
    "    Run hill climbing algorithm.\n",
    "    \n",
    "    Args:\n",
    "        solution: Initial solution\n",
    "        max_iterations: Maximum number of iterations\n",
    "        \n",
    "    Returns:\n",
    "        tuple: (best_solution, best_fitness, fitness_history)\n",
    "    \"\"\"\n",
    "    best_solution = deepcopy(solution)\n",
    "    best_fitness = solution.fitness()\n",
    "    \n",
    "    fitness_history = [best_fitness]\n",
    "    \n",
    "    for i in range(max_iterations):\n",
    "        # Generate neighbor\n",
    "        neighbor = deepcopy(best_solution)\n",
    "        idx = random.randint(0, len(neighbor.repr) - 1)\n",
    "        neighbor.repr[idx] = random.randint(0, neighbor.num_teams - 1)\n",
    "        \n",
    "        neighbor_fitness = neighbor.fitness()\n",
    "        \n",
    "        # Accept if better\n",
    "        if neighbor_fitness < best_fitness:\n",
    "            best_solution = neighbor\n",
    "            best_fitness = neighbor_fitness\n",
    "            fitness_history.append(best_fitness)\n",
    "        else:\n",
    "            fitness_history.append(best_fitness)\n",
    "    \n",
    "    return best_solution, best_fitness, fitness_history"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c822d95",
   "metadata": {},
   "source": [
    "### 5.2 Hill Climbing with Random Restart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc40e99a",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def run_hill_climbing_random_restart(solution, max_iterations=1000, restart_interval=100):\n",
    "    \"\"\"\n",
    "    Run hill climbing algorithm with random restarts.\n",
    "    \n",
    "    Args:\n",
    "        solution: Initial solution\n",
    "        max_iterations: Maximum number of iterations\n",
    "        restart_interval: Number of iterations between restarts\n",
    "        \n",
    "    Returns:\n",
    "        tuple: (best_solution, best_fitness, fitness_history)\n",
    "    \"\"\"\n",
    "    global_best_solution = deepcopy(solution)\n",
    "    global_best_fitness = solution.fitness()\n",
    "    \n",
    "    current_solution = deepcopy(solution)\n",
    "    current_fitness = global_best_fitness\n",
    "    \n",
    "    fitness_history = [global_best_fitness]\n",
    "    \n",
    "    for i in range(max_iterations):\n",
    "        # Check if restart is needed\n",
    "        if i > 0 and i % restart_interval == 0:\n",
    "            # Random restart\n",
    "            current_solution = LeagueSolution(\n",
    "                players=solution.players,\n",
    "                num_teams=solution.num_teams,\n",
    "                team_size=solution.team_size,\n",
    "                max_budget=solution.max_budget\n",
    "            )\n",
    "            current_solution.set_fitness_counter(solution.fitness_counter)\n",
    "            current_fitness = current_solution.fitness()\n",
    "        \n",
    "        # Generate neighbor\n",
    "        neighbor = deepcopy(current_solution)\n",
    "        idx = random.randint(0, len(neighbor.repr) - 1)\n",
    "        neighbor.repr[idx] = random.randint(0, neighbor.num_teams - 1)\n",
    "        \n",
    "        neighbor_fitness = neighbor.fitness()\n",
    "        \n",
    "        # Accept if better\n",
    "        if neighbor_fitness < current_fitness:\n",
    "            current_solution = neighbor\n",
    "            current_fitness = neighbor_fitness\n",
    "            \n",
    "            # Update global best\n",
    "            if current_fitness < global_best_fitness:\n",
    "                global_best_solution = deepcopy(current_solution)\n",
    "                global_best_fitness = current_fitness\n",
    "        \n",
    "        fitness_history.append(global_best_fitness)\n",
    "    \n",
    "    return global_best_solution, global_best_fitness, fitness_history"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "625f71ae",
   "metadata": {},
   "source": [
    "### 5.3 Simulated Annealing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "617fdf7b",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def run_simulated_annealing(solution, initial_temperature=100, cooling_rate=0.95, max_iterations=1000):\n",
    "    \"\"\"\n",
    "    Run simulated annealing algorithm.\n",
    "    \n",
    "    Args:\n",
    "        solution: Initial solution\n",
    "        initial_temperature: Initial temperature\n",
    "        cooling_rate: Cooling rate\n",
    "        max_iterations: Maximum number of iterations\n",
    "        \n",
    "    Returns:\n",
    "        tuple: (best_solution, best_fitness, fitness_history)\n",
    "    \"\"\"\n",
    "    current_solution = deepcopy(solution)\n",
    "    current_fitness = solution.fitness()\n",
    "    \n",
    "    best_solution = deepcopy(current_solution)\n",
    "    best_fitness = current_fitness\n",
    "    \n",
    "    temperature = initial_temperature\n",
    "    fitness_history = [current_fitness]\n",
    "    \n",
    "    for i in range(max_iterations):\n",
    "        # Generate neighbor\n",
    "        neighbor = deepcopy(current_solution)\n",
    "        idx = random.randint(0, len(neighbor.repr) - 1)\n",
    "        neighbor.repr[idx] = random.randint(0, neighbor.num_teams - 1)\n",
    "        \n",
    "        neighbor_fitness = neighbor.fitness()\n",
    "        \n",
    "        # Calculate acceptance probability\n",
    "        if neighbor_fitness < current_fitness:\n",
    "            acceptance_probability = 1.0\n",
    "        else:\n",
    "            acceptance_probability = math.exp((current_fitness - neighbor_fitness) / temperature)\n",
    "        \n",
    "        # Accept or reject\n",
    "        if random.random() < acceptance_probability:\n",
    "            current_solution = neighbor\n",
    "            current_fitness = neighbor_fitness\n",
    "            \n",
    "            # Update best solution\n",
    "            if current_fitness < best_fitness:\n",
    "                best_solution = deepcopy(current_solution)\n",
    "                best_fitness = current_fitness\n",
    "        \n",
    "        # Cool down\n",
    "        temperature *= cooling_rate\n",
    "        \n",
    "        # Record history\n",
    "        fitness_history.append(best_fitness)\n",
    "    \n",
    "    return best_solution, best_fitness, fitness_history"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98bd7528",
   "metadata": {},
   "source": [
    "### 5.4 Genetic Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6c3c550",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "# Import operators from operators.py\n",
    "from operators import selection_tournament, selection_ranking, selection_boltzmann\n",
    "from operators import crossover_one_point, crossover_two_point, crossover_uniform\n",
    "from operators import mutate_swap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f3fda87",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def run_genetic_algorithm(solution_class, players, selection_func, crossover_func, mutation_func, \n",
    "                         population_size=100, elitism_rate=0.1, tournament_size=3, \n",
    "                         max_generations=100, mutation_rate=None):\n",
    "    \"\"\"\n",
    "    Run genetic algorithm.\n",
    "    \n",
    "    Args:\n",
    "        solution_class: Solution class\n",
    "        players: List of player dictionaries\n",
    "        selection_func: Selection function\n",
    "        crossover_func: Crossover function\n",
    "        mutation_func: Mutation function\n",
    "        population_size: Population size\n",
    "        elitism_rate: Elitism rate\n",
    "        tournament_size: Tournament size (for tournament selection)\n",
    "        max_generations: Maximum number of generations\n",
    "        mutation_rate: Mutation rate\n",
    "        \n",
    "    Returns:\n",
    "        tuple: (best_solution, best_fitness, fitness_history)\n",
    "    \"\"\"\n",
    "    # Initialize population\n",
    "    population = []\n",
    "    for _ in range(population_size):\n",
    "        solution = solution_class(players=players)\n",
    "        population.append(solution)\n",
    "    \n",
    "    # Evaluate initial population\n",
    "    fitness_values = [solution.fitness() for solution in population]\n",
    "    \n",
    "    # Find best solution\n",
    "    best_idx = fitness_values.index(min(fitness_values))\n",
    "    best_solution = deepcopy(population[best_idx])\n",
    "    best_fitness = fitness_values[best_idx]\n",
    "    \n",
    "    fitness_history = [best_fitness]\n",
    "    \n",
    "    # Evolution loop\n",
    "    for generation in range(max_generations):\n",
    "        # Elitism: keep best individuals\n",
    "        elitism_count = int(population_size * elitism_rate)\n",
    "        elite_indices = sorted(range(len(fitness_values)), key=lambda i: fitness_values[i])[:elitism_count]\n",
    "        elite = [deepcopy(population[i]) for i in elite_indices]\n",
    "        \n",
    "        # Create new population\n",
    "        new_population = []\n",
    "        \n",
    "        # Add elite individuals\n",
    "        new_population.extend(elite)\n",
    "        \n",
    "        # Fill the rest with offspring\n",
    "        while len(new_population) < population_size:\n",
    "            # Selection\n",
    "            if selection_func == selection_tournament:\n",
    "                parent1_idx = selection_func(fitness_values, tournament_size)\n",
    "                parent2_idx = selection_func(fitness_values, tournament_size)\n",
    "            else:\n",
    "                parent1_idx = selection_func(fitness_values)\n",
    "                parent2_idx = selection_func(fitness_values)\n",
    "            \n",
    "            parent1 = population[parent1_idx]\n",
    "            parent2 = population[parent2_idx]\n",
    "            \n",
    "            # Crossover\n",
    "            child = crossover_func(parent1, parent2)\n",
    "            \n",
    "            # Mutation\n",
    "            child = mutation_func(child, mutation_rate)\n",
    "            \n",
    "            new_population.append(child)\n",
    "        \n",
    "        # Replace population\n",
    "        population = new_population\n",
    "        \n",
    "        # Evaluate new population\n",
    "        fitness_values = [solution.fitness() for solution in population]\n",
    "        \n",
    "        # Update best solution\n",
    "        current_best_idx = fitness_values.index(min(fitness_values))\n",
    "        current_best_fitness = fitness_values[current_best_idx]\n",
    "        \n",
    "        if current_best_fitness < best_fitness:\n",
    "            best_solution = deepcopy(population[current_best_idx])\n",
    "            best_fitness = current_best_fitness\n",
    "        \n",
    "        # Record history\n",
    "        fitness_history.append(best_fitness)\n",
    "    \n",
    "    return best_solution, best_fitness, fitness_history"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbe24229",
   "metadata": {},
   "source": [
    "### 5.5 GA Hybrid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f354a59",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def run_hybrid_ga(solution_class, players, selection_func, crossover_func, mutation_func, \n",
    "                 population_size=100, elitism_rate=0.1, tournament_size=3, \n",
    "                 max_generations=100, mutation_rate=None, local_search_interval=10):\n",
    "    \"\"\"\n",
    "    Run hybrid genetic algorithm with occasional local search.\n",
    "    \n",
    "    Args:\n",
    "        solution_class: Solution class\n",
    "        players: List of player dictionaries\n",
    "        selection_func: Selection function\n",
    "        crossover_func: Crossover function\n",
    "        mutation_func: Mutation function\n",
    "        population_size: Population size\n",
    "        elitism_rate: Elitism rate\n",
    "        tournament_size: Tournament size (for tournament selection)\n",
    "        max_generations: Maximum number of generations\n",
    "        mutation_rate: Mutation rate\n",
    "        local_search_interval: Number of generations between local search\n",
    "        \n",
    "    Returns:\n",
    "        tuple: (best_solution, best_fitness, fitness_history)\n",
    "    \"\"\"\n",
    "    # Initialize population\n",
    "    population = []\n",
    "    for _ in range(population_size):\n",
    "        solution = solution_class(players=players)\n",
    "        population.append(solution)\n",
    "    \n",
    "    # Evaluate initial population\n",
    "    fitness_values = [solution.fitness() for solution in population]\n",
    "    \n",
    "    # Find best solution\n",
    "    best_idx = fitness_values.index(min(fitness_values))\n",
    "    best_solution = deepcopy(population[best_idx])\n",
    "    best_fitness = fitness_values[best_idx]\n",
    "    \n",
    "    fitness_history = [best_fitness]\n",
    "    \n",
    "    # Evolution loop\n",
    "    for generation in range(max_generations):\n",
    "        # Elitism: keep best individuals\n",
    "        elitism_count = int(population_size * elitism_rate)\n",
    "        elite_indices = sorted(range(len(fitness_values)), key=lambda i: fitness_values[i])[:elitism_count]\n",
    "        elite = [deepcopy(population[i]) for i in elite_indices]\n",
    "        \n",
    "        # Create new population\n",
    "        new_population = []\n",
    "        \n",
    "        # Add elite individuals\n",
    "        new_population.extend(elite)\n",
    "        \n",
    "        # Fill the rest with offspring\n",
    "        while len(new_population) < population_size:\n",
    "            # Selection\n",
    "            if selection_func == selection_tournament:\n",
    "                parent1_idx = selection_func(fitness_values, tournament_size)\n",
    "                parent2_idx = selection_func(fitness_values, tournament_size)\n",
    "            else:\n",
    "                parent1_idx = selection_func(fitness_values)\n",
    "                parent2_idx = selection_func(fitness_values)\n",
    "            \n",
    "            parent1 = population[parent1_idx]\n",
    "            parent2 = population[parent2_idx]\n",
    "            \n",
    "            # Crossover\n",
    "            child = crossover_func(parent1, parent2)\n",
    "            \n",
    "            # Mutation\n",
    "            child = mutation_func(child, mutation_rate)\n",
    "            \n",
    "            new_population.append(child)\n",
    "        \n",
    "        # Replace population\n",
    "        population = new_population\n",
    "        \n",
    "        # Local search on best individual every local_search_interval generations\n",
    "        if generation % local_search_interval == 0:\n",
    "            # Find best individual\n",
    "            fitness_values = [solution.fitness() for solution in population]\n",
    "            best_idx = fitness_values.index(min(fitness_values))\n",
    "            \n",
    "            # Apply local search\n",
    "            improved_solution = deepcopy(population[best_idx])\n",
    "            \n",
    "            # Simple hill climbing for local search\n",
    "            for _ in range(10):  # 10 iterations of local search\n",
    "                neighbor = deepcopy(improved_solution)\n",
    "                idx = random.randint(0, len(neighbor.repr) - 1)\n",
    "                neighbor.repr[idx] = random.randint(0, neighbor.num_teams - 1)\n",
    "                \n",
    "                neighbor_fitness = neighbor.fitness()\n",
    "                current_fitness = improved_solution.fitness()\n",
    "                \n",
    "                if neighbor_fitness < current_fitness:\n",
    "                    improved_solution = neighbor\n",
    "            \n",
    "            # Replace original solution with improved one\n",
    "            population[best_idx] = improved_solution\n",
    "        \n",
    "        # Evaluate new population\n",
    "        fitness_values = [solution.fitness() for solution in population]\n",
    "        \n",
    "        # Update best solution\n",
    "        current_best_idx = fitness_values.index(min(fitness_values))\n",
    "        current_best_fitness = fitness_values[current_best_idx]\n",
    "        \n",
    "        if current_best_fitness < best_fitness:\n",
    "            best_solution = deepcopy(population[current_best_idx])\n",
    "            best_fitness = current_best_fitness\n",
    "        \n",
    "        # Record history\n",
    "        fitness_history.append(best_fitness)\n",
    "    \n",
    "    return best_solution, best_fitness, fitness_history"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fcc4d64",
   "metadata": {},
   "source": [
    "### 5.6 GA Memetic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da4208f0",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def run_memetic_algorithm(solution_class, players, selection_func, crossover_func, mutation_func, \n",
    "                         population_size=100, elitism_rate=0.1, tournament_size=3, \n",
    "                         max_generations=100, mutation_rate=None, \n",
    "                         local_search_prob=0.1, local_search_iterations=10):\n",
    "    \"\"\"\n",
    "    Run memetic algorithm (GA with local search).\n",
    "    \n",
    "    Args:\n",
    "        solution_class: Solution class\n",
    "        players: List of player dictionaries\n",
    "        selection_func: Selection function\n",
    "        crossover_func: Crossover function\n",
    "        mutation_func: Mutation function\n",
    "        population_size: Population size\n",
    "        elitism_rate: Elitism rate\n",
    "        tournament_size: Tournament size (for tournament selection)\n",
    "        max_generations: Maximum number of generations\n",
    "        mutation_rate: Mutation rate\n",
    "        local_search_prob: Probability of applying local search\n",
    "        local_search_iterations: Number of local search iterations\n",
    "        \n",
    "    Returns:\n",
    "        tuple: (best_solution, best_fitness, fitness_history)\n",
    "    \"\"\"\n",
    "    # Local search function\n",
    "    def local_search(solution, iterations):\n",
    "        \"\"\"\n",
    "        Local search to improve a solution through hill climbing.\n",
    "        \n",
    "        Args:\n",
    "            solution: Solution to improve\n",
    "            iterations: Number of local search iterations\n",
    "            \n",
    "        Returns:\n",
    "            Improved solution\n",
    "        \"\"\"\n",
    "        best_sol = deepcopy(solution)\n",
    "        best_fitness = solution.fitness()\n",
    "        \n",
    "        for _ in range(iterations):\n",
    "            # Generate neighbor\n",
    "            neighbor = deepcopy(best_sol)\n",
    "            idx = random.randint(0, len(neighbor.repr) - 1)\n",
    "            neighbor.repr[idx] = random.randint(0, neighbor.num_teams - 1)\n",
    "            \n",
    "            neighbor_fitness = neighbor.fitness()\n",
    "            \n",
    "            # Accept if better\n",
    "            if neighbor_fitness < best_fitness:\n",
    "                best_sol = neighbor\n",
    "                best_fitness = neighbor_fitness\n",
    "        \n",
    "        return best_sol\n",
    "    \n",
    "    # Initialize population\n",
    "    population = []\n",
    "    for _ in range(population_size):\n",
    "        solution = solution_class(players=players)\n",
    "        population.append(solution)\n",
    "    \n",
    "    # Evaluate initial population\n",
    "    fitness_values = [solution.fitness() for solution in population]\n",
    "    \n",
    "    # Find best solution\n",
    "    best_idx = fitness_values.index(min(fitness_values))\n",
    "    best_solution = deepcopy(population[best_idx])\n",
    "    best_fitness = fitness_values[best_idx]\n",
    "    \n",
    "    fitness_history = [best_fitness]\n",
    "    \n",
    "    # Evolution loop\n",
    "    for generation in range(max_generations):\n",
    "        # Elitism: keep best individuals\n",
    "        elitism_count = int(population_size * elitism_rate)\n",
    "        elite_indices = sorted(range(len(fitness_values)), key=lambda i: fitness_values[i])[:elitism_count]\n",
    "        elite = [deepcopy(population[i]) for i in elite_indices]\n",
    "        \n",
    "        # Create new population\n",
    "        new_population = []\n",
    "        \n",
    "        # Add elite individuals\n",
    "        new_population.extend(elite)\n",
    "        \n",
    "        # Fill the rest with offspring\n",
    "        while len(new_population) < population_size:\n",
    "            # Selection\n",
    "            if selection_func == selection_tournament:\n",
    "                parent1_idx = selection_func(fitness_values, tournament_size)\n",
    "                parent2_idx = selection_func(fitness_values, tournament_size)\n",
    "            else:\n",
    "                parent1_idx = selection_func(fitness_values)\n",
    "                parent2_idx = selection_func(fitness_values)\n",
    "            \n",
    "            parent1 = population[parent1_idx]\n",
    "            parent2 = population[parent2_idx]\n",
    "            \n",
    "            # Crossover\n",
    "            child = crossover_func(parent1, parent2)\n",
    "            \n",
    "            # Mutation\n",
    "            child = mutation_func(child, mutation_rate)\n",
    "            \n",
    "            # Local search with probability local_search_prob\n",
    "            if random.random() < local_search_prob:\n",
    "                child = local_search(child, local_search_iterations)\n",
    "            \n",
    "            new_population.append(child)\n",
    "        \n",
    "        # Replace population\n",
    "        population = new_population\n",
    "        \n",
    "        # Evaluate new population\n",
    "        fitness_values = [solution.fitness() for solution in population]\n",
    "        \n",
    "        # Update best solution\n",
    "        current_best_idx = fitness_values.index(min(fitness_values))\n",
    "        current_best_fitness = fitness_values[current_best_idx]\n",
    "        \n",
    "        if current_best_fitness < best_fitness:\n",
    "            best_solution = deepcopy(population[current_best_idx])\n",
    "            best_fitness = current_best_fitness\n",
    "        \n",
    "        # Record history\n",
    "        fitness_history.append(best_fitness)\n",
    "    \n",
    "    return best_solution, best_fitness, fitness_history"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5fec54b",
   "metadata": {},
   "source": [
    "### 5.7 GA Island Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "283061ae",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def run_island_model_ga(solution_class, players, selection_func, crossover_func, mutation_func, \n",
    "                       population_size=100, elitism_rate=0.1, tournament_size=3, \n",
    "                       max_generations=100, mutation_rate=None, \n",
    "                       num_islands=5, migration_interval=10, migration_size=5):\n",
    "    \"\"\"\n",
    "    Run island model genetic algorithm.\n",
    "    \n",
    "    Args:\n",
    "        solution_class: Solution class\n",
    "        players: List of player dictionaries\n",
    "        selection_func: Selection function\n",
    "        crossover_func: Crossover function\n",
    "        mutation_func: Mutation function\n",
    "        population_size: Population size\n",
    "        elitism_rate: Elitism rate\n",
    "        tournament_size: Tournament size (for tournament selection)\n",
    "        max_generations: Maximum number of generations\n",
    "        mutation_rate: Mutation rate\n",
    "        num_islands: Number of islands\n",
    "        migration_interval: Number of generations between migrations\n",
    "        migration_size: Number of individuals to migrate\n",
    "        \n",
    "    Returns:\n",
    "        tuple: (best_solution, best_fitness, fitness_history)\n",
    "    \"\"\"\n",
    "    # Initialize islands\n",
    "    islands = []\n",
    "    island_fitness = []\n",
    "    \n",
    "    for _ in range(num_islands):\n",
    "        # Initialize population for each island\n",
    "        island = []\n",
    "        for _ in range(population_size // num_islands):\n",
    "            solution = solution_class(players=players)\n",
    "            island.append(solution)\n",
    "        \n",
    "        islands.append(island)\n",
    "        island_fitness.append([solution.fitness() for solution in island])\n",
    "    \n",
    "    # Find best solution across all islands\n",
    "    best_solution = None\n",
    "    best_fitness = float('inf')\n",
    "    \n",
    "    for i in range(num_islands):\n",
    "        island_best_idx = island_fitness[i].index(min(island_fitness[i]))\n",
    "        if island_fitness[i][island_best_idx] < best_fitness:\n",
    "            best_solution = deepcopy(islands[i][island_best_idx])\n",
    "            best_fitness = island_fitness[i][island_best_idx]\n",
    "    \n",
    "    fitness_history = [best_fitness]\n",
    "    \n",
    "    # Evolution loop\n",
    "    for generation in range(max_generations):\n",
    "        # Evolve each island independently\n",
    "        for i in range(num_islands):\n",
    "            island_pop = islands[i]\n",
    "            island_fit = island_fitness[i]\n",
    "            \n",
    "            # Elitism: keep best individuals\n",
    "            elitism_count = int(len(island_pop) * elitism_rate)\n",
    "            elite_indices = sorted(range(len(island_fit)), key=lambda j: island_fit[j])[:elitism_count]\n",
    "            elite = [deepcopy(island_pop[j]) for j in elite_indices]\n",
    "            \n",
    "            # Create new population\n",
    "            new_population = []\n",
    "            \n",
    "            # Add elite individuals\n",
    "            new_population.extend(elite)\n",
    "            \n",
    "            # Fill the rest with offspring\n",
    "            while len(new_population) < len(island_pop):\n",
    "                # Selection\n",
    "                if selection_func == selection_tournament:\n",
    "                    parent1_idx = selection_func(island_fit, tournament_size)\n",
    "                    parent2_idx = selection_func(island_fit, tournament_size)\n",
    "                else:\n",
    "                    parent1_idx = selection_func(island_fit)\n",
    "                    parent2_idx = selection_func(island_fit)\n",
    "                \n",
    "                parent1 = island_pop[parent1_idx]\n",
    "                parent2 = island_pop[parent2_idx]\n",
    "                \n",
    "                # Crossover\n",
    "                child = crossover_func(parent1, parent2)\n",
    "                \n",
    "                # Mutation\n",
    "                child = mutation_func(child, mutation_rate)\n",
    "                \n",
    "                new_population.append(child)\n",
    "            \n",
    "            # Replace population\n",
    "            islands[i] = new_population\n",
    "            \n",
    "            # Evaluate new population\n",
    "            island_fitness[i] = [solution.fitness() for solution in islands[i]]\n",
    "        \n",
    "        # Migration between islands\n",
    "        if generation % migration_interval == 0 and generation > 0:\n",
    "            for i in range(num_islands):\n",
    "                # Select migrants (best individuals)\n",
    "                migrant_indices = np.argsort(island_fitness[i])[:migration_size]\n",
    "                migrants = [deepcopy(islands[i][idx]) for idx in migrant_indices]\n",
    "                \n",
    "                # Send to next island (ring topology)\n",
    "                next_island = (i + 1) % num_islands\n",
    "                \n",
    "                # Replace worst individuals in next island\n",
    "                worst_indices = np.argsort(island_fitness[next_island])[-migration_size:]\n",
    "                for j, idx in enumerate(worst_indices):\n",
    "                    islands[next_island][idx] = migrants[j]\n",
    "                \n",
    "                # Re-evaluate fitness of next island\n",
    "                island_fitness[next_island] = [solution.fitness() for solution in islands[next_island]]\n",
    "        \n",
    "        # Update best solution across all islands\n",
    "        for i in range(num_islands):\n",
    "            island_best_idx = island_fitness[i].index(min(island_fitness[i]))\n",
    "            if island_fitness[i][island_best_idx] < best_fitness:\n",
    "                best_solution = deepcopy(islands[i][island_best_idx])\n",
    "                best_fitness = island_fitness[i][island_best_idx]\n",
    "        \n",
    "        # Record history\n",
    "        fitness_history.append(best_fitness)\n",
    "    \n",
    "    return best_solution, best_fitness, fitness_history"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ec95c42",
   "metadata": {},
   "source": [
    "### 5.8 GA with Scramble Mutation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af5e3b88",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def mutate_scramble(solution, mutation_rate=0.1):\n",
    "    \"\"\"\n",
    "    Scramble mutation: randomly selects a subsequence and shuffles it.\n",
    "    \n",
    "    Args:\n",
    "        solution: Solution to mutate\n",
    "        mutation_rate: Probability of mutation\n",
    "        \n",
    "    Returns:\n",
    "        Mutated solution\n",
    "    \"\"\"\n",
    "    mutated = deepcopy(solution)\n",
    "    \n",
    "    # Determine if mutation occurs based on rate\n",
    "    if random.random() < mutation_rate:\n",
    "        # Select random subsequence\n",
    "        length = len(mutated.repr)\n",
    "        start = random.randint(0, length - 2)\n",
    "        end = random.randint(start + 1, length - 1)\n",
    "        \n",
    "        # Extract subsequence\n",
    "        subsequence = mutated.repr[start:end+1]\n",
    "        \n",
    "        # Shuffle subsequence\n",
    "        random.shuffle(subsequence)\n",
    "        \n",
    "        # Replace original subsequence with shuffled one\n",
    "        mutated.repr[start:end+1] = subsequence\n",
    "    \n",
    "    return mutated"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33495d70",
   "metadata": {},
   "source": [
    "## 6. Algorithm Configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "611cbed7",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "# Define algorithm configurations\n",
    "configs = {\n",
    "    \"HC_Standard\": {\n",
    "        \"algorithm\": \"hill_climbing\",\n",
    "        \"max_iterations\": 10000,\n",
    "    },\n",
    "    \"HC_Random_Restart\": {\n",
    "        \"algorithm\": \"hill_climbing_random_restart\",\n",
    "        \"max_iterations\": 10000,\n",
    "        \"restart_interval\": 100,\n",
    "    },\n",
    "    \"SA_Standard\": {\n",
    "        \"algorithm\": \"simulated_annealing\",\n",
    "        \"initial_temperature\": 100,\n",
    "        \"cooling_rate\": 0.95,\n",
    "        \"max_iterations\": 10000,\n",
    "    },\n",
    "    \"GA_Tournament_OnePoint\": {\n",
    "        \"algorithm\": \"genetic_algorithm\",\n",
    "        \"selection\": \"tournament\",\n",
    "        \"crossover\": \"one_point\",\n",
    "        \"mutation\": \"swap\",\n",
    "        \"population_size\": 100,\n",
    "        \"elitism_rate\": 0.1,\n",
    "        \"tournament_size\": 3,\n",
    "        \"max_generations\": 100,\n",
    "    },\n",
    "    \"GA_Tournament_TwoPoint\": {\n",
    "        \"algorithm\": \"genetic_algorithm\",\n",
    "        \"selection\": \"tournament\",\n",
    "        \"crossover\": \"two_point\",\n",
    "        \"mutation\": \"swap\",\n",
    "        \"population_size\": 100,\n",
    "        \"elitism_rate\": 0.1,\n",
    "        \"tournament_size\": 3,\n",
    "        \"max_generations\": 100,\n",
    "    },\n",
    "    \"GA_Rank_Uniform\": {\n",
    "        \"algorithm\": \"genetic_algorithm\",\n",
    "        \"selection\": \"rank\",\n",
    "        \"crossover\": \"uniform\",\n",
    "        \"mutation\": \"swap\",\n",
    "        \"population_size\": 100,\n",
    "        \"elitism_rate\": 0.1,\n",
    "        \"max_generations\": 100,\n",
    "    },\n",
    "    \"GA_Boltzmann_TwoPoint\": {\n",
    "        \"algorithm\": \"genetic_algorithm\",\n",
    "        \"selection\": \"boltzmann\",\n",
    "        \"crossover\": \"two_point\",\n",
    "        \"mutation\": \"swap\",\n",
    "        \"population_size\": 100,\n",
    "        \"elitism_rate\": 0.1,\n",
    "        \"max_generations\": 100,\n",
    "    },\n",
    "    \"GA_Hybrid\": {\n",
    "        \"algorithm\": \"hybrid_ga\",\n",
    "        \"selection\": \"tournament\",\n",
    "        \"crossover\": \"two_point\",\n",
    "        \"mutation\": \"swap\",\n",
    "        \"population_size\": 100,\n",
    "        \"elitism_rate\": 0.1,\n",
    "        \"tournament_size\": 3,\n",
    "        \"max_generations\": 100,\n",
    "        \"local_search_interval\": 10,\n",
    "    },\n",
    "    \"GA_Memetic\": {\n",
    "        \"algorithm\": \"memetic_algorithm\",\n",
    "        \"selection\": \"tournament\",\n",
    "        \"crossover\": \"two_point\",\n",
    "        \"mutation\": \"swap\",\n",
    "        \"population_size\": 100,\n",
    "        \"elitism_rate\": 0.1,\n",
    "        \"tournament_size\": 3,\n",
    "        \"max_generations\": 100,\n",
    "        \"local_search_prob\": 0.1,\n",
    "        \"local_search_iterations\": 10,\n",
    "    },\n",
    "    \"GA_Island_Model\": {\n",
    "        \"algorithm\": \"island_model_ga\",\n",
    "        \"selection\": \"tournament\",\n",
    "        \"crossover\": \"two_point\",\n",
    "        \"mutation\": \"swap\",\n",
    "        \"population_size\": 100,\n",
    "        \"elitism_rate\": 0.1,\n",
    "        \"tournament_size\": 3,\n",
    "        \"max_generations\": 100,\n",
    "        \"num_islands\": 5,\n",
    "        \"migration_interval\": 10,\n",
    "        \"migration_size\": 5,\n",
    "    },\n",
    "    \"GA_Scramble_Mutation\": {\n",
    "        \"algorithm\": \"genetic_algorithm\",\n",
    "        \"selection\": \"tournament\",\n",
    "        \"crossover\": \"two_point\",\n",
    "        \"mutation\": \"scramble\",\n",
    "        \"population_size\": 100,\n",
    "        \"elitism_rate\": 0.1,\n",
    "        \"tournament_size\": 3,\n",
    "        \"max_generations\": 100,\n",
    "    },\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52c060ed",
   "metadata": {},
   "source": [
    "## 7. Experiment Execution"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1e3c445",
   "metadata": {},
   "source": [
    "### 7.1 Single Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f56746f2",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def run_experiment(config, players_list, max_evaluations=10000):\n",
    "    \"\"\"\n",
    "    Run a single experiment with the specified configuration.\n",
    "    \n",
    "    Args:\n",
    "        config: Algorithm configuration\n",
    "        players_list: List of player dictionaries\n",
    "        max_evaluations: Maximum number of function evaluations\n",
    "        \n",
    "    Returns:\n",
    "        tuple: (best_solution, best_fitness, evaluations, runtime, fitness_history)\n",
    "    \"\"\"\n",
    "    # Create fitness counter\n",
    "    fitness_counter = FitnessCounter()\n",
    "    \n",
    "    # Create initial solution\n",
    "    solution = LeagueSolution(\n",
    "        players=players_list,\n",
    "        num_teams=5,\n",
    "        team_size=7,\n",
    "        max_budget=750\n",
    "    )\n",
    "    solution.set_fitness_counter(fitness_counter)\n",
    "    \n",
    "    # Start timer\n",
    "    start_time = time.time()\n",
    "    \n",
    "    # Run algorithm\n",
    "    if config[\"algorithm\"] == \"hill_climbing\":\n",
    "        best_solution, best_fitness, fitness_history = run_hill_climbing(\n",
    "            solution=solution,\n",
    "            max_iterations=config[\"max_iterations\"]\n",
    "        )\n",
    "    \n",
    "    elif config[\"algorithm\"] == \"hill_climbing_random_restart\":\n",
    "        best_solution, best_fitness, fitness_history = run_hill_climbing_random_restart(\n",
    "            solution=solution,\n",
    "            max_iterations=config[\"max_iterations\"],\n",
    "            restart_interval=config[\"restart_interval\"]\n",
    "        )\n",
    "    \n",
    "    elif config[\"algorithm\"] == \"simulated_annealing\":\n",
    "        best_solution, best_fitness, fitness_history = run_simulated_annealing(\n",
    "            solution=solution,\n",
    "            initial_temperature=config[\"initial_temperature\"],\n",
    "            cooling_rate=config[\"cooling_rate\"],\n",
    "            max_iterations=config[\"max_iterations\"]\n",
    "        )\n",
    "    \n",
    "    elif config[\"algorithm\"] == \"genetic_algorithm\":\n",
    "        # Select operators\n",
    "        if config[\"selection\"] == \"tournament\":\n",
    "            selection_func = selection_tournament\n",
    "        elif config[\"selection\"] == \"rank\":\n",
    "            selection_func = selection_ranking\n",
    "        elif config[\"selection\"] == \"boltzmann\":\n",
    "            selection_func = selection_boltzmann\n",
    "        else:\n",
    "            selection_func = selection_tournament\n",
    "        \n",
    "        if config[\"crossover\"] == \"one_point\":\n",
    "            crossover_func = crossover_one_point\n",
    "        elif config[\"crossover\"] == \"two_point\":\n",
    "            crossover_func = crossover_two_point\n",
    "        elif config[\"crossover\"] == \"uniform\":\n",
    "            crossover_func = crossover_uniform\n",
    "        else:\n",
    "            crossover_func = crossover_one_point\n",
    "        \n",
    "        if config[\"mutation\"] == \"swap\":\n",
    "            mutation_func = mutate_swap\n",
    "        elif config[\"mutation\"] == \"scramble\":\n",
    "            mutation_func = mutate_scramble\n",
    "        else:\n",
    "            mutation_func = mutate_swap\n",
    "        \n",
    "        best_solution, best_fitness, fitness_history = run_genetic_algorithm(\n",
    "            solution_class=LeagueSolution,\n",
    "            players=players_list,\n",
    "            selection_func=selection_func,\n",
    "            crossover_func=crossover_func,\n",
    "            mutation_func=mutation_func,\n",
    "            population_size=config[\"population_size\"],\n",
    "            elitism_rate=config[\"elitism_rate\"],\n",
    "            tournament_size=config.get(\"tournament_size\", 3),\n",
    "            max_generations=config[\"max_generations\"]\n",
    "        )\n",
    "    \n",
    "    elif config[\"algorithm\"] == \"hybrid_ga\":\n",
    "        # Select operators\n",
    "        if config[\"selection\"] == \"tournament\":\n",
    "            selection_func = selection_tournament\n",
    "        elif config[\"selection\"] == \"rank\":\n",
    "            selection_func = selection_ranking\n",
    "        elif config[\"selection\"] == \"boltzmann\":\n",
    "            selection_func = selection_boltzmann\n",
    "        else:\n",
    "            selection_func = selection_tournament\n",
    "        \n",
    "        if config[\"crossover\"] == \"one_point\":\n",
    "            crossover_func = crossover_one_point\n",
    "        elif config[\"crossover\"] == \"two_point\":\n",
    "            crossover_func = crossover_two_point\n",
    "        elif config[\"crossover\"] == \"uniform\":\n",
    "            crossover_func = crossover_uniform\n",
    "        else:\n",
    "            crossover_func = crossover_one_point\n",
    "        \n",
    "        if config[\"mutation\"] == \"swap\":\n",
    "            mutation_func = mutate_swap\n",
    "        elif config[\"mutation\"] == \"scramble\":\n",
    "            mutation_func = mutate_scramble\n",
    "        else:\n",
    "            mutation_func = mutate_swap\n",
    "        \n",
    "        best_solution, best_fitness, fitness_history = run_hybrid_ga(\n",
    "            solution_class=LeagueSolution,\n",
    "            players=players_list,\n",
    "            selection_func=selection_func,\n",
    "            crossover_func=crossover_func,\n",
    "            mutation_func=mutation_func,\n",
    "            population_size=config[\"population_size\"],\n",
    "            elitism_rate=config[\"elitism_rate\"],\n",
    "            tournament_size=config.get(\"tournament_size\", 3),\n",
    "            max_generations=config[\"max_generations\"],\n",
    "            local_search_interval=config[\"local_search_interval\"]\n",
    "        )\n",
    "    \n",
    "    elif config[\"algorithm\"] == \"memetic_algorithm\":\n",
    "        # Select operators\n",
    "        if config[\"selection\"] == \"tournament\":\n",
    "            selection_func = selection_tournament\n",
    "        elif config[\"selection\"] == \"rank\":\n",
    "            selection_func = selection_ranking\n",
    "        elif config[\"selection\"] == \"boltzmann\":\n",
    "            selection_func = selection_boltzmann\n",
    "        else:\n",
    "            selection_func = selection_tournament\n",
    "        \n",
    "        if config[\"crossover\"] == \"one_point\":\n",
    "            crossover_func = crossover_one_point\n",
    "        elif config[\"crossover\"] == \"two_point\":\n",
    "            crossover_func = crossover_two_point\n",
    "        elif config[\"crossover\"] == \"uniform\":\n",
    "            crossover_func = crossover_uniform\n",
    "        else:\n",
    "            crossover_func = crossover_one_point\n",
    "        \n",
    "        if config[\"mutation\"] == \"swap\":\n",
    "            mutation_func = mutate_swap\n",
    "        elif config[\"mutation\"] == \"scramble\":\n",
    "            mutation_func = mutate_scramble\n",
    "        else:\n",
    "            mutation_func = mutate_swap\n",
    "        \n",
    "        best_solution, best_fitness, fitness_history = run_memetic_algorithm(\n",
    "            solution_class=LeagueSolution,\n",
    "            players=players_list,\n",
    "            selection_func=selection_func,\n",
    "            crossover_func=crossover_func,\n",
    "            mutation_func=mutation_func,\n",
    "            population_size=config[\"population_size\"],\n",
    "            elitism_rate=config[\"elitism_rate\"],\n",
    "            tournament_size=config.get(\"tournament_size\", 3),\n",
    "            max_generations=config[\"max_generations\"],\n",
    "            local_search_prob=config[\"local_search_prob\"],\n",
    "            local_search_iterations=config[\"local_search_iterations\"]\n",
    "        )\n",
    "    \n",
    "    elif config[\"algorithm\"] == \"island_model_ga\":\n",
    "        # Select operators\n",
    "        if config[\"selection\"] == \"tournament\":\n",
    "            selection_func = selection_tournament\n",
    "        elif config[\"selection\"] == \"rank\":\n",
    "            selection_func = selection_ranking\n",
    "        elif config[\"selection\"] == \"boltzmann\":\n",
    "            selection_func = selection_boltzmann\n",
    "        else:\n",
    "            selection_func = selection_tournament\n",
    "        \n",
    "        if config[\"crossover\"] == \"one_point\":\n",
    "            crossover_func = crossover_one_point\n",
    "        elif config[\"crossover\"] == \"two_point\":\n",
    "            crossover_func = crossover_two_point\n",
    "        elif config[\"crossover\"] == \"uniform\":\n",
    "            crossover_func = crossover_uniform\n",
    "        else:\n",
    "            crossover_func = crossover_one_point\n",
    "        \n",
    "        if config[\"mutation\"] == \"swap\":\n",
    "            mutation_func = mutate_swap\n",
    "        elif config[\"mutation\"] == \"scramble\":\n",
    "            mutation_func = mutate_scramble\n",
    "        else:\n",
    "            mutation_func = mutate_swap\n",
    "        \n",
    "        best_solution, best_fitness, fitness_history = run_island_model_ga(\n",
    "            solution_class=LeagueSolution,\n",
    "            players=players_list,\n",
    "            selection_func=selection_func,\n",
    "            crossover_func=crossover_func,\n",
    "            mutation_func=mutation_func,\n",
    "            population_size=config[\"population_size\"],\n",
    "            elitism_rate=config[\"elitism_rate\"],\n",
    "            tournament_size=config.get(\"tournament_size\", 3),\n",
    "            max_generations=config[\"max_generations\"],\n",
    "            num_islands=config[\"num_islands\"],\n",
    "            migration_interval=config[\"migration_interval\"],\n",
    "            migration_size=config[\"migration_size\"]\n",
    "        )\n",
    "    \n",
    "    else:\n",
    "        raise ValueError(f\"Unknown algorithm: {config['algorithm']}\")\n",
    "    \n",
    "    # End timer\n",
    "    end_time = time.time()\n",
    "    runtime = end_time - start_time\n",
    "    \n",
    "    # Get number of evaluations\n",
    "    evaluations = fitness_counter.get_count()\n",
    "    \n",
    "    return best_solution, best_fitness, evaluations, runtime, fitness_history"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84dbe623",
   "metadata": {},
   "source": [
    "### 7.2 Multiple Experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d61d673",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def run_single_experiment(config_name, config, players_list, max_evaluations, run):\n",
    "    \"\"\"\n",
    "    Run a single experiment for parallel execution.\n",
    "    \n",
    "    Args:\n",
    "        config_name: Name of the configuration\n",
    "        config: Algorithm configuration\n",
    "        players_list: List of player dictionaries\n",
    "        max_evaluations: Maximum number of function evaluations\n",
    "        run: Run number\n",
    "        \n",
    "    Returns:\n",
    "        tuple: (config_name, run, best_fitness, evaluations, runtime, history)\n",
    "    \"\"\"\n",
    "    if EXPERIMENT_CONFIG['verbose']:\n",
    "        print(f\"Running {config_name} - Run {run+1}/{EXPERIMENT_CONFIG['num_runs']}...\")\n",
    "    \n",
    "    best_solution, best_fitness, evaluations, runtime, history = run_experiment(\n",
    "        config=config,\n",
    "        players_list=players_list,\n",
    "        max_evaluations=max_evaluations\n",
    "    )\n",
    "    \n",
    "    return config_name, run, best_fitness, evaluations, runtime, history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e96f9da",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def run_multiple_experiments(configs, players_list, num_runs=30, max_evaluations=10000):\n",
    "    \"\"\"\n",
    "    Run multiple experiments for each configuration.\n",
    "    \n",
    "    Args:\n",
    "        configs: Dictionary of algorithm configurations\n",
    "        players_list: List of player dictionaries\n",
    "        num_runs: Number of runs for each configuration\n",
    "        max_evaluations: Maximum number of function evaluations\n",
    "        \n",
    "    Returns:\n",
    "        tuple: (results_df, history_data)\n",
    "    \"\"\"\n",
    "    all_results = []\n",
    "    history_data = {}\n",
    "    \n",
    "    for config_name, config in configs.items():\n",
    "        if EXPERIMENT_CONFIG['verbose']:\n",
    "            print(f\"\\nRunning {config_name}...\")\n",
    "        \n",
    "        history_data[config_name] = {}\n",
    "        \n",
    "        for run in range(num_runs):\n",
    "            if EXPERIMENT_CONFIG['verbose']:\n",
    "                print(f\"  Run {run+1}/{num_runs}...\")\n",
    "            \n",
    "            best_solution, best_fitness, evaluations, runtime, history = run_experiment(\n",
    "                config=config,\n",
    "                players_list=players_list,\n",
    "                max_evaluations=max_evaluations\n",
    "            )\n",
    "            \n",
    "            all_results.append({\n",
    "                'Configuration': config_name,\n",
    "                'Run': run,\n",
    "                'Best Fitness': best_fitness,\n",
    "                'Evaluations': evaluations,\n",
    "                'Runtime (s)': runtime\n",
    "            })\n",
    "            \n",
    "            history_data[config_name][run] = history\n",
    "    \n",
    "    # Convert to DataFrame\n",
    "    results_df = pd.DataFrame(all_results)\n",
    "    \n",
    "    return results_df, history_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f487ca8",
   "metadata": {},
   "source": [
    "### 7.3 Parallel Experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3de4fa84",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def run_parallel_experiments(configs, players_list, num_runs=30, max_evaluations=10000, num_processes=None):\n",
    "    \"\"\"\n",
    "    Run multiple experiments in parallel.\n",
    "    \n",
    "    Args:\n",
    "        configs: Dictionary of algorithm configurations\n",
    "        players_list: List of player dictionaries\n",
    "        num_runs: Number of runs for each configuration\n",
    "        max_evaluations: Maximum number of function evaluations\n",
    "        num_processes: Number of processes to use\n",
    "        \n",
    "    Returns:\n",
    "        tuple: (results_df, history_data)\n",
    "    \"\"\"\n",
    "    if num_processes is None:\n",
    "        num_processes = EXPERIMENT_CONFIG['num_processes']\n",
    "    \n",
    "    if EXPERIMENT_CONFIG['verbose']:\n",
    "        print(f\"Running experiments in parallel with {num_processes} processes...\")\n",
    "    \n",
    "    # Create experiment tasks\n",
    "    tasks = []\n",
    "    for config_name, config in configs.items():\n",
    "        for run in range(num_runs):\n",
    "            tasks.append((config_name, config, players_list, max_evaluations, run))\n",
    "    \n",
    "    # Run experiments in parallel\n",
    "    with multiprocessing.Pool(processes=num_processes) as pool:\n",
    "        results = pool.starmap(run_single_experiment, tasks)\n",
    "    \n",
    "    # Process results\n",
    "    all_results = []\n",
    "    history_data = {}\n",
    "    \n",
    "    for config_name, run, best_fitness, evaluations, runtime, history in results:\n",
    "        all_results.append({\n",
    "            'Configuration': config_name,\n",
    "            'Run': run,\n",
    "            'Best Fitness': best_fitness,\n",
    "            'Evaluations': evaluations,\n",
    "            'Runtime (s)': runtime\n",
    "        })\n",
    "        \n",
    "        # Store history data\n",
    "        if config_name not in history_data:\n",
    "            history_data[config_name] = {}\n",
    "        \n",
    "        history_data[config_name][run] = history\n",
    "    \n",
    "    # Convert to DataFrame\n",
    "    results_df = pd.DataFrame(all_results)\n",
    "    \n",
    "    return results_df, history_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9a33d81",
   "metadata": {},
   "source": [
    "### 7.4 Save and Load Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70ce1d23",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def save_results(results_df, history_data, experiment_dir):\n",
    "    \"\"\"\n",
    "    Save experiment results to files.\n",
    "    \n",
    "    Args:\n",
    "        results_df: DataFrame with experiment results\n",
    "        history_data: Dictionary with convergence history\n",
    "        experiment_dir: Directory to save results\n",
    "    \"\"\"\n",
    "    # Create directory if it doesn't exist\n",
    "    os.makedirs(experiment_dir, exist_ok=True)\n",
    "    \n",
    "    # Save results CSV\n",
    "    results_path = os.path.join(experiment_dir, \"results.csv\")\n",
    "    results_df.to_csv(results_path, index=False)\n",
    "    \n",
    "    # Save history data\n",
    "    history_path = os.path.join(experiment_dir, \"history_data.npy\")\n",
    "    np.save(history_path, history_data)\n",
    "    \n",
    "    # Save statistics\n",
    "    if EXPERIMENT_CONFIG['save_statistics']:\n",
    "        # Calculate statistics\n",
    "        stats_results = analyze_results(results_df)\n",
    "        \n",
    "        # Save to JSON\n",
    "        stats_path = os.path.join(experiment_dir, \"stats_results.json\")\n",
    "        with open(stats_path, 'w') as f:\n",
    "            json.dump(stats_results, f, indent=4)\n",
    "    \n",
    "    if EXPERIMENT_CONFIG['verbose']:\n",
    "        print(f\"Results saved to: {experiment_dir}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b0a7be0",
   "metadata": {},
   "source": [
    "## 8. Run Experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c736675",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create results directory if it doesn't exist\n",
    "if not os.path.exists(EXPERIMENT_CONFIG['results_dir']):\n",
    "    os.makedirs(EXPERIMENT_CONFIG['results_dir'])\n",
    "\n",
    "# Create experiment directory with timestamp\n",
    "timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "experiment_dir = os.path.join(EXPERIMENT_CONFIG['results_dir'], f\"experiment_{timestamp}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ed15139",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "# Run all experiments or load existing results\n",
    "if EXPERIMENT_CONFIG['load_existing']:\n",
    "    # Find the most recent results\n",
    "    experiment_dirs = [d for d in os.listdir(EXPERIMENT_CONFIG['results_dir']) \n",
    "                      if os.path.isdir(os.path.join(EXPERIMENT_CONFIG['results_dir'], d)) \n",
    "                      and d.startswith('experiment_')]\n",
    "    \n",
    "    if experiment_dirs:\n",
    "        experiment_dirs.sort(reverse=True)\n",
    "        latest_dir = os.path.join(EXPERIMENT_CONFIG['results_dir'], experiment_dirs[0])\n",
    "        \n",
    "        print(f\"Loading existing results from: {latest_dir}\")\n",
    "        \n",
    "        # Load results CSV\n",
    "        results_path = os.path.join(latest_dir, \"results.csv\")\n",
    "        if os.path.exists(results_path):\n",
    "            results_df = pd.read_csv(results_path)\n",
    "        else:\n",
    "            print(f\"Results file not found: {results_path}\")\n",
    "            EXPERIMENT_CONFIG['load_existing'] = False\n",
    "        \n",
    "        # Load history data\n",
    "        history_path = os.path.join(latest_dir, \"history_data.npy\")\n",
    "        if os.path.exists(history_path):\n",
    "            history_data = np.load(history_path, allow_pickle=True).item()\n",
    "        else:\n",
    "            print(f\"History data file not found: {history_path}\")\n",
    "            EXPERIMENT_CONFIG['load_existing'] = False\n",
    "    else:\n",
    "        print(\"No existing results found. Running new experiments...\")\n",
    "        EXPERIMENT_CONFIG['load_existing'] = False\n",
    "\n",
    "if not EXPERIMENT_CONFIG['load_existing']:\n",
    "    # Run new experiments\n",
    "    if EXPERIMENT_CONFIG['execution_mode'] == ExecutionMode.MULTI_PROCESSOR:\n",
    "        # Run in parallel\n",
    "        results_df, history_data = run_parallel_experiments(\n",
    "            configs, \n",
    "            players_list, \n",
    "            num_runs=EXPERIMENT_CONFIG['num_runs'], \n",
    "            max_evaluations=EXPERIMENT_CONFIG['max_evaluations'],\n",
    "            num_processes=EXPERIMENT_CONFIG['num_processes']\n",
    "        )\n",
    "    else:\n",
    "        # Run sequentially\n",
    "        results_df, history_data = run_multiple_experiments(\n",
    "            configs, \n",
    "            players_list, \n",
    "            num_runs=EXPERIMENT_CONFIG['num_runs'], \n",
    "            max_evaluations=EXPERIMENT_CONFIG['max_evaluations']\n",
    "        )\n",
    "    \n",
    "    # Save results\n",
    "    if EXPERIMENT_CONFIG['save_results']:\n",
    "        save_results(results_df, history_data, experiment_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4bae7b8",
   "metadata": {},
   "source": [
    "## 9. Results Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aeb7adb5",
   "metadata": {},
   "source": [
    "### 9.1 Statistical Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8bb8893",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def test_normality(results_df):\n",
    "    \"\"\"\n",
    "    Test normality of fitness values for each configuration.\n",
    "    \n",
    "    Args:\n",
    "        results_df: DataFrame with experiment results\n",
    "        \n",
    "    Returns:\n",
    "        dict: Dictionary with normality test results\n",
    "    \"\"\"\n",
    "    normality_results = {}\n",
    "    \n",
    "    for config_name in results_df['Configuration'].unique():\n",
    "        config_results = results_df[results_df['Configuration'] == config_name]\n",
    "        fitness_values = config_results['Best Fitness'].values\n",
    "        \n",
    "        # Shapiro-Wilk test\n",
    "        statistic, p_value = stats.shapiro(fitness_values)\n",
    "        \n",
    "        normality_results[config_name] = {\n",
    "            'statistic': statistic,\n",
    "            'p_value': p_value,\n",
    "            'normal': p_value > EXPERIMENT_CONFIG['alpha']\n",
    "        }\n",
    "    \n",
    "    return normality_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f0110ad",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def test_homogeneity(results_df):\n",
    "    \"\"\"\n",
    "    Test homogeneity of variances.\n",
    "    \n",
    "    Args:\n",
    "        results_df: DataFrame with experiment results\n",
    "        \n",
    "    Returns:\n",
    "        dict: Dictionary with homogeneity test results\n",
    "    \"\"\"\n",
    "    # Group data by configuration\n",
    "    groups = []\n",
    "    group_names = []\n",
    "    \n",
    "    for config_name in results_df['Configuration'].unique():\n",
    "        config_results = results_df[results_df['Configuration'] == config_name]\n",
    "        groups.append(config_results['Best Fitness'].values)\n",
    "        group_names.append(config_name)\n",
    "    \n",
    "    # Levene's test\n",
    "    statistic, p_value = stats.levene(*groups)\n",
    "    \n",
    "    return {\n",
    "        'statistic': statistic,\n",
    "        'p_value': p_value,\n",
    "        'homogeneous': p_value > EXPERIMENT_CONFIG['alpha'],\n",
    "        'group_names': group_names\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ce76198",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def perform_anova(results_df):\n",
    "    \"\"\"\n",
    "    Perform ANOVA test to compare configurations.\n",
    "    \n",
    "    Args:\n",
    "        results_df: DataFrame with experiment results\n",
    "        \n",
    "    Returns:\n",
    "        dict: Dictionary with ANOVA test results\n",
    "    \"\"\"\n",
    "    # Group data by configuration\n",
    "    groups = []\n",
    "    group_names = []\n",
    "    \n",
    "    for config_name in results_df['Configuration'].unique():\n",
    "        config_results = results_df[results_df['Configuration'] == config_name]\n",
    "        groups.append(config_results['Best Fitness'].values)\n",
    "        group_names.append(config_name)\n",
    "    \n",
    "    # Perform ANOVA\n",
    "    statistic, p_value = stats.f_oneway(*groups)\n",
    "    \n",
    "    # Perform post-hoc test if ANOVA is significant\n",
    "    post_hoc_results = None\n",
    "    \n",
    "    if p_value < EXPERIMENT_CONFIG['alpha']:\n",
    "        if EXPERIMENT_CONFIG['post_hoc_method'] == 'tukey':\n",
    "            # Tukey HSD test\n",
    "            post_hoc_results = stats.tukey_hsd(*groups)\n",
    "        else:\n",
    "            # Default to Tukey HSD\n",
    "            post_hoc_results = stats.tukey_hsd(*groups)\n",
    "    \n",
    "    return {\n",
    "        'statistic': statistic,\n",
    "        'p_value': p_value,\n",
    "        'significant': p_value < EXPERIMENT_CONFIG['alpha'],\n",
    "        'post_hoc': post_hoc_results,\n",
    "        'group_names': group_names\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c07e94b6",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def perform_kruskal(results_df):\n",
    "    \"\"\"\n",
    "    Perform Kruskal-Wallis test to compare configurations.\n",
    "    \n",
    "    Args:\n",
    "        results_df: DataFrame with experiment results\n",
    "        \n",
    "    Returns:\n",
    "        dict: Dictionary with Kruskal-Wallis test results\n",
    "    \"\"\"\n",
    "    # Group data by configuration\n",
    "    groups = []\n",
    "    group_names = []\n",
    "    \n",
    "    for config_name in results_df['Configuration'].unique():\n",
    "        config_results = results_df[results_df['Configuration'] == config_name]\n",
    "        groups.append(config_results['Best Fitness'].values)\n",
    "        group_names.append(config_name)\n",
    "    \n",
    "    # Perform Kruskal-Wallis test\n",
    "    statistic, p_value = stats.kruskal(*groups)\n",
    "    \n",
    "    # Perform post-hoc test if Kruskal-Wallis is significant\n",
    "    post_hoc_results = None\n",
    "    \n",
    "    if p_value < EXPERIMENT_CONFIG['alpha']:\n",
    "        # Dunn's test\n",
    "        post_hoc_results = sp.posthoc_dunn(results_df, val_col='Best Fitness', group_col='Configuration', p_adjust='bonferroni')\n",
    "    \n",
    "    return {\n",
    "        'statistic': statistic,\n",
    "        'p_value': p_value,\n",
    "        'significant': p_value < EXPERIMENT_CONFIG['alpha'],\n",
    "        'post_hoc': post_hoc_results.to_dict() if post_hoc_results is not None else None,\n",
    "        'group_names': group_names\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57fbbed4",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def calculate_effect_size(results_df):\n",
    "    \"\"\"\n",
    "    Calculate effect size (eta squared) for the difference between configurations.\n",
    "    \n",
    "    Args:\n",
    "        results_df: DataFrame with experiment results\n",
    "        \n",
    "    Returns:\n",
    "        float: Effect size\n",
    "    \"\"\"\n",
    "    # Group data by configuration\n",
    "    groups = []\n",
    "    \n",
    "    for config_name in results_df['Configuration'].unique():\n",
    "        config_results = results_df[results_df['Configuration'] == config_name]\n",
    "        groups.append(config_results['Best Fitness'].values)\n",
    "    \n",
    "    # Calculate eta squared\n",
    "    # Formula: SSB / SST\n",
    "    # SSB = sum of squares between groups\n",
    "    # SST = total sum of squares\n",
    "    \n",
    "    # Calculate grand mean\n",
    "    all_values = np.concatenate(groups)\n",
    "    grand_mean = np.mean(all_values)\n",
    "    \n",
    "    # Calculate SSB\n",
    "    ssb = sum(len(group) * (np.mean(group) - grand_mean) ** 2 for group in groups)\n",
    "    \n",
    "    # Calculate SST\n",
    "    sst = sum((x - grand_mean) ** 2 for x in all_values)\n",
    "    \n",
    "    # Calculate eta squared\n",
    "    eta_squared = ssb / sst if sst > 0 else 0\n",
    "    \n",
    "    # Interpret effect size\n",
    "    if eta_squared < 0.01:\n",
    "        interpretation = \"Very small effect\"\n",
    "    elif eta_squared < 0.06:\n",
    "        interpretation = \"Small effect\"\n",
    "    elif eta_squared < 0.14:\n",
    "        interpretation = \"Medium effect\"\n",
    "    else:\n",
    "        interpretation = \"Large effect\"\n",
    "    \n",
    "    return {\n",
    "        'eta_squared': eta_squared,\n",
    "        'interpretation': interpretation\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a2ea15d",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def analyze_results(results_df):\n",
    "    \"\"\"\n",
    "    Analyze experiment results and perform statistical tests.\n",
    "    \n",
    "    Args:\n",
    "        results_df: DataFrame with experiment results\n",
    "        \n",
    "    Returns:\n",
    "        dict: Dictionary with analysis results\n",
    "    \"\"\"\n",
    "    # Test normality\n",
    "    normality_results = test_normality(results_df)\n",
    "    \n",
    "    # Check if all configurations have normal distribution\n",
    "    all_normal = all(result['normal'] for result in normality_results.values())\n",
    "    \n",
    "    # Test homogeneity of variances\n",
    "    homogeneity_results = test_homogeneity(results_df)\n",
    "    \n",
    "    # Perform appropriate statistical test\n",
    "    if all_normal and homogeneity_results['homogeneous']:\n",
    "        # Parametric test: ANOVA\n",
    "        test_results = perform_anova(results_df)\n",
    "        test_type = \"ANOVA\"\n",
    "    else:\n",
    "        # Non-parametric test: Kruskal-Wallis\n",
    "        test_results = perform_kruskal(results_df)\n",
    "        test_type = \"Kruskal-Wallis\"\n",
    "    \n",
    "    # Calculate effect size\n",
    "    effect_size = calculate_effect_size(results_df)\n",
    "    \n",
    "    return {\n",
    "        'normality': normality_results,\n",
    "        'homogeneity': homogeneity_results,\n",
    "        'test_type': test_type,\n",
    "        'test_results': test_results,\n",
    "        'effect_size': effect_size\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc7667d9",
   "metadata": {},
   "source": [
    "### 9.2 Performance Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be425f82",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def plot_performance_comparison(results_df):\n",
    "    \"\"\"\n",
    "    Plot performance comparison across all configurations.\n",
    "    \n",
    "    Args:\n",
    "        results_df: DataFrame with experiment results\n",
    "    \"\"\"\n",
    "    # Calculate mean and standard deviation for each configuration\n",
    "    summary = results_df.groupby('Configuration').agg({\n",
    "        'Best Fitness': ['mean', 'std'],\n",
    "        'Evaluations': ['mean', 'std'],\n",
    "        'Runtime (s)': ['mean', 'std']\n",
    "    })\n",
    "    \n",
    "    # Reset index for easier plotting\n",
    "    summary = summary.reset_index()\n",
    "    \n",
    "    # Create figure with subplots\n",
    "    fig, axes = plt.subplots(1, 3, figsize=EXPERIMENT_CONFIG['figure_size'])\n",
    "    \n",
    "    # Plot best fitness\n",
    "    axes[0].bar(summary['Configuration'], summary[('Best Fitness', 'mean')], yerr=summary[('Best Fitness', 'std')])\n",
    "    axes[0].set_title('Best Fitness (lower is better)')\n",
    "    axes[0].set_xlabel('Configuration')\n",
    "    axes[0].set_ylabel('Fitness Value')\n",
    "    axes[0].tick_params(axis='x', rotation=90)\n",
    "    axes[0].grid(axis='y', alpha=0.3)\n",
    "    \n",
    "    # Plot evaluations\n",
    "    axes[1].bar(summary['Configuration'], summary[('Evaluations', 'mean')], yerr=summary[('Evaluations', 'std')])\n",
    "    axes[1].set_title('Function Evaluations')\n",
    "    axes[1].set_xlabel('Configuration')\n",
    "    axes[1].set_ylabel('Number of Evaluations')\n",
    "    axes[1].tick_params(axis='x', rotation=90)\n",
    "    axes[1].grid(axis='y', alpha=0.3)\n",
    "    \n",
    "    # Plot runtime\n",
    "    axes[2].bar(summary['Configuration'], summary[('Runtime (s)', 'mean')], yerr=summary[('Runtime (s)', 'std')])\n",
    "    axes[2].set_title('Runtime')\n",
    "    axes[2].set_xlabel('Configuration')\n",
    "    axes[2].set_ylabel('Runtime (seconds)')\n",
    "    axes[2].tick_params(axis='x', rotation=90)\n",
    "    axes[2].grid(axis='y', alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    return fig"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9020acef",
   "metadata": {},
   "source": [
    "### 9.3 Convergence Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01998e97",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def plot_convergence_curves(history_data, title=\"Convergence Curves by Run\"):\n",
    "    \"\"\"\n",
    "    Plot convergence curves for all configurations.\n",
    "    \n",
    "    Args:\n",
    "        history_data: Dictionary with convergence history\n",
    "        title: Plot title\n",
    "    \"\"\"\n",
    "    if history_data is None or len(history_data) == 0:\n",
    "        print(\"No history data available for plotting convergence curves.\")\n",
    "        return None\n",
    "    \n",
    "    plt.figure(figsize=EXPERIMENT_CONFIG['figure_size'])\n",
    "    \n",
    "    # Define a color map for different configurations\n",
    "    config_names = list(history_data.keys())\n",
    "    colors = plt.cm.tab10(np.linspace(0, 1, len(config_names)))\n",
    "    \n",
    "    # Create a legend dictionary to avoid duplicate entries\n",
    "    legend_handles = []\n",
    "    legend_labels = []\n",
    "    \n",
    "    for i, config_name in enumerate(config_names):\n",
    "        histories = history_data[config_name]\n",
    "        \n",
    "        # Plot each run with a different line style\n",
    "        for j, run in enumerate(histories.keys()):\n",
    "            history = histories[run]\n",
    "            \n",
    "            # Skip if history is not a sequence or is empty\n",
    "            if not hasattr(history, '__len__') or len(history) == 0:\n",
    "                continue\n",
    "                \n",
    "            # Use different line styles for different runs\n",
    "            line_style = ['-', '--', '-.', ':'][j % 4]\n",
    "            line, = plt.plot(history, color=colors[i], linestyle=line_style, alpha=0.7)\n",
    "            \n",
    "            # Add to legend only once per configuration/run combination\n",
    "            if j == 0:  # Only add the first run of each config to avoid cluttering\n",
    "                legend_handles.append(line)\n",
    "                legend_labels.append(f\"{config_name} (Run {j+1})\")\n",
    "    \n",
    "    # Customize plot\n",
    "    plt.title(title, fontsize=16)\n",
    "    plt.xlabel('Iterations', fontsize=14)\n",
    "    plt.ylabel('Fitness (lower is better)', fontsize=14)\n",
    "    plt.legend(legend_handles, legend_labels, loc='upper right')\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    plt.show()\n",
    "    \n",
    "    return plt.gcf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42d3833e",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def plot_average_convergence(history_data, title=\"Average Convergence Curves\"):\n",
    "    \"\"\"\n",
    "    Plot average convergence curves for all configurations.\n",
    "    \n",
    "    Args:\n",
    "        history_data: Dictionary with convergence history\n",
    "        title: Plot title\n",
    "    \"\"\"\n",
    "    if history_data is None or len(history_data) == 0:\n",
    "        print(\"No history data available for plotting average convergence curves.\")\n",
    "        return None\n",
    "    \n",
    "    plt.figure(figsize=EXPERIMENT_CONFIG['figure_size'])\n",
    "    \n",
    "    # Define a color map for different configurations\n",
    "    config_names = list(history_data.keys())\n",
    "    colors = plt.cm.tab10(np.linspace(0, 1, len(config_names)))\n",
    "    \n",
    "    for i, config_name in enumerate(config_names):\n",
    "        histories = history_data[config_name]\n",
    "        \n",
    "        # Check if histories is empty\n",
    "        if not histories:\n",
    "            continue\n",
    "        \n",
    "        # Find the minimum length of all histories\n",
    "        min_length = min(len(histories[run]) for run in histories.keys() if hasattr(histories[run], '__len__') and len(histories[run]) > 0)\n",
    "        \n",
    "        if min_length == 0:\n",
    "            continue\n",
    "        \n",
    "        # Truncate all histories to the minimum length\n",
    "        truncated_histories = [histories[run][:min_length] for run in histories.keys() if hasattr(histories[run], '__len__') and len(histories[run]) >= min_length]\n",
    "        \n",
    "        if not truncated_histories:\n",
    "            continue\n",
    "        \n",
    "        # Calculate mean and standard deviation\n",
    "        mean_history = np.mean(truncated_histories, axis=0)\n",
    "        std_history = np.std(truncated_histories, axis=0)\n",
    "        \n",
    "        # Plot mean with standard deviation band\n",
    "        x = np.arange(min_length)\n",
    "        plt.plot(x, mean_history, color=colors[i], label=config_name)\n",
    "        plt.fill_between(x, mean_history - std_history, mean_history + std_history, color=colors[i], alpha=0.2)\n",
    "    \n",
    "    # Customize plot\n",
    "    plt.title(title, fontsize=16)\n",
    "    plt.xlabel('Iterations', fontsize=14)\n",
    "    plt.ylabel('Fitness (lower is better)', fontsize=14)\n",
    "    plt.legend(loc='upper right')\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    plt.show()\n",
    "    \n",
    "    return plt.gcf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29fddca3",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def plot_normalized_convergence(history_data, title=\"Normalized Convergence Curves\"):\n",
    "    \"\"\"\n",
    "    Plot normalized convergence curves for all configurations.\n",
    "    \n",
    "    Args:\n",
    "        history_data: Dictionary with convergence history\n",
    "        title: Plot title\n",
    "    \"\"\"\n",
    "    if history_data is None or len(history_data) == 0:\n",
    "        print(\"No history data available for plotting normalized convergence curves.\")\n",
    "        return None\n",
    "    \n",
    "    plt.figure(figsize=EXPERIMENT_CONFIG['figure_size'])\n",
    "    \n",
    "    # Define a color map for different configurations\n",
    "    config_names = list(history_data.keys())\n",
    "    colors = plt.cm.tab10(np.linspace(0, 1, len(config_names)))\n",
    "    \n",
    "    for i, config_name in enumerate(config_names):\n",
    "        histories = history_data[config_name]\n",
    "        \n",
    "        # Check if histories is empty\n",
    "        if not histories:\n",
    "            continue\n",
    "        \n",
    "        # Find the minimum length of all histories\n",
    "        min_length = min(len(histories[run]) for run in histories.keys() if hasattr(histories[run], '__len__') and len(histories[run]) > 0)\n",
    "        \n",
    "        if min_length == 0:\n",
    "            continue\n",
    "        \n",
    "        # Normalize and truncate all histories\n",
    "        normalized_histories = []\n",
    "        \n",
    "        for run in histories.keys():\n",
    "            history = histories[run]\n",
    "            \n",
    "            if not hasattr(history, '__len__') or len(history) < min_length:\n",
    "                continue\n",
    "            \n",
    "            # Truncate to minimum length\n",
    "            history = history[:min_length]\n",
    "            \n",
    "            # Normalize to [0, 1] range\n",
    "            if max(history) > min(history):\n",
    "                normalized_history = (history - min(history)) / (max(history) - min(history))\n",
    "            else:\n",
    "                normalized_history = np.zeros_like(history)\n",
    "            \n",
    "            normalized_histories.append(normalized_history)\n",
    "        \n",
    "        if not normalized_histories:\n",
    "            continue\n",
    "        \n",
    "        # Calculate mean and standard deviation\n",
    "        mean_history = np.mean(normalized_histories, axis=0)\n",
    "        std_history = np.std(normalized_histories, axis=0)\n",
    "        \n",
    "        # Plot mean with standard deviation band\n",
    "        x = np.arange(min_length)\n",
    "        plt.plot(x, mean_history, color=colors[i], label=config_name)\n",
    "        plt.fill_between(x, mean_history - std_history, mean_history + std_history, color=colors[i], alpha=0.2)\n",
    "    \n",
    "    # Customize plot\n",
    "    plt.title(title, fontsize=16)\n",
    "    plt.xlabel('Iterations', fontsize=14)\n",
    "    plt.ylabel('Normalized Fitness (lower is better)', fontsize=14)\n",
    "    plt.legend(loc='upper right')\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    plt.show()\n",
    "    \n",
    "    return plt.gcf()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac7b224c",
   "metadata": {},
   "source": [
    "### 9.4 Statistical Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55f07705",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def plot_boxplots(results_df):\n",
    "    \"\"\"\n",
    "    Plot boxplots for fitness values across all configurations.\n",
    "    \n",
    "    Args:\n",
    "        results_df: DataFrame with experiment results\n",
    "    \"\"\"\n",
    "    plt.figure(figsize=EXPERIMENT_CONFIG['figure_size'])\n",
    "    \n",
    "    # Create boxplot\n",
    "    boxplot = plt.boxplot([results_df[results_df['Configuration'] == config]['Best Fitness'].values \n",
    "                          for config in results_df['Configuration'].unique()],\n",
    "                         labels=results_df['Configuration'].unique(),\n",
    "                         patch_artist=True)\n",
    "    \n",
    "    # Set colors\n",
    "    colors = plt.cm.tab10(np.linspace(0, 1, len(results_df['Configuration'].unique())))\n",
    "    \n",
    "    for i, box in enumerate(boxplot['boxes']):\n",
    "        box.set(facecolor=colors[i], alpha=0.7)\n",
    "    \n",
    "    # Customize plot\n",
    "    plt.title('Fitness Distribution by Configuration', fontsize=16)\n",
    "    plt.xlabel('Configuration', fontsize=14)\n",
    "    plt.ylabel('Fitness (lower is better)', fontsize=14)\n",
    "    plt.xticks(rotation=90)\n",
    "    plt.grid(axis='y', alpha=0.3)\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    plt.show()\n",
    "    \n",
    "    return plt.gcf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb436f19",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def plot_statistical_significance(results_df, stats_results):\n",
    "    \"\"\"\n",
    "    Plot statistical significance of differences between configurations.\n",
    "    \n",
    "    Args:\n",
    "        results_df: DataFrame with experiment results\n",
    "        stats_results: Dictionary with statistical test results\n",
    "    \"\"\"\n",
    "    # Check if post-hoc test results are available\n",
    "    if 'test_results' not in stats_results or 'post_hoc' not in stats_results['test_results'] or stats_results['test_results']['post_hoc'] is None:\n",
    "        print(\"No post-hoc test results available for plotting statistical significance.\")\n",
    "        return None\n",
    "    \n",
    "    # Get configuration names\n",
    "    config_names = results_df['Configuration'].unique()\n",
    "    \n",
    "    # Create figure\n",
    "    plt.figure(figsize=EXPERIMENT_CONFIG['figure_size'])\n",
    "    \n",
    "    # Create heatmap of p-values\n",
    "    if stats_results['test_type'] == 'ANOVA':\n",
    "        # For ANOVA with Tukey HSD\n",
    "        post_hoc = stats_results['test_results']['post_hoc']\n",
    "        \n",
    "        # Create p-value matrix\n",
    "        p_values = np.zeros((len(config_names), len(config_names)))\n",
    "        \n",
    "        for i in range(len(config_names)):\n",
    "            for j in range(len(config_names)):\n",
    "                if i == j:\n",
    "                    p_values[i, j] = 1.0\n",
    "                else:\n",
    "                    # Find the p-value for this pair\n",
    "                    p_values[i, j] = post_hoc.pvalue[i, j]\n",
    "    else:\n",
    "        # For Kruskal-Wallis with Dunn's test\n",
    "        post_hoc = stats_results['test_results']['post_hoc']\n",
    "        \n",
    "        # Create p-value matrix\n",
    "        p_values = np.zeros((len(config_names), len(config_names)))\n",
    "        \n",
    "        for i, config1 in enumerate(config_names):\n",
    "            for j, config2 in enumerate(config_names):\n",
    "                if i == j:\n",
    "                    p_values[i, j] = 1.0\n",
    "                else:\n",
    "                    # Find the p-value for this pair\n",
    "                    p_values[i, j] = post_hoc.get(config1, {}).get(config2, 1.0)\n",
    "    \n",
    "    # Plot heatmap\n",
    "    plt.imshow(p_values, cmap='YlOrRd_r', vmin=0, vmax=1)\n",
    "    \n",
    "    # Add colorbar\n",
    "    cbar = plt.colorbar()\n",
    "    cbar.set_label('p-value', rotation=270, labelpad=15)\n",
    "    \n",
    "    # Add significance markers\n",
    "    for i in range(len(config_names)):\n",
    "        for j in range(len(config_names)):\n",
    "            if i != j:\n",
    "                if p_values[i, j] < 0.001:\n",
    "                    plt.text(j, i, '***', ha='center', va='center')\n",
    "                elif p_values[i, j] < 0.01:\n",
    "                    plt.text(j, i, '**', ha='center', va='center')\n",
    "                elif p_values[i, j] < 0.05:\n",
    "                    plt.text(j, i, '*', ha='center', va='center')\n",
    "    \n",
    "    # Customize plot\n",
    "    plt.title(f'Statistical Significance ({stats_results[\"test_type\"]})', fontsize=16)\n",
    "    plt.xticks(np.arange(len(config_names)), config_names, rotation=90)\n",
    "    plt.yticks(np.arange(len(config_names)), config_names)\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    plt.show()\n",
    "    \n",
    "    return plt.gcf()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89bec8e6",
   "metadata": {},
   "source": [
    "## 10. Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68a0ad10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze results\n",
    "stats_results = analyze_results(results_df)\n",
    "\n",
    "# Print statistical analysis results\n",
    "print(\"\\nStatistical Analysis Results:\")\n",
    "print(f\"Test type: {stats_results['test_type']}\")\n",
    "print(f\"p-value: {stats_results['test_results']['p_value']:.6f}\")\n",
    "print(f\"Significant: {stats_results['test_results']['significant']}\")\n",
    "print(f\"Effect size (eta squared): {stats_results['effect_size']['eta_squared']:.6f}\")\n",
    "print(f\"Effect size interpretation: {stats_results['effect_size']['interpretation']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb739aac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot performance comparison\n",
    "plot_performance_comparison(results_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55891167",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot convergence curves\n",
    "if history_data is not None and len(history_data) > 0:\n",
    "    # Check if history data is valid\n",
    "    valid_history = False\n",
    "    for config_name in history_data:\n",
    "        for run in history_data[config_name]:\n",
    "            history = history_data[config_name][run]\n",
    "            if hasattr(history, '__len__') and len(history) > 0:\n",
    "                valid_history = True\n",
    "                break\n",
    "        if valid_history:\n",
    "            break\n",
    "    \n",
    "    if valid_history:\n",
    "        # Plot convergence curves\n",
    "        plot_convergence_curves(history_data, \"Convergence Curves by Run\")\n",
    "        \n",
    "        # Plot average convergence curves\n",
    "        plot_average_convergence(history_data, \"Average Convergence Curves\")\n",
    "        \n",
    "        # Plot normalized convergence curves\n",
    "        plot_normalized_convergence(history_data, \"Normalized Convergence Curves\")\n",
    "    else:\n",
    "        print(\"No valid history data available for plotting convergence curves.\")\n",
    "else:\n",
    "    print(\"No history data available for plotting convergence curves.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c37b9da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot boxplots\n",
    "plot_boxplots(results_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e41a45a0",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "# Plot statistical significance\n",
    "plot_statistical_significance(results_df, stats_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c369f85",
   "metadata": {},
   "source": [
    "## 11. Best Solution Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe9b7ff8",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def display_team_solution(solution):\n",
    "    \"\"\"\n",
    "    Display the team composition of a solution.\n",
    "    \n",
    "    Args:\n",
    "        solution: Solution to display\n",
    "    \"\"\"\n",
    "    team_stats = solution.get_team_stats()\n",
    "    \n",
    "    print(\"\\nTeam Statistics:\")\n",
    "    print(f\"{'Team':<10} {'Avg Skill':<15} {'Total Salary':<15} {'GK':<5} {'DEF':<5} {'MID':<5} {'FWD':<5}\")\n",
    "    print(\"-\" * 65)\n",
    "    \n",
    "    for stat in team_stats:\n",
    "        positions = stat[\"positions\"]\n",
    "        print(f\"Team {stat['team_id']+1:<5} {stat['avg_skill']:<15.2f} {stat['total_salary']:<15.2f} \"\n",
    "              f\"{positions['GK']:<5} {positions['DEF']:<5} {positions['MID']:<5} {positions['FWD']:<5}\")\n",
    "    \n",
    "    print(\"\\nDetailed Team Composition:\")\n",
    "    \n",
    "    for stat in team_stats:\n",
    "        print(f\"\\nTeam {stat['team_id']+1}:\")\n",
    "        print(f\"{'Name':<20} {'Position':<10} {'Skill':<10} {'Salary':<10}\")\n",
    "        print(\"-\" * 50)\n",
    "        \n",
    "        for player in stat[\"players\"]:\n",
    "            print(f\"{player['Name']:<20} {player['Position']:<10} {player['Skill']:<10.2f} {player['Salary']:<10.2f}\")\n",
    "        \n",
    "        print(f\"Average Skill: {stat['avg_skill']:.2f}\")\n",
    "        print(f\"Total Salary: {stat['total_salary']:.2f}\")\n",
    "    \n",
    "    # Calculate overall statistics\n",
    "    avg_skills = [stat[\"avg_skill\"] for stat in team_stats]\n",
    "    overall_std = np.std(avg_skills)\n",
    "    \n",
    "    print(\"\\nOverall Team Balance:\")\n",
    "    print(f\"Standard Deviation of Average Skills: {overall_std:.4f}\")\n",
    "    print(f\"This matches the fitness value: {solution.fitness():.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ce4e541",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def plot_team_solution(solution):\n",
    "    \"\"\"\n",
    "    Create a graphical visualization of the team solution.\n",
    "    \n",
    "    Args:\n",
    "        solution: Solution to visualize\n",
    "    \"\"\"\n",
    "    team_stats = solution.get_team_stats()\n",
    "    \n",
    "    # Plot average skills\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    teams = [f\"Team {stat['team_id']+1}\" for stat in team_stats]\n",
    "    avg_skills = [stat[\"avg_skill\"] for stat in team_stats]\n",
    "    \n",
    "    plt.bar(teams, avg_skills)\n",
    "    plt.title(\"Average Skill by Team\")\n",
    "    plt.xlabel(\"Team\")\n",
    "    plt.ylabel(\"Average Skill\")\n",
    "    plt.grid(axis='y', alpha=0.3)\n",
    "    \n",
    "    # Add value labels\n",
    "    for i, v in enumerate(avg_skills):\n",
    "        plt.text(i, v + 0.1, f\"{v:.2f}\", ha='center')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Plot position distribution\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    positions = [\"GK\", \"DEF\", \"MID\", \"FWD\"]\n",
    "    \n",
    "    for i, stat in enumerate(team_stats):\n",
    "        pos_counts = [stat[\"positions\"][pos] for pos in positions]\n",
    "        plt.subplot(2, 3, i+1)\n",
    "        plt.bar(positions, pos_counts)\n",
    "        plt.title(f\"Team {stat['team_id']+1}\")\n",
    "        plt.ylim(0, 3)\n",
    "        \n",
    "        # Add value labels\n",
    "        for j, v in enumerate(pos_counts):\n",
    "            plt.text(j, v + 0.1, str(v), ha='center')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Plot salary distribution\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    total_salaries = [stat[\"total_salary\"] for stat in team_stats]\n",
    "    \n",
    "    plt.bar(teams, total_salaries)\n",
    "    plt.title(\"Total Salary by Team\")\n",
    "    plt.xlabel(\"Team\")\n",
    "    plt.ylabel(\"Total Salary (€M)\")\n",
    "    plt.grid(axis='y', alpha=0.3)\n",
    "    \n",
    "    # Add value labels\n",
    "    for i, v in enumerate(total_salaries):\n",
    "        plt.text(i, v + 10, f\"{v:.2f}\", ha='center')\n",
    "    \n",
    "    # Add budget line\n",
    "    plt.axhline(y=solution.max_budget, color='r', linestyle='--', label=f\"Budget Limit ({solution.max_budget})\")\n",
    "    plt.legend()\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "864f6855",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the best solution\n",
    "best_config = results_df.groupby('Configuration')['Best Fitness'].mean().idxmin()\n",
    "best_run = results_df[(results_df['Configuration'] == best_config)]['Best Fitness'].idxmin()\n",
    "best_run_data = results_df.iloc[best_run]\n",
    "\n",
    "print(f\"\\nBest Configuration: {best_config}\")\n",
    "print(f\"Best Run: {best_run_data['Run']}\")\n",
    "print(f\"Best Fitness: {best_run_data['Best Fitness']:.6f}\")\n",
    "print(f\"Evaluations: {best_run_data['Evaluations']}\")\n",
    "print(f\"Runtime: {best_run_data['Runtime (s)']:.2f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbf20913",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a solution with the best configuration\n",
    "best_solution = LeagueSolution(\n",
    "    players=players_list,\n",
    "    num_teams=5,\n",
    "    team_size=7,\n",
    "    max_budget=750\n",
    ")\n",
    "\n",
    "# Run the best algorithm to get the best solution\n",
    "if best_config in configs:\n",
    "    config = configs[best_config]\n",
    "    \n",
    "    best_solution, best_fitness, evaluations, runtime, history = run_experiment(\n",
    "        config=config,\n",
    "        players_list=players_list,\n",
    "        max_evaluations=EXPERIMENT_CONFIG['max_evaluations']\n",
    "    )\n",
    "    \n",
    "    # Display the best solution\n",
    "    display_team_solution(best_solution)\n",
    "    \n",
    "    # Plot the best solution\n",
    "    plot_team_solution(best_solution)\n",
    "else:\n",
    "    print(f\"Configuration {best_config} not found in configs.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30fc4345",
   "metadata": {},
   "source": [
    "## 12. Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "216c5994",
   "metadata": {},
   "source": [
    "In this notebook, we have implemented and analyzed various optimization algorithms for the Fantasy League Team Optimization problem. The goal was to create balanced teams of players while respecting position and budget constraints.\n",
    "\n",
    "We compared the following algorithms:\n",
    "- Hill Climbing (HC_Standard)\n",
    "- Hill Climbing with Random Restart (HC_Random_Restart)\n",
    "- Simulated Annealing (SA_Standard)\n",
    "- Genetic Algorithm variants (GA_Tournament_OnePoint, GA_Tournament_TwoPoint, GA_Rank_Uniform, GA_Boltzmann_TwoPoint)\n",
    "- GA Hybrid\n",
    "- GA Memetic\n",
    "- GA Island Model\n",
    "- GA with Scramble Mutation\n",
    "\n",
    "Our statistical analysis showed significant differences between the algorithms, with a large effect size. The best performing algorithm was the GA Memetic, which combines the global exploration capabilities of genetic algorithms with the local exploitation capabilities of hill climbing.\n",
    "\n",
    "The optimal team solution achieved a good balance of skills across teams while respecting all constraints. This demonstrates the effectiveness of our approach for solving the Fantasy League Team Optimization problem."
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "formats": ".jupytext-sync-ipynb//ipynb,py:percent",
   "main_language": "python"
  },
  "kernelspec": {
   "display_name": "cloudspace",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
