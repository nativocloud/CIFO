{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sports League Optimization: Comparative Analysis of Algorithms\n",
    "\n",
    "This notebook presents a comprehensive analysis of different optimization algorithms applied to the Sports League problem. We compare Hill Climbing, Simulated Annealing, and Genetic Algorithm approaches, analyzing their performance across multiple metrics.\n",
    "\n",
    "## Table of Contents\n",
    "1. [Problem Definition](#1-problem-definition)\n",
    "2. [Experimental Setup](#2-experimental-setup)\n",
    "3. [Algorithm Implementations](#3-algorithm-implementations)\n",
    "4. [Performance Comparison](#4-performance-comparison)\n",
    "5. [Statistical Analysis](#5-statistical-analysis)\n",
    "6. [Conclusion](#6-conclusion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import time\n",
    "from scipy import stats\n",
    "import random\n",
    "from copy import deepcopy\n",
    "\n",
    "# Import our custom modules\n",
    "from solution import LeagueSolution, LeagueHillClimbingSolution, LeagueSASolution\n",
    "from evolution import (\n",
    "    hill_climbing, \n",
    "    simulated_annealing, \n",
    "    genetic_algorithm,\n",
    "    # Mutation operators\n",
    "    mutate_swap,\n",
    "    mutate_swap_constrained,\n",
    "    mutate_team_shift,\n",
    "    mutate_targeted_player_exchange,\n",
    "    mutate_shuffle_within_team_constrained,\n",
    "    # Crossover operators\n",
    "    crossover_one_point,\n",
    "    crossover_one_point_prefer_valid,\n",
    "    crossover_uniform,\n",
    "    crossover_uniform_prefer_valid,\n",
    "    # Selection operators\n",
    "    selection_tournament,\n",
    "    selection_tournament_variable_k,\n",
    "    selection_ranking,\n",
    "    selection_boltzmann\n",
    ")\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "random.seed(42)\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Problem Definition\n",
    "\n",
    "### 1.1 Sports League Problem\n",
    "\n",
    "The Sports League problem involves assigning players to teams while satisfying specific constraints and optimizing for team balance. The goal is to create teams with similar average skill levels.\n",
    "\n",
    "**Formal Definition:**\n",
    "- We have 35 players with different positions (GK, DEF, MID, FWD) and skill levels\n",
    "- We need to assign these players to 5 teams (7 players per team)\n",
    "- Each team must have exactly 1 GK, 2 DEF, 2 MID, and 2 FWD\n",
    "- Each team's total salary must not exceed 750M â‚¬\n",
    "- The objective is to minimize the standard deviation of average team skills\n",
    "\n",
    "### 1.2 Solution Representation\n",
    "\n",
    "We represent a solution as a list of team assignments for each player. For example, if `solution.repr[0] = 2`, it means player 0 is assigned to team 2.\n",
    "\n",
    "**Search Space Size:**\n",
    "- For 35 players and 5 teams, the theoretical search space is 5^35\n",
    "- With constraints, the actual feasible search space is much smaller, but still extremely large\n",
    "\n",
    "### 1.3 Fitness Function\n",
    "\n",
    "The fitness function calculates the standard deviation of the average skill levels across all teams. A lower value indicates more balanced teams, which is our optimization goal.\n",
    "\n",
    "For invalid solutions (those violating constraints), we return infinity to ensure they are never selected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Load player data\n",
    "players_df = pd.read_csv(\"players.csv\", sep=\";\")\n",
    "players_data = players_df.to_dict(orient=\"records\")\n",
    "\n",
    "# Display the player data\n",
    "players_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4 Data Analysis\n",
    "\n",
    "Let's analyze the player data to understand the distribution of skills, positions, and salaries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Analyze player positions\n",
    "position_counts = players_df['Position'].value_counts()\n",
    "print(\"Position distribution:\")\n",
    "print(position_counts)\n",
    "\n",
    "# Analyze skill distribution by position\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.boxplot(x='Position', y='Skill', data=players_df)\n",
    "plt.title('Skill Distribution by Position')\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "# Analyze salary distribution by position\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.boxplot(x='Position', y='Salary', data=players_df)\n",
    "plt.title('Salary Distribution by Position')\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "# Correlation between skill and salary\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.scatterplot(x='Skill', y='Salary', hue='Position', data=players_df)\n",
    "plt.title('Correlation between Skill and Salary')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Experimental Setup\n",
    "\n",
    "### 2.1 Metrics for Comparison\n",
    "\n",
    "To ensure a fair comparison between different algorithms, we'll track the following metrics:\n",
    "\n",
    "1. **Solution Quality**: The fitness value (standard deviation of average team skills)\n",
    "2. **Function Evaluations**: Number of fitness function calls\n",
    "3. **Iterations**: Number of algorithm iterations\n",
    "4. **Runtime**: Actual execution time in seconds\n",
    "\n",
    "### 2.2 Algorithm Configurations\n",
    "\n",
    "We'll test the following algorithm configurations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Define algorithm configurations\n",
    "configs = {\n",
    "    # Hill Climbing configurations\n",
    "    'HC_Standard': {\n",
    "        'algorithm': 'Hill Climbing',\n",
    "        'params': {\n",
    "            'max_iterations': 500,\n",
    "            'max_no_improvement': 100,\n",
    "            'verbose': False\n",
    "        }\n",
    "    },\n",
    "    \n",
    "    # Simulated Annealing configurations\n",
    "    'SA_Standard': {\n",
    "        'algorithm': 'Simulated Annealing',\n",
    "        'params': {\n",
    "            'initial_temperature': 200.0,\n",
    "            'cooling_rate': 0.95,\n",
    "            'min_temperature': 1e-5,\n",
    "            'iterations_per_temp': 20,\n",
    "            'verbose': False\n",
    "        }\n",
    "    },\n",
    "    \n",
    "    # Genetic Algorithm configurations\n",
    "    'GA_Tournament_OnePoint': {\n",
    "        'algorithm': 'Genetic Algorithm',\n",
    "        'params': {\n",
    "            'population_size': 100,\n",
    "            'max_generations': 50,\n",
    "            'selection_operator': selection_tournament,\n",
    "            'crossover_operator': crossover_one_point_prefer_valid,\n",
    "            'crossover_rate': 0.8,\n",
    "            'mutation_operator': mutate_swap_constrained,\n",
    "            'mutation_rate': 0.1,\n",
    "            'elitism': True,\n",
    "            'elitism_size': 2,\n",
    "            'verbose': False\n",
    "        }\n",
    "    },\n",
    "    'GA_Ranking_Uniform': {\n",
    "        'algorithm': 'Genetic Algorithm',\n",
    "        'params': {\n",
    "            'population_size': 100,\n",
    "            'max_generations': 50,\n",
    "            'selection_operator': selection_ranking,\n",
    "            'crossover_operator': crossover_uniform_prefer_valid,\n",
    "            'crossover_rate': 0.8,\n",
    "            'mutation_operator': mutate_targeted_player_exchange,\n",
    "            'mutation_rate': 0.1,\n",
    "            'elitism': True,\n",
    "            'elitism_size': 2,\n",
    "            'verbose': False\n",
    "        }\n",
    "    },\n",
    "    'GA_Boltzmann_TeamShift': {\n",
    "        'algorithm': 'Genetic Algorithm',\n",
    "        'params': {\n",
    "            'population_size': 100,\n",
    "            'max_generations': 50,\n",
    "            'selection_operator': selection_boltzmann,\n",
    "            'selection_params': {'temperature': 1.0},\n",
    "            'crossover_operator': crossover_one_point_prefer_valid,\n",
    "            'crossover_rate': 0.8,\n",
    "            'mutation_operator': mutate_team_shift,\n",
    "            'mutation_rate': 0.1,\n",
    "            'elitism': True,\n",
    "            'elitism_size': 2,\n",
    "            'verbose': False\n",
    "        }\n",
    "    },\n",
    "    'GA_Hybrid': {\n",
    "        'algorithm': 'Hybrid GA',\n",
    "        'params': {\n",
    "            'population_size': 75,\n",
    "            'max_generations': 40,\n",
    "            'selection_operator': selection_tournament_variable_k,\n",
    "            'selection_params': {'k': 3},\n",
    "            'crossover_operator': crossover_uniform_prefer_valid,\n",
    "            'crossover_rate': 0.85,\n",
    "            'mutation_operator': mutate_shuffle_within_team_constrained,\n",
    "            'mutation_rate': 0.15,\n",
    "            'elitism': True,\n",
    "            'elitism_size': 1,\n",
    "            'local_search': {\n",
    "                'algorithm': 'hill_climbing',\n",
    "                'frequency': 5,  # Apply HC every 5 generations\n",
    "                'iterations': 50  # HC iterations per application\n",
    "            },\n",
    "            'verbose': False\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "# Display the configurations\n",
    "for name, config in configs.items():\n",
    "    print(f\"Configuration: {name}\")\n",
    "    print(f\"Algorithm: {config['algorithm']}\")\n",
    "    print(\"Parameters:\")\n",
    "    for param, value in config['params'].items():\n",
    "        if param not in ['selection_operator', 'crossover_operator', 'mutation_operator', 'verbose']:\n",
    "            print(f\"  {param}: {value}\")\n",
    "    print(\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Tracking Function Evaluations\n",
    "\n",
    "To ensure fair comparison between algorithms, we'll implement a counter for fitness function evaluations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Create a wrapper for the fitness function to count evaluations\n",
    "class FitnessCounter:\n",
    "    def __init__(self):\n",
    "        self.count = 0\n",
    "        self.original_fitness = LeagueSolution.fitness\n",
    "        \n",
    "    def start_counting(self):\n",
    "        self.count = 0\n",
    "        LeagueSolution.fitness = self.counting_fitness\n",
    "        \n",
    "    def stop_counting(self):\n",
    "        LeagueSolution.fitness = self.original_fitness\n",
    "        return self.count\n",
    "    \n",
    "    def counting_fitness(self, solution):\n",
    "        self.count += 1\n",
    "        return self.original_fitness(solution)\n",
    "\n",
    "# Initialize the counter\n",
    "fitness_counter = FitnessCounter()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4 Experiment Runner\n",
    "\n",
    "We'll create a function to run experiments with all configurations and collect results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "def run_experiments(configs, players_data, num_runs=5):\n",
    "    results = []\n",
    "    \n",
    "    for config_name, config in configs.items():\n",
    "        print(f\"Running {config_name}...\")\n",
    "        \n",
    "        for run in range(num_runs):\n",
    "            # Reset random seed for each run to ensure fair comparison\n",
    "            random.seed(42 + run)\n",
    "            np.random.seed(42 + run)\n",
    "            \n",
    "            # Start counting fitness evaluations\n",
    "            fitness_counter.start_counting()\n",
    "            \n",
    "            # Record start time\n",
    "            start_time = time.time()\n",
    "            \n",
    "            # Run the appropriate algorithm\n",
    "            if config['algorithm'] == 'Hill Climbing':\n",
    "                # Create initial solution\n",
    "                initial_solution = LeagueHillClimbingSolution(players=players_data)\n",
    "                \n",
    "                # Run Hill Climbing\n",
    "                best_solution, best_fitness, history = hill_climbing(\n",
    "                    initial_solution,\n",
    "                    **config['params']\n",
    "                )\n",
    "                \n",
    "                iterations = len(history)\n",
    "                \n",
    "            elif config['algorithm'] == 'Simulated Annealing':\n",
    "                # Create initial solution\n",
    "                initial_solution = LeagueSASolution(players=players_data)\n",
    "                \n",
    "                # Run Simulated Annealing\n",
    "                best_solution, best_fitness, history = simulated_annealing(\n",
    "                    initial_solution,\n",
    "                    **config['params']\n",
    "                )\n",
    "                \n",
    "                iterations = len(history)\n",
    "                \n",
    "            elif config['algorithm'] in ['Genetic Algorithm', 'Hybrid GA']:\n",
    "                # Run Genetic Algorithm\n",
    "                best_solution, best_fitness, history = genetic_algorithm(\n",
    "                    players_data,\n",
    "                    **config['params']\n",
    "                )\n",
    "                \n",
    "                iterations = len(history)\n",
    "            \n",
    "            # Record end time and calculate runtime\n",
    "            runtime = time.time() - start_time\n",
    "            \n",
    "            # Get number of fitness evaluations\n",
    "            evaluations = fitness_counter.stop_counting()\n",
    "            \n",
    "            # Store results\n",
    "            results.append({\n",
    "                'Configuration': config_name,\n",
    "                'Algorithm': config['algorithm'],\n",
    "                'Run': run + 1,\n",
    "                'Best Fitness': best_fitness,\n",
    "                'Iterations': iterations,\n",
    "                'Function Evaluations': evaluations,\n",
    "                'Runtime (s)': runtime,\n",
    "                'History': history\n",
    "            })\n",
    "            \n",
    "            print(f\"  Run {run + 1}: Fitness = {best_fitness:.6f}, Evaluations = {evaluations}, Runtime = {runtime:.2f}s\")\n",
    "    \n",
    "    return pd.DataFrame(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Algorithm Implementations\n",
    "\n",
    "### 3.1 Hill Climbing\n",
    "\n",
    "Hill Climbing is a local search algorithm that starts with an initial solution and iteratively moves to better neighboring solutions until no improvement is possible.\n",
    "\n",
    "**Key Components:**\n",
    "- **Neighborhood Generation**: Defined in `LeagueHillClimbingSolution.get_neighbors()`, which generates valid neighboring solutions by swapping players between teams.\n",
    "- **Selection Strategy**: We use steepest ascent, selecting the best neighbor at each iteration.\n",
    "- **Termination Criteria**: The algorithm stops when no better neighbor is found or after a maximum number of iterations.\n",
    "\n",
    "### 3.2 Simulated Annealing\n",
    "\n",
    "Simulated Annealing is inspired by the annealing process in metallurgy. It allows accepting worse solutions with a probability that decreases over time, helping to escape local optima.\n",
    "\n",
    "**Key Components:**\n",
    "- **Random Neighbor Generation**: Defined in `LeagueSASolution.get_random_neighbor()`, which generates a random valid neighboring solution.\n",
    "- **Acceptance Probability**: Based on the temperature and the fitness difference between the current and new solutions.\n",
    "- **Cooling Schedule**: The temperature decreases over time, reducing the probability of accepting worse solutions.\n",
    "\n",
    "### 3.3 Genetic Algorithm\n",
    "\n",
    "Genetic Algorithm is a population-based search algorithm inspired by natural selection and genetics.\n",
    "\n",
    "**Key Components:**\n",
    "- **Selection Operators**: We've implemented three selection mechanisms:\n",
    "  - Tournament Selection: Selects the best solution from k random candidates.\n",
    "  - Ranking Selection: Selects solutions with probability proportional to their rank.\n",
    "  - Boltzmann Selection: Uses Boltzmann distribution to select solutions.\n",
    "\n",
    "- **Crossover Operators**: We've implemented three crossover operators:\n",
    "  - One-Point Crossover: Creates a child by taking a portion from each parent.\n",
    "  - One-Point Prefer Valid: Tries multiple cut points to find a valid solution.\n",
    "  - Uniform Crossover: Creates a child by randomly selecting genes from either parent.\n",
    "\n",
    "- **Mutation Operators**: We've implemented four mutation operators:\n",
    "  - Swap: Randomly swaps two players between teams.\n",
    "  - Swap Constrained: Swaps players of the same position.\n",
    "  - Team Shift: Shifts all player assignments by a random number.\n",
    "  - Targeted Player Exchange: Swaps players between teams to improve balance.\n",
    "  - Shuffle Within Team: Shuffles players within a team with other teams.\n",
    "\n",
    "- **Elitism**: Preserves the best solutions from one generation to the next.\n",
    "\n",
    "### 3.4 Hybrid Approach\n",
    "\n",
    "We've also implemented a hybrid approach that combines Genetic Algorithm with Hill Climbing, applying local search to the best solutions periodically."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Performance Comparison\n",
    "\n",
    "Let's run the experiments and compare the performance of different algorithms:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Run experiments\n",
    "results_df = run_experiments(configs, players_data, num_runs=3)\n",
    "\n",
    "# Display summary statistics\n",
    "summary = results_df.groupby('Configuration').agg({\n",
    "    'Best Fitness': ['mean', 'std', 'min'],\n",
    "    'Iterations': ['mean', 'std'],\n",
    "    'Function Evaluations': ['mean', 'std'],\n",
    "    'Runtime (s)': ['mean', 'std']\n",
    "})\n",
    "\n",
    "print(\"Summary Statistics:\")\n",
    "summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 Solution Quality Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Compare solution quality (fitness)\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.boxplot(x='Configuration', y='Best Fitness', data=results_df)\n",
    "plt.title('Solution Quality Comparison')\n",
    "plt.ylabel('Fitness (lower is better)')\n",
    "plt.xticks(rotation=45)\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Computational Efficiency Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Compare function evaluations\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.barplot(x='Configuration', y='Function Evaluations', data=results_df, estimator=np.mean, ci='sd')\n",
    "plt.title('Function Evaluations Comparison')\n",
    "plt.ylabel('Number of Function Evaluations')\n",
    "plt.xticks(rotation=45)\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Compare runtime\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.barplot(x='Configuration', y='Runtime (s)', data=results_df, estimator=np.mean, ci='sd')\n",
    "plt.title('Runtime Comparison')\n",
    "plt.ylabel('Runtime (seconds)')\n",
    "plt.xticks(rotation=45)\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3 Convergence Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Plot convergence curves\n",
    "plt.figure(figsize=(14, 8))\n",
    "\n",
    "# Get one history from each configuration (first run)\n",
    "for config_name in configs.keys():\n",
    "    history = results_df[results_df['Configuration'] == config_name].iloc[0]['History']\n",
    "    plt.plot(history, label=config_name)\n",
    "\n",
    "plt.title('Convergence Comparison')\n",
    "plt.xlabel('Iterations')\n",
    "plt.ylabel('Fitness (lower is better)')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Plot normalized convergence curves (by function evaluations)\n",
    "plt.figure(figsize=(14, 8))\n",
    "\n",
    "for config_name in configs.keys():\n",
    "    row = results_df[results_df['Configuration'] == config_name].iloc[0]\n",
    "    history = row['History']\n",
    "    evals = row['Function Evaluations']\n",
    "    \n",
    "    # Create x-axis as percentage of total evaluations\n",
    "    x = np.linspace(0, 100, len(history))\n",
    "    plt.plot(x, history, label=config_name)\n",
    "\n",
    "plt.title('Normalized Convergence Comparison')\n",
    "plt.xlabel('Percentage of Function Evaluations')\n",
    "plt.ylabel('Fitness (lower is better)')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Statistical Analysis\n",
    "\n",
    "### 5.1 ANOVA Test\n",
    "\n",
    "Let's perform an ANOVA test to determine if there are statistically significant differences between the algorithms:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Perform ANOVA test on fitness values\n",
    "groups = [results_df[results_df['Configuration'] == config]['Best Fitness'].values for config in configs.keys()]\n",
    "f_stat, p_value = stats.f_oneway(*groups)\n",
    "\n",
    "print(f\"ANOVA Test Results:\")\n",
    "print(f\"F-statistic: {f_stat:.4f}\")\n",
    "print(f\"p-value: {p_value:.4f}\")\n",
    "print(f\"Statistically significant difference: {p_value < 0.05}\")\n",
    "\n",
    "# If ANOVA shows significant difference, perform post-hoc test\n",
    "if p_value < 0.05:\n",
    "    from statsmodels.stats.multicomp import pairwise_tukeyhsd\n",
    "    \n",
    "    # Prepare data for Tukey's test\n",
    "    fitness_values = results_df['Best Fitness'].values\n",
    "    config_labels = results_df['Configuration'].values\n",
    "    \n",
    "    # Perform Tukey's test\n",
    "    tukey_results = pairwise_tukeyhsd(fitness_values, config_labels, alpha=0.05)\n",
    "    \n",
    "    print(\"\\nTukey's HSD Test Results:\")\n",
    "    print(tukey_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2 Efficiency vs. Quality Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Create a scatter plot of fitness vs. function evaluations\n",
    "plt.figure(figsize=(12, 8))\n",
    "sns.scatterplot(x='Function Evaluations', y='Best Fitness', hue='Configuration', data=results_df, s=100)\n",
    "plt.title('Efficiency vs. Quality Analysis')\n",
    "plt.xlabel('Number of Function Evaluations')\n",
    "plt.ylabel('Fitness (lower is better)')\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Create a scatter plot of fitness vs. runtime\n",
    "plt.figure(figsize=(12, 8))\n",
    "sns.scatterplot(x='Runtime (s)', y='Best Fitness', hue='Configuration', data=results_df, s=100)\n",
    "plt.title('Runtime vs. Quality Analysis')\n",
    "plt.xlabel('Runtime (seconds)')\n",
    "plt.ylabel('Fitness (lower is better)')\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Best Solution Analysis\n",
    "\n",
    "Let's analyze the best solution found across all experiments:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Find the best overall solution\n",
    "best_row = results_df.loc[results_df['Best Fitness'].idxmin()]\n",
    "print(f\"Best solution found by {best_row['Configuration']} (Run {best_row['Run']})\")\n",
    "print(f\"Fitness: {best_row['Best Fitness']:.6f}\")\n",
    "print(f\"Function Evaluations: {best_row['Function Evaluations']}\")\n",
    "print(f\"Runtime: {best_row['Runtime (s)']:.2f} seconds\")\n",
    "\n",
    "# Re-run the best configuration to get the solution\n",
    "config = configs[best_row['Configuration']]\n",
    "random.seed(42 + best_row['Run'] - 1)\n",
    "np.random.seed(42 + best_row['Run'] - 1)\n",
    "\n",
    "if config['algorithm'] == 'Hill Climbing':\n",
    "    initial_solution = LeagueHillClimbingSolution(players=players_data)\n",
    "    best_solution, _, _ = hill_climbing(initial_solution, **config['params'])\n",
    "elif config['algorithm'] == 'Simulated Annealing':\n",
    "    initial_solution = LeagueSASolution(players=players_data)\n",
    "    best_solution, _, _ = simulated_annealing(initial_solution, **config['params'])\n",
    "else:  # Genetic Algorithm or Hybrid GA\n",
    "    best_solution, _, _ = genetic_algorithm(players_data, **config['params'])\n",
    "\n",
    "# Analyze the best solution\n",
    "team_stats = best_solution.get_team_stats()\n",
    "\n",
    "# Create a DataFrame for team statistics\n",
    "teams_df = pd.DataFrame([\n",
    "    {\n",
    "        'Team': f\"Team {stats['team_id']}\",\n",
    "        'Average Skill': stats['avg_skill'],\n",
    "        'Total Salary': stats['total_salary'],\n",
    "        'GK': stats['positions']['GK'],\n",
    "        'DEF': stats['positions']['DEF'],\n",
    "        'MID': stats['positions']['MID'],\n",
    "        'FWD': stats['positions']['FWD']\n",
    "    } for stats in team_stats\n",
    "])\n",
    "\n",
    "teams_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Plot team skills\n",
    "plt.figure(figsize=(10, 6))\n",
    "bars = plt.bar(teams_df['Team'], teams_df['Average Skill'])\n",
    "plt.title('Average Skill by Team')\n",
    "plt.ylabel('Average Skill')\n",
    "plt.axhline(y=teams_df['Average Skill'].mean(), color='r', linestyle='--', label='Mean')\n",
    "\n",
    "# Add value labels on top of bars\n",
    "for bar in bars:\n",
    "    height = bar.get_height()\n",
    "    plt.text(bar.get_x() + bar.get_width()/2., height + 0.01,\n",
    "             f'{height:.2f}',\n",
    "             ha='center', va='bottom')\n",
    "\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "# Plot team salaries\n",
    "plt.figure(figsize=(10, 6))\n",
    "bars = plt.bar(teams_df['Team'], teams_df['Total Salary'])\n",
    "plt.title('Total Salary by Team')\n",
    "plt.ylabel('Total Salary (M â‚¬)')\n",
    "plt.axhline(y=750, color='r', linestyle='--', label='Budget Limit')\n",
    "\n",
    "# Add value labels on top of bars\n",
    "for bar in bars:\n",
    "    height = bar.get_height()\n",
    "    plt.text(bar.get_x() + bar.get_width()/2., height + 5,\n",
    "             f'{height:.1f}',\n",
    "             ha='center', va='bottom')\n",
    "\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Display detailed team compositions\n",
    "for i, stats in enumerate(team_stats):\n",
    "    print(f\"\\nTeam {i}:\")\n",
    "    print(f\"Average Skill: {stats['avg_skill']:.2f}\")\n",
    "    print(f\"Total Salary: {stats['total_salary']} M â‚¬\")\n",
    "    print(\"Players:\")\n",
    "    \n",
    "    # Create a DataFrame for this team's players\n",
    "    team_df = pd.DataFrame(stats['players'])\n",
    "    team_df = team_df.sort_values(by='Position')\n",
    "    display(team_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Conclusion\n",
    "\n",
    "### 7.1 Algorithm Performance Summary\n",
    "\n",
    "Based on our experiments, we can draw the following conclusions:\n",
    "\n",
    "1. **Solution Quality**: [To be filled after running experiments]\n",
    "2. **Computational Efficiency**: [To be filled after running experiments]\n",
    "3. **Convergence Behavior**: [To be filled after running experiments]\n",
    "\n",
    "### 7.2 Operator Impact Analysis\n",
    "\n",
    "1. **Selection Operators**: [To be filled after running experiments]\n",
    "2. **Crossover Operators**: [To be filled after running experiments]\n",
    "3. **Mutation Operators**: [To be filled after running experiments]\n",
    "4. **Elitism Impact**: [To be filled after running experiments]\n",
    "\n",
    "### 7.3 Recommendations\n",
    "\n",
    "Based on our analysis, we recommend the following approach for solving the Sports League problem:\n",
    "\n",
    "1. **Algorithm Choice**: [To be filled after running experiments]\n",
    "2. **Parameter Settings**: [To be filled after running experiments]\n",
    "3. **Operator Selection**: [To be filled after running experiments]\n",
    "\n",
    "### 7.4 Future Work\n",
    "\n",
    "Potential areas for future improvement include:\n",
    "\n",
    "1. **Multi-objective Optimization**: Consider both team balance and other factors like player chemistry or strategic fit.\n",
    "2. **Advanced Hybridization**: Explore more sophisticated combinations of global and local search.\n",
    "3. **Adaptive Parameters**: Implement dynamic parameter adjustment based on search progress.\n",
    "4. **Parallel Implementation**: Leverage parallel computing for population-based methods to improve efficiency."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
