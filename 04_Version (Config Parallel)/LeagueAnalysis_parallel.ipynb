{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b44c53ba",
   "metadata": {},
   "source": [
    "# Sports League Optimization Analysis\n",
    "\n",
    "Este notebook analisa diferentes algoritmos de otimização para o problema da Liga Esportiva."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "48e18785",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'run_genetic_algorithm' from 'evolution' (/teamspace/studios/this_studio/CIFO/04_Version (Config Parallel)/evolution.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mImportError\u001b[39m                               Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 17\u001b[39m\n\u001b[32m     15\u001b[39m \u001b[38;5;66;03m# Importações explícitas das classes necessárias para execução paralela\u001b[39;00m\n\u001b[32m     16\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msolution\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m LeagueSolution, LeagueHillClimbingSolution, LeagueSASolution\n\u001b[32m---> \u001b[39m\u001b[32m17\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mevolution\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m hill_climbing, simulated_annealing, run_genetic_algorithm, run_hybrid_ga\n\u001b[32m     18\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01moperators\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m     19\u001b[39m     mutate_swap, mutate_swap_constrained, mutate_team_shift,\n\u001b[32m     20\u001b[39m     mutate_targeted_player_exchange, mutate_shuffle_within_team_constrained,\n\u001b[32m     21\u001b[39m     crossover_one_point, crossover_uniform,\n\u001b[32m     22\u001b[39m     selection_tournament, selection_ranking\n\u001b[32m     23\u001b[39m )\n\u001b[32m     25\u001b[39m \u001b[38;5;66;03m# Implementação da função mutate_scramble que está faltando\u001b[39;00m\n",
      "\u001b[31mImportError\u001b[39m: cannot import name 'run_genetic_algorithm' from 'evolution' (/teamspace/studios/this_studio/CIFO/04_Version (Config Parallel)/evolution.py)"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import time\n",
    "import random\n",
    "from copy import deepcopy\n",
    "import multiprocessing\n",
    "from multiprocessing import Process, Queue\n",
    "import os\n",
    "import sys\n",
    "import warnings\n",
    "from collections import defaultdict\n",
    "\n",
    "# Importações explícitas das classes necessárias para execução paralela\n",
    "from solution import LeagueSolution, LeagueHillClimbingSolution, LeagueSASolution\n",
    "from evolution import hill_climbing, simulated_annealing, run_genetic_algorithm, run_hybrid_ga\n",
    "from operators import (\n",
    "    mutate_swap, mutate_swap_constrained, mutate_team_shift,\n",
    "    mutate_targeted_player_exchange, mutate_shuffle_within_team_constrained,\n",
    "    crossover_one_point, crossover_uniform,\n",
    "    selection_tournament, selection_ranking\n",
    ")\n",
    "\n",
    "# Implementação da função mutate_scramble que está faltando\n",
    "def mutate_scramble(solution, mutation_rate=None):\n",
    "    \"\"\"\n",
    "    Scramble mutation: randomly shuffles a subsequence of the solution.\n",
    "    \n",
    "    Args:\n",
    "        solution (LeagueSolution): The solution to mutate\n",
    "        mutation_rate (float, optional): Probability of mutation. Defaults to 0.1 if None.\n",
    "        \n",
    "    Returns:\n",
    "        LeagueSolution: A new solution with the mutation applied\n",
    "    \"\"\"\n",
    "    if mutation_rate is None:\n",
    "        mutation_rate = 0.1\n",
    "        \n",
    "    # Create a copy of the solution\n",
    "    mutated = deepcopy(solution)\n",
    "    \n",
    "    # Apply mutation with probability mutation_rate\n",
    "    if random.random() < mutation_rate:\n",
    "        # Select random subsequence\n",
    "        length = len(mutated.repr)\n",
    "        start = random.randint(0, length - 2)\n",
    "        end = random.randint(start + 1, length - 1)\n",
    "        \n",
    "        # Scramble the subsequence\n",
    "        subsequence = mutated.repr[start:end+1]\n",
    "        random.shuffle(subsequence)\n",
    "        mutated.repr[start:end+1] = subsequence\n",
    "        \n",
    "    return mutated\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "random.seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "# Configure plot style\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "sns.set_context(\"notebook\", font_scale=1.2)\n",
    "\n",
    "# Suppress warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e72ec46c",
   "metadata": {},
   "source": [
    "## 1. Configuração"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "956cdae6",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "# Experiment configuration\n",
    "EXPERIMENT_CONFIG = {\n",
    "    'parallel': True,           # Enable/disable parallel execution\n",
    "    'num_runs': 30,             # Number of runs per configuration\n",
    "    'num_processes': None,      # Number of parallel processes (None = automatic)\n",
    "    'max_evaluations': None,    # Maximum fitness evaluations (None = unlimited)\n",
    "    'save_results': True,       # Save results to file\n",
    "    'results_file': 'experiment_results.csv',  # Results file name\n",
    "    'verbose': True,            # Show detailed progress\n",
    "    'safe_exp_max': 700,        # Maximum value for safe exponential function\n",
    "    'show_best_solution': True  # Show details of the best solution found\n",
    "}\n",
    "\n",
    "# Define algorithm configurations to test\n",
    "ALGORITHM_CONFIGS = [\n",
    "    {\n",
    "        \"name\": \"Hill Climbing\",\n",
    "        \"algorithm\": \"hill_climbing\",\n",
    "        \"max_iterations\": 1000\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"Intensive Hill Climbing\",\n",
    "        \"algorithm\": \"hill_climbing\",\n",
    "        \"max_iterations\": 5000,\n",
    "        \"max_neighbors\": 100\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"Simulated Annealing\",\n",
    "        \"algorithm\": \"simulated_annealing\",\n",
    "        \"initial_temperature\": 100,\n",
    "        \"cooling_rate\": 0.95,\n",
    "        \"max_iterations\": 1000\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"Enhanced Simulated Annealing\",\n",
    "        \"algorithm\": \"simulated_annealing\",\n",
    "        \"initial_temperature\": 1000,\n",
    "        \"cooling_rate\": 0.99,\n",
    "        \"max_iterations\": 5000\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"Genetic Algorithm (Tournament)\",\n",
    "        \"algorithm\": \"genetic_algorithm\",\n",
    "        \"selection\": \"tournament\",\n",
    "        \"crossover\": \"uniform\",\n",
    "        \"mutation\": \"swap\",\n",
    "        \"population_size\": 100,\n",
    "        \"elitism_rate\": 0.1,\n",
    "        \"tournament_size\": 3,\n",
    "        \"max_generations\": 50,\n",
    "        \"mutation_rate\": 0.1\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"Genetic Algorithm (Ranking)\",\n",
    "        \"algorithm\": \"genetic_algorithm\",\n",
    "        \"selection\": \"ranking\",\n",
    "        \"crossover\": \"uniform\",\n",
    "        \"mutation\": \"swap\",\n",
    "        \"population_size\": 100,\n",
    "        \"elitism_rate\": 0.1,\n",
    "        \"max_generations\": 50,\n",
    "        \"mutation_rate\": 0.1\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"Hybrid GA\",\n",
    "        \"algorithm\": \"hybrid_ga\",\n",
    "        \"selection\": \"tournament\",\n",
    "        \"crossover\": \"uniform\",\n",
    "        \"mutation\": \"swap\",\n",
    "        \"population_size\": 50,\n",
    "        \"elitism_rate\": 0.1,\n",
    "        \"tournament_size\": 3,\n",
    "        \"max_generations\": 40,\n",
    "        \"mutation_rate\": 0.1,\n",
    "        \"local_search_rate\": 0.2\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"Optimized Hybrid GA\",\n",
    "        \"algorithm\": \"hybrid_ga\",\n",
    "        \"selection\": \"tournament\",\n",
    "        \"crossover\": \"uniform\",\n",
    "        \"mutation\": \"swap_constrained\",\n",
    "        \"population_size\": 100,\n",
    "        \"elitism_rate\": 0.2,\n",
    "        \"tournament_size\": 5,\n",
    "        \"max_generations\": 50,\n",
    "        \"mutation_rate\": 0.15,\n",
    "        \"local_search_rate\": 0.3\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5548474f",
   "metadata": {},
   "source": [
    "## 2. Funções Auxiliares"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4187455b",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "# Safe exponential function to prevent overflow\n",
    "# Importante: Não substituir np.exp globalmente para evitar recursão infinita\n",
    "def safe_exp(x, max_value=EXPERIMENT_CONFIG['safe_exp_max']):\n",
    "    \"\"\"\n",
    "    Compute exponential function safely to prevent overflow.\n",
    "    \n",
    "    Args:\n",
    "        x: Input value\n",
    "        max_value: Maximum absolute value to allow before clipping\n",
    "        \n",
    "    Returns:\n",
    "        Exponential of clipped input value\n",
    "    \"\"\"\n",
    "    return np.exp(np.clip(x, -max_value, max_value))\n",
    "\n",
    "# Fitness counter class\n",
    "class FitnessCounter:\n",
    "    \"\"\"\n",
    "    Class to count fitness evaluations.\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        self.count = 0\n",
    "        self.original_fitness = None\n",
    "    \n",
    "    def start_counting(self):\n",
    "        \"\"\"Start counting fitness evaluations.\"\"\"\n",
    "        self.original_fitness = LeagueSolution.fitness\n",
    "        self.count = 0\n",
    "        \n",
    "        # Use a wrapper function that correctly handles the 'self' parameter\n",
    "        def counting_wrapper(instance):\n",
    "            self.count += 1\n",
    "            return self.original_fitness(instance)\n",
    "        \n",
    "        # Replace the fitness method with our wrapper\n",
    "        LeagueSolution.fitness = counting_wrapper\n",
    "    \n",
    "    def stop_counting(self):\n",
    "        \"\"\"Stop counting and restore original fitness function.\"\"\"\n",
    "        # Restore original fitness function\n",
    "        if self.original_fitness:\n",
    "            LeagueSolution.fitness = self.original_fitness\n",
    "        \n",
    "        return self.count\n",
    "\n",
    "# Function to run a single experiment\n",
    "def run_experiment(config, players_list, max_evaluations=None):\n",
    "    \"\"\"\n",
    "    Run a single experiment with the specified configuration.\n",
    "    \n",
    "    Args:\n",
    "        config: Algorithm configuration dictionary\n",
    "        players_list: List of player dictionaries\n",
    "        max_evaluations: Maximum number of fitness evaluations (None = unlimited)\n",
    "        \n",
    "    Returns:\n",
    "        Tuple of (best_solution, best_fitness, evaluations, runtime, history)\n",
    "    \"\"\"\n",
    "    # Start timing\n",
    "    start_time = time.time()\n",
    "    \n",
    "    # Create fitness counter\n",
    "    fitness_counter = FitnessCounter()\n",
    "    \n",
    "    # Start counting fitness evaluations\n",
    "    fitness_counter.start_counting()\n",
    "    \n",
    "    # Run the appropriate algorithm\n",
    "    if config[\"algorithm\"] == \"hill_climbing\":\n",
    "        max_neighbors = config.get(\"max_neighbors\", 10)\n",
    "        best_solution, best_fitness, history = hill_climbing(\n",
    "            solution_class=LeagueSolution,\n",
    "            players=players_list,\n",
    "            max_iterations=config[\"max_iterations\"],\n",
    "            max_neighbors=max_neighbors,\n",
    "            max_evaluations=max_evaluations\n",
    "        )\n",
    "        \n",
    "    elif config[\"algorithm\"] == \"simulated_annealing\":\n",
    "        best_solution, best_fitness, history = simulated_annealing(\n",
    "            solution_class=LeagueSolution,\n",
    "            players=players_list,\n",
    "            initial_temperature=config[\"initial_temperature\"],\n",
    "            cooling_rate=config[\"cooling_rate\"],\n",
    "            max_iterations=config[\"max_iterations\"],\n",
    "            max_evaluations=max_evaluations\n",
    "        )\n",
    "        \n",
    "    elif config[\"algorithm\"] == \"genetic_algorithm\":\n",
    "        # Select operators\n",
    "        if config[\"selection\"] == \"tournament\":\n",
    "            selection_func = selection_tournament\n",
    "        elif config[\"selection\"] == \"ranking\":\n",
    "            selection_func = selection_ranking\n",
    "        else:\n",
    "            selection_func = selection_tournament\n",
    "            \n",
    "        if config[\"crossover\"] == \"uniform\":\n",
    "            crossover_func = crossover_uniform\n",
    "        elif config[\"crossover\"] == \"one_point\":\n",
    "            crossover_func = crossover_one_point\n",
    "        else:\n",
    "            crossover_func = crossover_uniform\n",
    "            \n",
    "        if config[\"mutation\"] == \"swap\":\n",
    "            mutation_func = mutate_swap\n",
    "        elif config[\"mutation\"] == \"swap_constrained\":\n",
    "            mutation_func = mutate_swap_constrained\n",
    "        elif config[\"mutation\"] == \"scramble\":\n",
    "            mutation_func = mutate_scramble\n",
    "        else:\n",
    "            mutation_func = mutate_swap\n",
    "            \n",
    "        best_solution, best_fitness, history = run_genetic_algorithm(\n",
    "            solution_class=LeagueSolution,\n",
    "            players=players_list,\n",
    "            selection_func=selection_func,\n",
    "            crossover_func=crossover_func,\n",
    "            mutation_func=mutation_func,\n",
    "            population_size=config[\"population_size\"],\n",
    "            elitism_rate=config[\"elitism_rate\"],\n",
    "            tournament_size=config.get(\"tournament_size\", 3),\n",
    "            max_generations=config[\"max_generations\"],\n",
    "            mutation_rate=config.get(\"mutation_rate\", 0.1),\n",
    "            max_evaluations=max_evaluations\n",
    "        )\n",
    "        \n",
    "    elif config[\"algorithm\"] == \"hybrid_ga\":\n",
    "        # Select operators\n",
    "        if config[\"selection\"] == \"tournament\":\n",
    "            selection_func = selection_tournament\n",
    "        elif config[\"selection\"] == \"ranking\":\n",
    "            selection_func = selection_ranking\n",
    "        else:\n",
    "            selection_func = selection_tournament\n",
    "            \n",
    "        if config[\"crossover\"] == \"uniform\":\n",
    "            crossover_func = crossover_uniform\n",
    "        elif config[\"crossover\"] == \"one_point\":\n",
    "            crossover_func = crossover_one_point\n",
    "        else:\n",
    "            crossover_func = crossover_uniform\n",
    "            \n",
    "        if config[\"mutation\"] == \"swap\":\n",
    "            mutation_func = mutate_swap\n",
    "        elif config[\"mutation\"] == \"swap_constrained\":\n",
    "            mutation_func = mutate_swap_constrained\n",
    "        elif config[\"mutation\"] == \"scramble\":\n",
    "            mutation_func = mutate_scramble\n",
    "        else:\n",
    "            mutation_func = mutate_swap\n",
    "            \n",
    "        best_solution, best_fitness, history = run_hybrid_ga(\n",
    "            solution_class=LeagueHillClimbingSolution,\n",
    "            players=players_list,\n",
    "            selection_func=selection_func,\n",
    "            crossover_func=crossover_func,\n",
    "            mutation_func=mutation_func,\n",
    "            population_size=config[\"population_size\"],\n",
    "            elitism_rate=config[\"elitism_rate\"],\n",
    "            tournament_size=config.get(\"tournament_size\", 3),\n",
    "            max_generations=config[\"max_generations\"],\n",
    "            mutation_rate=config.get(\"mutation_rate\", 0.1),\n",
    "            local_search_rate=config.get(\"local_search_rate\", 0.1),\n",
    "            max_evaluations=max_evaluations\n",
    "        )\n",
    "    else:\n",
    "        raise ValueError(f\"Unknown algorithm: {config['algorithm']}\")\n",
    "    \n",
    "    # Stop counting fitness evaluations\n",
    "    evaluations = fitness_counter.stop_counting()\n",
    "    \n",
    "    # Calculate runtime\n",
    "    runtime = time.time() - start_time\n",
    "    \n",
    "    return best_solution, best_fitness, evaluations, runtime, history\n",
    "\n",
    "# Function to run multiple experiments sequentially\n",
    "def run_multiple_experiments(configs, players_list, num_runs=3, max_evaluations=None):\n",
    "    \"\"\"\n",
    "    Run multiple experiments sequentially.\n",
    "    \n",
    "    Args:\n",
    "        configs: List of algorithm configurations\n",
    "        players_list: List of player dictionaries\n",
    "        num_runs: Number of runs per configuration\n",
    "        max_evaluations: Maximum number of fitness evaluations per run\n",
    "        \n",
    "    Returns:\n",
    "        Tuple of (results_df, history_data)\n",
    "    \"\"\"\n",
    "    all_results = []\n",
    "    history_data = defaultdict(dict)\n",
    "    \n",
    "    for config_idx, config in enumerate(configs):\n",
    "        config_name = config[\"name\"]\n",
    "        \n",
    "        if EXPERIMENT_CONFIG['verbose']:\n",
    "            print(f\"Running {config_name}...\")\n",
    "        \n",
    "        for run in range(num_runs):\n",
    "            if EXPERIMENT_CONFIG['verbose']:\n",
    "                print(f\"  Run {run+1}/{num_runs}...\")\n",
    "            \n",
    "            # Run experiment\n",
    "            result = run_experiment(\n",
    "                config=config,\n",
    "                players_list=players_list,\n",
    "                max_evaluations=max_evaluations\n",
    "            )\n",
    "            \n",
    "            # Extract values from result\n",
    "            best_solution, best_fitness, evaluations, runtime, history = result\n",
    "            \n",
    "            # Store results\n",
    "            all_results.append({\n",
    "                'Configuration': config_name,\n",
    "                'Run': run,\n",
    "                'Best Fitness': best_fitness,\n",
    "                'Iterations': len(history),\n",
    "                'Function Evaluations': evaluations,\n",
    "                'Runtime (s)': runtime\n",
    "            })\n",
    "            \n",
    "            # Store history\n",
    "            history_data[config_name][run] = history\n",
    "    \n",
    "    # Convert to DataFrame\n",
    "    results_df = pd.DataFrame(all_results)\n",
    "    \n",
    "    return results_df, history_data\n",
    "\n",
    "# Function for worker process in parallel execution\n",
    "def run_worker(config, players_list, run, max_evaluations, result_queue, error_queue):\n",
    "    \"\"\"\n",
    "    Worker function for parallel execution.\n",
    "    \n",
    "    Args:\n",
    "        config: Algorithm configuration\n",
    "        players_list: List of player dictionaries\n",
    "        run: Run number\n",
    "        max_evaluations: Maximum number of fitness evaluations\n",
    "        result_queue: Queue for results\n",
    "        error_queue: Queue for errors\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Set random seed based on run number to ensure different results\n",
    "        random.seed(42 + run)\n",
    "        np.random.seed(42 + run)\n",
    "        \n",
    "        config_name = config[\"name\"]\n",
    "        \n",
    "        # Print start message\n",
    "        print(f\"Process started for {config_name}, Run {run+1}\")\n",
    "        \n",
    "        # Run experiment\n",
    "        result = run_experiment(\n",
    "            config=config,\n",
    "            players_list=players_list,\n",
    "            max_evaluations=max_evaluations\n",
    "        )\n",
    "        \n",
    "        # Extract values from result\n",
    "        best_solution, best_fitness, evaluations, runtime, history = result\n",
    "        \n",
    "        # Put result in queue\n",
    "        result_queue.put({\n",
    "            'Configuration': config_name,\n",
    "            'Run': run,\n",
    "            'Best Fitness': best_fitness,\n",
    "            'Iterations': len(history),\n",
    "            'Function Evaluations': evaluations,\n",
    "            'Runtime (s)': runtime,\n",
    "            'History': history\n",
    "        })\n",
    "        \n",
    "        # Print completion message\n",
    "        print(f\"Process completed for {config_name}, Run {run+1}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        # Put error in queue\n",
    "        error_queue.put({\n",
    "            'Configuration': config[\"name\"],\n",
    "            'Run': run,\n",
    "            'Error': str(e),\n",
    "            'Traceback': str(sys.exc_info())\n",
    "        })\n",
    "        print(f\"Error in {config['name']}, Run {run+1}: {str(e)}\")\n",
    "\n",
    "# Function to run multiple experiments in parallel\n",
    "def run_parallel_experiments(configs, players_list, num_runs=3, max_evaluations=None, num_processes=None):\n",
    "    \"\"\"\n",
    "    Run multiple experiments in parallel.\n",
    "    \n",
    "    Args:\n",
    "        configs: List of algorithm configurations\n",
    "        players_list: List of player dictionaries\n",
    "        num_runs: Number of runs per configuration\n",
    "        max_evaluations: Maximum number of fitness evaluations per run\n",
    "        num_processes: Number of parallel processes (None = automatic)\n",
    "        \n",
    "    Returns:\n",
    "        Tuple of (results_df, history_data)\n",
    "    \"\"\"\n",
    "    # Determine number of processes\n",
    "    if num_processes is None:\n",
    "        num_processes = multiprocessing.cpu_count()\n",
    "    \n",
    "    if EXPERIMENT_CONFIG['verbose']:\n",
    "        print(f\"Running experiments in parallel with {num_processes} processes...\")\n",
    "    \n",
    "    # Create queues for results and errors\n",
    "    result_queue = multiprocessing.Queue()\n",
    "    error_queue = multiprocessing.Queue()\n",
    "    \n",
    "    # Create list of all experiments to run\n",
    "    experiments = []\n",
    "    for config in configs:\n",
    "        for run in range(num_runs):\n",
    "            experiments.append((config, run))\n",
    "    \n",
    "    # Create and start processes\n",
    "    processes = []\n",
    "    for config, run in experiments:\n",
    "        p = multiprocessing.Process(\n",
    "            target=run_worker,\n",
    "            args=(config, players_list, run, max_evaluations, result_queue, error_queue)\n",
    "        )\n",
    "        processes.append(p)\n",
    "        p.start()\n",
    "        \n",
    "        # Limit number of concurrent processes\n",
    "        if len(processes) >= num_processes:\n",
    "            # Wait for a process to finish\n",
    "            processes[0].join()\n",
    "            processes.pop(0)\n",
    "    \n",
    "    # Wait for remaining processes to finish\n",
    "    for p in processes:\n",
    "        p.join()\n",
    "    \n",
    "    # Collect results\n",
    "    all_results = []\n",
    "    history_data = defaultdict(dict)\n",
    "    \n",
    "    # Get results from queue\n",
    "    while not result_queue.empty():\n",
    "        result = result_queue.get()\n",
    "        history = result.pop('History')\n",
    "        all_results.append(result)\n",
    "        history_data[result['Configuration']][result['Run']] = history\n",
    "    \n",
    "    # Check for errors\n",
    "    errors = []\n",
    "    while not error_queue.empty():\n",
    "        errors.append(error_queue.get())\n",
    "    \n",
    "    if errors:\n",
    "        print(f\"Encountered {len(errors)} errors:\")\n",
    "        for error in errors:\n",
    "            print(f\"  {error['Configuration']}, Run {error['Run']+1}: {error['Error']}\")\n",
    "    \n",
    "    # Convert to DataFrame\n",
    "    results_df = pd.DataFrame(all_results)\n",
    "    \n",
    "    return results_df, history_data\n",
    "\n",
    "# Function to run experiments (sequential or parallel)\n",
    "def run_experiments(configs, players_list, experiment_config=None):\n",
    "    \"\"\"\n",
    "    Run experiments with the specified configurations.\n",
    "    \n",
    "    Args:\n",
    "        configs: List of algorithm configurations\n",
    "        players_list: List of player dictionaries\n",
    "        experiment_config: Experiment configuration dictionary\n",
    "        \n",
    "    Returns:\n",
    "        Tuple of (results_df, history_data)\n",
    "    \"\"\"\n",
    "    if experiment_config is None:\n",
    "        experiment_config = EXPERIMENT_CONFIG\n",
    "    \n",
    "    # Extract configuration\n",
    "    parallel = experiment_config.get('parallel', False)\n",
    "    num_runs = experiment_config.get('num_runs', 3)\n",
    "    num_processes = experiment_config.get('num_processes', None)\n",
    "    max_evaluations = experiment_config.get('max_evaluations', None)\n",
    "    \n",
    "    # Run experiments\n",
    "    if parallel:\n",
    "        results_df, history_data = run_parallel_experiments(\n",
    "            configs, \n",
    "            players_list, \n",
    "            num_runs=num_runs, \n",
    "            max_evaluations=max_evaluations,\n",
    "            num_processes=num_processes\n",
    "        )\n",
    "    else:\n",
    "        # Run sequentially\n",
    "        results_df, history_data = run_multiple_experiments(\n",
    "            configs, \n",
    "            players_list, \n",
    "            num_runs=num_runs, \n",
    "            max_evaluations=max_evaluations\n",
    "        )\n",
    "    \n",
    "    # Save results\n",
    "    if experiment_config.get('save_results', False):\n",
    "        results_file = experiment_config.get('results_file', 'experiment_results.csv')\n",
    "        results_df.to_csv(results_file, index=False)\n",
    "        print(f\"Results saved to {results_file}\")\n",
    "    \n",
    "    return results_df, history_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96dc4914",
   "metadata": {},
   "source": [
    "## 3. Carregamento de Dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83705e21",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "# Função para carregar dados dos jogadores\n",
    "def load_players_data(file_paths=None):\n",
    "    \"\"\"\n",
    "    Load players data from CSV file.\n",
    "    \n",
    "    Args:\n",
    "        file_paths: List of possible file paths to try\n",
    "        \n",
    "    Returns:\n",
    "        List of player dictionaries\n",
    "    \"\"\"\n",
    "    if file_paths is None:\n",
    "        file_paths = [\n",
    "            \"players.csv\",\n",
    "            \"data/players.csv\",\n",
    "            \"../data/players.csv\",\n",
    "            \"/home/ubuntu/CIFO-24-25/data/players.csv\",\n",
    "            \"/home/ubuntu/CIFO/data/players.csv\"\n",
    "        ]\n",
    "    \n",
    "    # Try each path until one works\n",
    "    for path in file_paths:\n",
    "        try:\n",
    "            print(f\"Trying to load players data from {path}...\")\n",
    "            players_df = pd.read_csv(path)\n",
    "            print(f\"Successfully loaded players data from {path}\")\n",
    "            \n",
    "            # Normalize column names if needed\n",
    "            if \"Salary (€M)\" in players_df.columns and \"Salary\" not in players_df.columns:\n",
    "                # Create a copy of the Salary column with the simpler name\n",
    "                players_df[\"Salary\"] = players_df[\"Salary (€M)\"]\n",
    "                print(\"Normalized 'Salary (€M)' column to 'Salary'\")\n",
    "            \n",
    "            # Convert DataFrame to list of dictionaries\n",
    "            players_list = players_df.to_dict('records')\n",
    "            return players_list\n",
    "        except FileNotFoundError:\n",
    "            print(f\"File not found: {path}\")\n",
    "    \n",
    "    raise FileNotFoundError(\"Could not find players data file in any of the specified paths\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "feb3ad86",
   "metadata": {},
   "source": [
    "## 4. Execução dos Experimentos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ad4c5a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carregar dados dos jogadores\n",
    "try:\n",
    "    players_list = load_players_data()\n",
    "    print(f\"Loaded {len(players_list)} players\")\n",
    "except FileNotFoundError as e:\n",
    "    print(f\"Error: {e}\")\n",
    "    print(\"Please provide the correct path to the players.csv file\")\n",
    "    players_list = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "018f0ced",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "# Executar experimentos se os dados foram carregados com sucesso\n",
    "if players_list:\n",
    "    # Run experiments\n",
    "    results_df, history_data = run_experiments(\n",
    "        ALGORITHM_CONFIGS, \n",
    "        players_list, \n",
    "        experiment_config=EXPERIMENT_CONFIG\n",
    "    )\n",
    "    \n",
    "    # Display results\n",
    "    print(\"\\nExperiment Results:\")\n",
    "    print(results_df)\n",
    "else:\n",
    "    print(\"Cannot run experiments without player data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c7d7e6f",
   "metadata": {},
   "source": [
    "## 5. Análise de Resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12d4b124",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "# Função para calcular estatísticas de resumo\n",
    "def calculate_summary_statistics(results_df):\n",
    "    \"\"\"\n",
    "    Calculate summary statistics for each configuration.\n",
    "    \n",
    "    Args:\n",
    "        results_df: DataFrame with experiment results\n",
    "        \n",
    "    Returns:\n",
    "        Dictionary of DataFrames with statistics for each metric\n",
    "    \"\"\"\n",
    "    # Group by configuration\n",
    "    grouped = results_df.groupby('Configuration')\n",
    "    \n",
    "    # Calculate statistics for each metric\n",
    "    metrics = {\n",
    "        'Best Fitness': 'Fitness Statistics:',\n",
    "        'Iterations': 'Iterations Statistics:',\n",
    "        'Function Evaluations': 'Function Evaluations Statistics:',\n",
    "        'Runtime (s)': 'Runtime Statistics (seconds):'\n",
    "    }\n",
    "    \n",
    "    stats_dfs = {}\n",
    "    \n",
    "    for metric, title in metrics.items():\n",
    "        # Calculate statistics\n",
    "        metric_stats = grouped[metric].agg(['mean', 'std', 'min', 'max'])\n",
    "        \n",
    "        # Format values for display\n",
    "        metric_stats = metric_stats.map(lambda x: f\"{x:.6f}\" if not pd.isna(x) and not np.isinf(x) else \"N/A\")\n",
    "        \n",
    "        stats_dfs[metric] = (title, metric_stats)\n",
    "    \n",
    "    return stats_dfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e082afa",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "if 'results_df' in locals():\n",
    "    # Calculate summary statistics\n",
    "    stats_dfs = calculate_summary_statistics(results_df)\n",
    "    \n",
    "    # Display statistics\n",
    "    for metric, (title, df) in stats_dfs.items():\n",
    "        print(f\"\\n{title}\")\n",
    "        print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba234b99",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "# Função para plotar gráficos de convergência\n",
    "def plot_convergence_graphs(history_data, num_runs_to_show=3):\n",
    "    \"\"\"\n",
    "    Plot convergence graphs for each algorithm.\n",
    "    \n",
    "    Args:\n",
    "        history_data: Dictionary of history data\n",
    "        num_runs_to_show: Number of runs to show in the plot\n",
    "    \"\"\"\n",
    "    # Create figure\n",
    "    fig, axes = plt.subplots(len(history_data), 1, figsize=(12, 4 * len(history_data)))\n",
    "    \n",
    "    if len(history_data) == 1:\n",
    "        axes = [axes]\n",
    "    \n",
    "    # Plot each algorithm\n",
    "    for i, (config_name, runs) in enumerate(history_data.items()):\n",
    "        ax = axes[i]\n",
    "        \n",
    "        # Plot each run\n",
    "        for run in range(min(num_runs_to_show, len(runs))):\n",
    "            history = runs[run]\n",
    "            ax.plot(history, label=f'Run {run+1}')\n",
    "        \n",
    "        # Add labels and title\n",
    "        ax.set_xlabel('Iteration')\n",
    "        ax.set_ylabel('Fitness (lower is better)')\n",
    "        ax.set_title(f'Convergence for {config_name}')\n",
    "        ax.legend()\n",
    "        ax.grid(True)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08d052f6",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "if 'history_data' in locals():\n",
    "    # Plot convergence graphs\n",
    "    plot_convergence_graphs(history_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e377c4f4",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "# Função para plotar comparação de algoritmos\n",
    "def plot_algorithm_comparison(results_df):\n",
    "    \"\"\"\n",
    "    Plot comparison of algorithms.\n",
    "    \n",
    "    Args:\n",
    "        results_df: DataFrame with experiment results\n",
    "    \"\"\"\n",
    "    # Create figure\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "    \n",
    "    # Flatten axes for easier iteration\n",
    "    axes = axes.flatten()\n",
    "    \n",
    "    # Metrics to plot\n",
    "    metrics = [\n",
    "        ('Best Fitness', 'Fitness (lower is better)'),\n",
    "        ('Iterations', 'Number of Iterations'),\n",
    "        ('Function Evaluations', 'Number of Function Evaluations'),\n",
    "        ('Runtime (s)', 'Runtime (seconds)')\n",
    "    ]\n",
    "    \n",
    "    # Plot each metric\n",
    "    for i, (metric, ylabel) in enumerate(metrics):\n",
    "        # Create boxplot with scatterplot overlay\n",
    "        ax = axes[i]\n",
    "        \n",
    "        # Boxplot\n",
    "        sns.boxplot(x='Configuration', y=metric, data=results_df, ax=ax)\n",
    "        \n",
    "        # Scatterplot overlay\n",
    "        sns.stripplot(x='Configuration', y=metric, data=results_df, \n",
    "                     color='black', alpha=0.5, jitter=True, ax=ax)\n",
    "        \n",
    "        # Rotate x-axis labels\n",
    "        ax.set_xticklabels(ax.get_xticklabels(), rotation=45, ha='right')\n",
    "        \n",
    "        # Add labels and title\n",
    "        ax.set_xlabel('Algorithm')\n",
    "        ax.set_ylabel(ylabel)\n",
    "        ax.set_title(f'Comparison of {metric} by Algorithm')\n",
    "        \n",
    "        # Add grid\n",
    "        ax.grid(True, linestyle='--', alpha=0.7)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fabc22ec",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "if 'results_df' in locals():\n",
    "    # Plot algorithm comparison\n",
    "    plot_algorithm_comparison(results_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c06b18b7",
   "metadata": {},
   "source": [
    "## 6. Visualização da Melhor Solução"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc3b5ed6",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "# Função para encontrar a melhor solução global\n",
    "def find_best_solution(results_df, history_data, players_list):\n",
    "    \"\"\"\n",
    "    Find the best solution across all experiments.\n",
    "    \n",
    "    Args:\n",
    "        results_df: DataFrame with experiment results\n",
    "        history_data: Dictionary of history data\n",
    "        players_list: List of player dictionaries\n",
    "        \n",
    "    Returns:\n",
    "        Tuple of (best_config, best_run, best_fitness)\n",
    "    \"\"\"\n",
    "    if len(results_df) == 0:\n",
    "        return None, None, None\n",
    "    \n",
    "    # Find row with minimum fitness\n",
    "    best_idx = results_df['Best Fitness'].idxmin()\n",
    "    best_row = results_df.loc[best_idx]\n",
    "    \n",
    "    best_config = best_row['Configuration']\n",
    "    best_run = best_row['Run']\n",
    "    best_fitness = best_row['Best Fitness']\n",
    "    \n",
    "    print(f\"Best solution found by {best_config}, Run {best_run+1}\")\n",
    "    print(f\"Fitness: {best_fitness:.6f}\")\n",
    "    print(f\"Iterations: {best_row['Iterations']}\")\n",
    "    print(f\"Function Evaluations: {best_row['Function Evaluations']}\")\n",
    "    print(f\"Runtime: {best_row['Runtime (s)']:.6f} seconds\")\n",
    "    \n",
    "    return best_config, best_run, best_fitness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1450aa3e",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "# Função para visualizar a melhor solução\n",
    "def visualize_best_solution(best_config, best_run, players_list, algorithm_configs):\n",
    "    \"\"\"\n",
    "    Visualize the best solution.\n",
    "    \n",
    "    Args:\n",
    "        best_config: Name of the best configuration\n",
    "        best_run: Run number of the best solution\n",
    "        players_list: List of player dictionaries\n",
    "        algorithm_configs: List of algorithm configurations\n",
    "    \"\"\"\n",
    "    if best_config is None or best_run is None:\n",
    "        print(\"No best solution found\")\n",
    "        return\n",
    "    \n",
    "    # Find the configuration\n",
    "    config = next((c for c in algorithm_configs if c[\"name\"] == best_config), None)\n",
    "    if config is None:\n",
    "        print(f\"Configuration {best_config} not found\")\n",
    "        return\n",
    "    \n",
    "    # Re-run the experiment to get the best solution\n",
    "    best_solution, best_fitness, _, _, _ = run_experiment(config, players_list)\n",
    "    \n",
    "    # Get teams\n",
    "    teams = best_solution.get_teams()\n",
    "    team_stats = best_solution.get_team_stats()\n",
    "    \n",
    "    # Display team statistics\n",
    "    print(\"\\nTeam Statistics:\")\n",
    "    for i, stats in enumerate(team_stats):\n",
    "        print(f\"\\nTeam {i+1}:\")\n",
    "        print(f\"  Average Skill: {stats['avg_skill']:.2f}\")\n",
    "        print(f\"  Total Salary: {stats['total_salary']:.2f}\")\n",
    "        print(f\"  Positions: {stats['positions']}\")\n",
    "        \n",
    "        # Display players\n",
    "        print(\"  Players:\")\n",
    "        for p in stats['players']:\n",
    "            print(f\"    {p['Name']} - {p['Position']} - Skill: {p['Skill']} - Salary: {p.get('Salary', p.get('Salary (€M)', 'N/A'))}\")\n",
    "    \n",
    "    # Plot team skills\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    team_skills = [stats['avg_skill'] for stats in team_stats]\n",
    "    plt.bar(range(1, len(team_skills) + 1), team_skills)\n",
    "    plt.axhline(y=np.mean(team_skills), color='r', linestyle='-', label=f'Mean: {np.mean(team_skills):.2f}')\n",
    "    plt.xlabel('Team')\n",
    "    plt.ylabel('Average Skill')\n",
    "    plt.title('Team Balance - Average Skill by Team')\n",
    "    plt.xticks(range(1, len(team_skills) + 1))\n",
    "    plt.legend()\n",
    "    plt.grid(True, linestyle='--', alpha=0.7)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3a68bf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'results_df' in locals() and 'history_data' in locals() and players_list:\n",
    "    # Find and visualize best solution\n",
    "    best_config, best_run, best_fitness = find_best_solution(results_df, history_data, players_list)\n",
    "    \n",
    "    if EXPERIMENT_CONFIG['show_best_solution'] and best_config is not None:\n",
    "        visualize_best_solution(best_config, best_run, players_list, ALGORITHM_CONFIGS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67a5c7c0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "jupytext": {
   "formats": "ipynb,py:percent"
  },
  "kernelspec": {
   "display_name": "cloudspace",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
